[33m[2022-09-15 15:22:01,264] [ WARNING][0m - evaluation_strategy reset to IntervalStrategy.STEPS for do_eval is True. you can also set evaluation_strategy='epoch'.[0m
[32m[2022-09-15 15:22:01,265] [    INFO][0m - The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).[0m
[32m[2022-09-15 15:22:01,265] [    INFO][0m - ============================================================[0m
[32m[2022-09-15 15:22:01,265] [    INFO][0m -      Model Configuration Arguments      [0m
[32m[2022-09-15 15:22:01,265] [    INFO][0m - paddle commit id              :269bd1fe1f9b7d4bf043b9d7a039b9f4cd53ebb7[0m
[32m[2022-09-15 15:22:01,265] [    INFO][0m - do_save                       :True[0m
[32m[2022-09-15 15:22:01,265] [    INFO][0m - do_test                       :True[0m
[32m[2022-09-15 15:22:01,266] [    INFO][0m - early_stop_patience           :4[0m
[32m[2022-09-15 15:22:01,266] [    INFO][0m - export_type                   :paddle[0m
[32m[2022-09-15 15:22:01,266] [    INFO][0m - model_name_or_path            :ernie-1.0-large-zh-cw[0m
[32m[2022-09-15 15:22:01,266] [    INFO][0m - [0m
[32m[2022-09-15 15:22:01,266] [    INFO][0m - ============================================================[0m
[32m[2022-09-15 15:22:01,266] [    INFO][0m -       Data Configuration Arguments      [0m
[32m[2022-09-15 15:22:01,266] [    INFO][0m - paddle commit id              :269bd1fe1f9b7d4bf043b9d7a039b9f4cd53ebb7[0m
[32m[2022-09-15 15:22:01,266] [    INFO][0m - encoder_hidden_size           :200[0m
[32m[2022-09-15 15:22:01,266] [    INFO][0m - pretrained                    :./checkpoints_cmnli/checkpoint-6000/model_state.pdparams[0m
[32m[2022-09-15 15:22:01,266] [    INFO][0m - prompt                        :‚Äú{'text':'text_a'}‚Äù{'mask'}{'mask'}Ôºå‚Äú{'text':'text_b'}‚Äù[0m
[32m[2022-09-15 15:22:01,266] [    INFO][0m - soft_encoder                  :lstm[0m
[32m[2022-09-15 15:22:01,266] [    INFO][0m - split_id                      :few_all[0m
[32m[2022-09-15 15:22:01,266] [    INFO][0m - task_name                     :ocnli[0m
[32m[2022-09-15 15:22:01,266] [    INFO][0m - [0m
[32m[2022-09-15 15:22:01,267] [    INFO][0m - Already cached /ssd2/wanghuijuan03/.paddlenlp/models/ernie-1.0-large-zh-cw/ernie_1.0_large_zh_cw.pdparams[0m
W0915 15:22:01.268656 75291 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2
W0915 15:22:01.272936 75291 gpu_resources.cc:91] device: 0, cuDNN Version: 8.1.
[32m[2022-09-15 15:22:12,514] [    INFO][0m - Already cached /ssd2/wanghuijuan03/.paddlenlp/models/ernie-1.0-large-zh-cw/vocab.txt[0m
[32m[2022-09-15 15:22:12,525] [    INFO][0m - tokenizer config file saved in /ssd2/wanghuijuan03/.paddlenlp/models/ernie-1.0-large-zh-cw/tokenizer_config.json[0m
[32m[2022-09-15 15:22:12,526] [    INFO][0m - Special tokens file saved in /ssd2/wanghuijuan03/.paddlenlp/models/ernie-1.0-large-zh-cw/special_tokens_map.json[0m
[32m[2022-09-15 15:22:12,526] [    INFO][0m - Using template: [{'add_prefix_space': '', 'hard': '‚Äú'}, {'add_prefix_space': '', 'text': 'text_a'}, {'add_prefix_space': '', 'hard': '‚Äù'}, {'add_prefix_space': '', 'mask': None}, {'add_prefix_space': '', 'mask': None}, {'add_prefix_space': '', 'hard': 'Ôºå‚Äú'}, {'add_prefix_space': '', 'text': 'text_b'}, {'add_prefix_space': '', 'hard': '‚Äù'}][0m
[32m[2022-09-15 15:22:14,974] [    INFO][0m - ============================================================[0m
[32m[2022-09-15 15:22:14,974] [    INFO][0m -     Training Configuration Arguments    [0m
[32m[2022-09-15 15:22:14,974] [    INFO][0m - paddle commit id              :269bd1fe1f9b7d4bf043b9d7a039b9f4cd53ebb7[0m
[32m[2022-09-15 15:22:14,975] [    INFO][0m - _no_sync_in_gradient_accumulation:True[0m
[32m[2022-09-15 15:22:14,975] [    INFO][0m - adam_beta1                    :0.9[0m
[32m[2022-09-15 15:22:14,975] [    INFO][0m - adam_beta2                    :0.999[0m
[32m[2022-09-15 15:22:14,975] [    INFO][0m - adam_epsilon                  :1e-08[0m
[32m[2022-09-15 15:22:14,975] [    INFO][0m - alpha_rdrop                   :5.0[0m
[32m[2022-09-15 15:22:14,975] [    INFO][0m - alpha_rgl                     :0.5[0m
[32m[2022-09-15 15:22:14,975] [    INFO][0m - current_device                :gpu:0[0m
[32m[2022-09-15 15:22:14,975] [    INFO][0m - dataloader_drop_last          :False[0m
[32m[2022-09-15 15:22:14,975] [    INFO][0m - dataloader_num_workers        :0[0m
[32m[2022-09-15 15:22:14,975] [    INFO][0m - device                        :gpu[0m
[32m[2022-09-15 15:22:14,975] [    INFO][0m - disable_tqdm                  :True[0m
[32m[2022-09-15 15:22:14,975] [    INFO][0m - do_eval                       :True[0m
[32m[2022-09-15 15:22:14,976] [    INFO][0m - do_export                     :False[0m
[32m[2022-09-15 15:22:14,976] [    INFO][0m - do_predict                    :True[0m
[32m[2022-09-15 15:22:14,976] [    INFO][0m - do_train                      :True[0m
[32m[2022-09-15 15:22:14,976] [    INFO][0m - eval_batch_size               :16[0m
[32m[2022-09-15 15:22:14,976] [    INFO][0m - eval_steps                    :500[0m
[32m[2022-09-15 15:22:14,976] [    INFO][0m - evaluation_strategy           :IntervalStrategy.STEPS[0m
[32m[2022-09-15 15:22:14,976] [    INFO][0m - first_max_length              :None[0m
[32m[2022-09-15 15:22:14,976] [    INFO][0m - fp16                          :False[0m
[32m[2022-09-15 15:22:14,976] [    INFO][0m - fp16_opt_level                :O1[0m
[32m[2022-09-15 15:22:14,976] [    INFO][0m - freeze_dropout                :False[0m
[32m[2022-09-15 15:22:14,976] [    INFO][0m - freeze_plm                    :False[0m
[32m[2022-09-15 15:22:14,976] [    INFO][0m - gradient_accumulation_steps   :1[0m
[32m[2022-09-15 15:22:14,976] [    INFO][0m - greater_is_better             :True[0m
[32m[2022-09-15 15:22:14,976] [    INFO][0m - ignore_data_skip              :False[0m
[32m[2022-09-15 15:22:14,977] [    INFO][0m - label_names                   :None[0m
[32m[2022-09-15 15:22:14,977] [    INFO][0m - learning_rate                 :3e-06[0m
[32m[2022-09-15 15:22:14,977] [    INFO][0m - load_best_model_at_end        :True[0m
[32m[2022-09-15 15:22:14,977] [    INFO][0m - local_process_index           :0[0m
[32m[2022-09-15 15:22:14,977] [    INFO][0m - local_rank                    :-1[0m
[32m[2022-09-15 15:22:14,977] [    INFO][0m - log_level                     :-1[0m
[32m[2022-09-15 15:22:14,977] [    INFO][0m - log_level_replica             :-1[0m
[32m[2022-09-15 15:22:14,977] [    INFO][0m - log_on_each_node              :True[0m
[32m[2022-09-15 15:22:14,977] [    INFO][0m - logging_dir                   :./checkpoints/runs/Sep15_15-22-01_instance-3bwob41y-01[0m
[32m[2022-09-15 15:22:14,977] [    INFO][0m - logging_first_step            :False[0m
[32m[2022-09-15 15:22:14,977] [    INFO][0m - logging_steps                 :10[0m
[32m[2022-09-15 15:22:14,977] [    INFO][0m - logging_strategy              :IntervalStrategy.STEPS[0m
[32m[2022-09-15 15:22:14,977] [    INFO][0m - lr_scheduler_type             :SchedulerType.LINEAR[0m
[32m[2022-09-15 15:22:14,978] [    INFO][0m - max_grad_norm                 :1.0[0m
[32m[2022-09-15 15:22:14,978] [    INFO][0m - max_seq_length                :128[0m
[32m[2022-09-15 15:22:14,978] [    INFO][0m - max_steps                     :-1[0m
[32m[2022-09-15 15:22:14,978] [    INFO][0m - metric_for_best_model         :accuracy[0m
[32m[2022-09-15 15:22:14,978] [    INFO][0m - minimum_eval_times            :None[0m
[32m[2022-09-15 15:22:14,978] [    INFO][0m - no_cuda                       :False[0m
[32m[2022-09-15 15:22:14,978] [    INFO][0m - num_train_epochs              :50.0[0m
[32m[2022-09-15 15:22:14,978] [    INFO][0m - optim                         :OptimizerNames.ADAMW[0m
[32m[2022-09-15 15:22:14,978] [    INFO][0m - other_max_length              :None[0m
[32m[2022-09-15 15:22:14,978] [    INFO][0m - output_dir                    :./checkpoints/[0m
[32m[2022-09-15 15:22:14,978] [    INFO][0m - overwrite_output_dir          :False[0m
[32m[2022-09-15 15:22:14,978] [    INFO][0m - past_index                    :-1[0m
[32m[2022-09-15 15:22:14,978] [    INFO][0m - per_device_eval_batch_size    :16[0m
[32m[2022-09-15 15:22:14,978] [    INFO][0m - per_device_train_batch_size   :16[0m
[32m[2022-09-15 15:22:14,979] [    INFO][0m - ppt_adam_beta1                :0.9[0m
[32m[2022-09-15 15:22:14,979] [    INFO][0m - ppt_adam_beta2                :0.999[0m
[32m[2022-09-15 15:22:14,979] [    INFO][0m - ppt_adam_epsilon              :1e-08[0m
[32m[2022-09-15 15:22:14,979] [    INFO][0m - ppt_learning_rate             :3e-05[0m
[32m[2022-09-15 15:22:14,979] [    INFO][0m - ppt_weight_decay              :0.0[0m
[32m[2022-09-15 15:22:14,979] [    INFO][0m - prediction_loss_only          :False[0m
[32m[2022-09-15 15:22:14,979] [    INFO][0m - process_index                 :0[0m
[32m[2022-09-15 15:22:14,979] [    INFO][0m - remove_unused_columns         :True[0m
[32m[2022-09-15 15:22:14,979] [    INFO][0m - report_to                     :['visualdl'][0m
[32m[2022-09-15 15:22:14,979] [    INFO][0m - resume_from_checkpoint        :None[0m
[32m[2022-09-15 15:22:14,979] [    INFO][0m - run_name                      :./checkpoints/[0m
[32m[2022-09-15 15:22:14,979] [    INFO][0m - save_on_each_node             :False[0m
[32m[2022-09-15 15:22:14,979] [    INFO][0m - save_steps                    :500[0m
[32m[2022-09-15 15:22:14,980] [    INFO][0m - save_strategy                 :IntervalStrategy.STEPS[0m
[32m[2022-09-15 15:22:14,980] [    INFO][0m - save_total_limit              :None[0m
[32m[2022-09-15 15:22:14,980] [    INFO][0m - scale_loss                    :32768[0m
[32m[2022-09-15 15:22:14,980] [    INFO][0m - seed                          :42[0m
[32m[2022-09-15 15:22:14,980] [    INFO][0m - should_log                    :True[0m
[32m[2022-09-15 15:22:14,980] [    INFO][0m - should_save                   :True[0m
[32m[2022-09-15 15:22:14,980] [    INFO][0m - task_type                     :multi-class[0m
[32m[2022-09-15 15:22:14,980] [    INFO][0m - train_batch_size              :16[0m
[32m[2022-09-15 15:22:14,980] [    INFO][0m - truncate_mode                 :tail[0m
[32m[2022-09-15 15:22:14,980] [    INFO][0m - use_rdrop                     :False[0m
[32m[2022-09-15 15:22:14,980] [    INFO][0m - use_rgl                       :False[0m
[32m[2022-09-15 15:22:14,980] [    INFO][0m - warmup_ratio                  :0.0[0m
[32m[2022-09-15 15:22:14,980] [    INFO][0m - warmup_steps                  :0[0m
[32m[2022-09-15 15:22:14,980] [    INFO][0m - weight_decay                  :0.0[0m
[32m[2022-09-15 15:22:14,981] [    INFO][0m - world_size                    :1[0m
[32m[2022-09-15 15:22:14,981] [    INFO][0m - [0m
[32m[2022-09-15 15:22:14,983] [    INFO][0m - ***** Running training *****[0m
[32m[2022-09-15 15:22:14,983] [    INFO][0m -   Num examples = 160[0m
[32m[2022-09-15 15:22:14,983] [    INFO][0m -   Num Epochs = 50[0m
[32m[2022-09-15 15:22:14,983] [    INFO][0m -   Instantaneous batch size per device = 16[0m
[32m[2022-09-15 15:22:14,983] [    INFO][0m -   Total train batch size (w. parallel, distributed & accumulation) = 16[0m
[32m[2022-09-15 15:22:14,984] [    INFO][0m -   Gradient Accumulation steps = 1[0m
[32m[2022-09-15 15:22:14,984] [    INFO][0m -   Total optimization steps = 500.0[0m
[32m[2022-09-15 15:22:14,984] [    INFO][0m -   Total num train samples = 8000[0m
[32m[2022-09-15 15:22:24,910] [    INFO][0m - loss: 3.04744015, learning_rate: 2.9400000000000002e-06, global_step: 10, interval_runtime: 9.9243, interval_samples_per_second: 1.612, interval_steps_per_second: 1.008, epoch: 1.0[0m
[32m[2022-09-15 15:22:32,668] [    INFO][0m - loss: 1.56155968, learning_rate: 2.88e-06, global_step: 20, interval_runtime: 7.7589, interval_samples_per_second: 2.062, interval_steps_per_second: 1.289, epoch: 2.0[0m
[32m[2022-09-15 15:22:40,444] [    INFO][0m - loss: 0.99572744, learning_rate: 2.82e-06, global_step: 30, interval_runtime: 7.7762, interval_samples_per_second: 2.058, interval_steps_per_second: 1.286, epoch: 3.0[0m
[32m[2022-09-15 15:22:48,213] [    INFO][0m - loss: 0.75681205, learning_rate: 2.7600000000000003e-06, global_step: 40, interval_runtime: 7.769, interval_samples_per_second: 2.059, interval_steps_per_second: 1.287, epoch: 4.0[0m
[32m[2022-09-15 15:22:55,977] [    INFO][0m - loss: 0.58147435, learning_rate: 2.7e-06, global_step: 50, interval_runtime: 7.7642, interval_samples_per_second: 2.061, interval_steps_per_second: 1.288, epoch: 5.0[0m
[32m[2022-09-15 15:23:03,804] [    INFO][0m - loss: 0.42681384, learning_rate: 2.64e-06, global_step: 60, interval_runtime: 7.8274, interval_samples_per_second: 2.044, interval_steps_per_second: 1.278, epoch: 6.0[0m
[32m[2022-09-15 15:23:11,600] [    INFO][0m - loss: 0.32044842, learning_rate: 2.58e-06, global_step: 70, interval_runtime: 7.7955, interval_samples_per_second: 2.052, interval_steps_per_second: 1.283, epoch: 7.0[0m
[32m[2022-09-15 15:23:19,401] [    INFO][0m - loss: 0.25460775, learning_rate: 2.52e-06, global_step: 80, interval_runtime: 7.8005, interval_samples_per_second: 2.051, interval_steps_per_second: 1.282, epoch: 8.0[0m
[32m[2022-09-15 15:23:27,167] [    INFO][0m - loss: 0.18283327, learning_rate: 2.4599999999999997e-06, global_step: 90, interval_runtime: 7.7659, interval_samples_per_second: 2.06, interval_steps_per_second: 1.288, epoch: 9.0[0m
[32m[2022-09-15 15:23:34,993] [    INFO][0m - loss: 0.1037432, learning_rate: 2.4000000000000003e-06, global_step: 100, interval_runtime: 7.826, interval_samples_per_second: 2.044, interval_steps_per_second: 1.278, epoch: 10.0[0m
[32m[2022-09-15 15:23:42,781] [    INFO][0m - loss: 0.04732373, learning_rate: 2.34e-06, global_step: 110, interval_runtime: 7.7882, interval_samples_per_second: 2.054, interval_steps_per_second: 1.284, epoch: 11.0[0m
[32m[2022-09-15 15:23:50,481] [    INFO][0m - loss: 0.02960921, learning_rate: 2.28e-06, global_step: 120, interval_runtime: 7.6989, interval_samples_per_second: 2.078, interval_steps_per_second: 1.299, epoch: 12.0[0m
[32m[2022-09-15 15:23:58,271] [    INFO][0m - loss: 0.01618422, learning_rate: 2.22e-06, global_step: 130, interval_runtime: 7.791, interval_samples_per_second: 2.054, interval_steps_per_second: 1.284, epoch: 13.0[0m
[32m[2022-09-15 15:24:06,047] [    INFO][0m - loss: 0.00281077, learning_rate: 2.16e-06, global_step: 140, interval_runtime: 7.7761, interval_samples_per_second: 2.058, interval_steps_per_second: 1.286, epoch: 14.0[0m
[32m[2022-09-15 15:24:13,882] [    INFO][0m - loss: 0.00980846, learning_rate: 2.1e-06, global_step: 150, interval_runtime: 7.8353, interval_samples_per_second: 2.042, interval_steps_per_second: 1.276, epoch: 15.0[0m
[32m[2022-09-15 15:24:21,685] [    INFO][0m - loss: 0.02704768, learning_rate: 2.0400000000000004e-06, global_step: 160, interval_runtime: 7.8022, interval_samples_per_second: 2.051, interval_steps_per_second: 1.282, epoch: 16.0[0m
[32m[2022-09-15 15:24:29,503] [    INFO][0m - loss: 0.00465214, learning_rate: 1.98e-06, global_step: 170, interval_runtime: 7.8184, interval_samples_per_second: 2.046, interval_steps_per_second: 1.279, epoch: 17.0[0m
[32m[2022-09-15 15:24:37,275] [    INFO][0m - loss: 0.00040581, learning_rate: 1.9200000000000003e-06, global_step: 180, interval_runtime: 7.7718, interval_samples_per_second: 2.059, interval_steps_per_second: 1.287, epoch: 18.0[0m
[32m[2022-09-15 15:24:45,065] [    INFO][0m - loss: 0.00026571, learning_rate: 1.86e-06, global_step: 190, interval_runtime: 7.7907, interval_samples_per_second: 2.054, interval_steps_per_second: 1.284, epoch: 19.0[0m
[32m[2022-09-15 15:24:52,852] [    INFO][0m - loss: 0.00047109, learning_rate: 1.8e-06, global_step: 200, interval_runtime: 7.7863, interval_samples_per_second: 2.055, interval_steps_per_second: 1.284, epoch: 20.0[0m
[32m[2022-09-15 15:25:00,716] [    INFO][0m - loss: 0.00036476, learning_rate: 1.7399999999999999e-06, global_step: 210, interval_runtime: 7.8642, interval_samples_per_second: 2.035, interval_steps_per_second: 1.272, epoch: 21.0[0m
[32m[2022-09-15 15:25:08,503] [    INFO][0m - loss: 0.00013023, learning_rate: 1.6800000000000002e-06, global_step: 220, interval_runtime: 7.7871, interval_samples_per_second: 2.055, interval_steps_per_second: 1.284, epoch: 22.0[0m
[32m[2022-09-15 15:25:16,324] [    INFO][0m - loss: 0.00016291, learning_rate: 1.6200000000000002e-06, global_step: 230, interval_runtime: 7.821, interval_samples_per_second: 2.046, interval_steps_per_second: 1.279, epoch: 23.0[0m
[32m[2022-09-15 15:25:24,113] [    INFO][0m - loss: 0.00014412, learning_rate: 1.56e-06, global_step: 240, interval_runtime: 7.7886, interval_samples_per_second: 2.054, interval_steps_per_second: 1.284, epoch: 24.0[0m
[32m[2022-09-15 15:25:31,926] [    INFO][0m - loss: 9.754e-05, learning_rate: 1.5e-06, global_step: 250, interval_runtime: 7.8133, interval_samples_per_second: 2.048, interval_steps_per_second: 1.28, epoch: 25.0[0m
[32m[2022-09-15 15:25:39,748] [    INFO][0m - loss: 0.0001381, learning_rate: 1.44e-06, global_step: 260, interval_runtime: 7.8224, interval_samples_per_second: 2.045, interval_steps_per_second: 1.278, epoch: 26.0[0m
[32m[2022-09-15 15:25:47,597] [    INFO][0m - loss: 9.139e-05, learning_rate: 1.3800000000000001e-06, global_step: 270, interval_runtime: 7.8493, interval_samples_per_second: 2.038, interval_steps_per_second: 1.274, epoch: 27.0[0m
[32m[2022-09-15 15:25:55,488] [    INFO][0m - loss: 0.00014676, learning_rate: 1.32e-06, global_step: 280, interval_runtime: 7.89, interval_samples_per_second: 2.028, interval_steps_per_second: 1.267, epoch: 28.0[0m
[32m[2022-09-15 15:26:03,135] [    INFO][0m - loss: 0.00057587, learning_rate: 1.26e-06, global_step: 290, interval_runtime: 7.6478, interval_samples_per_second: 2.092, interval_steps_per_second: 1.308, epoch: 29.0[0m
[32m[2022-09-15 15:26:10,964] [    INFO][0m - loss: 0.00022721, learning_rate: 1.2000000000000002e-06, global_step: 300, interval_runtime: 7.8286, interval_samples_per_second: 2.044, interval_steps_per_second: 1.277, epoch: 30.0[0m
[32m[2022-09-15 15:26:18,770] [    INFO][0m - loss: 7.229e-05, learning_rate: 1.14e-06, global_step: 310, interval_runtime: 7.8056, interval_samples_per_second: 2.05, interval_steps_per_second: 1.281, epoch: 31.0[0m
[32m[2022-09-15 15:26:26,610] [    INFO][0m - loss: 5.477e-05, learning_rate: 1.08e-06, global_step: 320, interval_runtime: 7.8399, interval_samples_per_second: 2.041, interval_steps_per_second: 1.276, epoch: 32.0[0m
[32m[2022-09-15 15:26:34,394] [    INFO][0m - loss: 4.042e-05, learning_rate: 1.0200000000000002e-06, global_step: 330, interval_runtime: 7.7844, interval_samples_per_second: 2.055, interval_steps_per_second: 1.285, epoch: 33.0[0m
[32m[2022-09-15 15:26:42,062] [    INFO][0m - loss: 0.00019079, learning_rate: 9.600000000000001e-07, global_step: 340, interval_runtime: 7.6676, interval_samples_per_second: 2.087, interval_steps_per_second: 1.304, epoch: 34.0[0m
[32m[2022-09-15 15:26:49,773] [    INFO][0m - loss: 8.605e-05, learning_rate: 9e-07, global_step: 350, interval_runtime: 7.7107, interval_samples_per_second: 2.075, interval_steps_per_second: 1.297, epoch: 35.0[0m
[32m[2022-09-15 15:26:57,495] [    INFO][0m - loss: 7.879e-05, learning_rate: 8.400000000000001e-07, global_step: 360, interval_runtime: 7.7227, interval_samples_per_second: 2.072, interval_steps_per_second: 1.295, epoch: 36.0[0m
[32m[2022-09-15 15:27:05,169] [    INFO][0m - loss: 5.738e-05, learning_rate: 7.8e-07, global_step: 370, interval_runtime: 7.6742, interval_samples_per_second: 2.085, interval_steps_per_second: 1.303, epoch: 37.0[0m
[32m[2022-09-15 15:27:12,818] [    INFO][0m - loss: 4.256e-05, learning_rate: 7.2e-07, global_step: 380, interval_runtime: 7.6483, interval_samples_per_second: 2.092, interval_steps_per_second: 1.307, epoch: 38.0[0m
[32m[2022-09-15 15:27:20,638] [    INFO][0m - loss: 4.174e-05, learning_rate: 6.6e-07, global_step: 390, interval_runtime: 7.8199, interval_samples_per_second: 2.046, interval_steps_per_second: 1.279, epoch: 39.0[0m
[32m[2022-09-15 15:27:28,463] [    INFO][0m - loss: 4.106e-05, learning_rate: 6.000000000000001e-07, global_step: 400, interval_runtime: 7.825, interval_samples_per_second: 2.045, interval_steps_per_second: 1.278, epoch: 40.0[0m
[32m[2022-09-15 15:27:36,324] [    INFO][0m - loss: 4.618e-05, learning_rate: 5.4e-07, global_step: 410, interval_runtime: 7.8607, interval_samples_per_second: 2.035, interval_steps_per_second: 1.272, epoch: 41.0[0m
[32m[2022-09-15 15:27:44,173] [    INFO][0m - loss: 0.00010301, learning_rate: 4.800000000000001e-07, global_step: 420, interval_runtime: 7.8492, interval_samples_per_second: 2.038, interval_steps_per_second: 1.274, epoch: 42.0[0m
[32m[2022-09-15 15:27:52,039] [    INFO][0m - loss: 0.00010285, learning_rate: 4.2000000000000006e-07, global_step: 430, interval_runtime: 7.8665, interval_samples_per_second: 2.034, interval_steps_per_second: 1.271, epoch: 43.0[0m
[32m[2022-09-15 15:27:59,911] [    INFO][0m - loss: 5.568e-05, learning_rate: 3.6e-07, global_step: 440, interval_runtime: 7.8723, interval_samples_per_second: 2.032, interval_steps_per_second: 1.27, epoch: 44.0[0m
[32m[2022-09-15 15:28:07,541] [    INFO][0m - loss: 4.23e-05, learning_rate: 3.0000000000000004e-07, global_step: 450, interval_runtime: 7.6301, interval_samples_per_second: 2.097, interval_steps_per_second: 1.311, epoch: 45.0[0m
[32m[2022-09-15 15:28:15,410] [    INFO][0m - loss: 3.798e-05, learning_rate: 2.4000000000000003e-07, global_step: 460, interval_runtime: 7.869, interval_samples_per_second: 2.033, interval_steps_per_second: 1.271, epoch: 46.0[0m
[32m[2022-09-15 15:28:23,239] [    INFO][0m - loss: 4.059e-05, learning_rate: 1.8e-07, global_step: 470, interval_runtime: 7.8281, interval_samples_per_second: 2.044, interval_steps_per_second: 1.277, epoch: 47.0[0m
[32m[2022-09-15 15:28:31,096] [    INFO][0m - loss: 6.221e-05, learning_rate: 1.2000000000000002e-07, global_step: 480, interval_runtime: 7.8572, interval_samples_per_second: 2.036, interval_steps_per_second: 1.273, epoch: 48.0[0m
[32m[2022-09-15 15:28:38,917] [    INFO][0m - loss: 5.762e-05, learning_rate: 6.000000000000001e-08, global_step: 490, interval_runtime: 7.8212, interval_samples_per_second: 2.046, interval_steps_per_second: 1.279, epoch: 49.0[0m
[32m[2022-09-15 15:28:46,816] [    INFO][0m - loss: 3.782e-05, learning_rate: 0.0, global_step: 500, interval_runtime: 7.8988, interval_samples_per_second: 2.026, interval_steps_per_second: 1.266, epoch: 50.0[0m
[32m[2022-09-15 15:28:46,816] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-15 15:28:46,817] [    INFO][0m -   Num examples = 160[0m
[32m[2022-09-15 15:28:46,817] [    INFO][0m -   Pre device batch size = 16[0m
[32m[2022-09-15 15:28:46,817] [    INFO][0m -   Total Batch size = 16[0m
[32m[2022-09-15 15:28:46,817] [    INFO][0m -   Total prediction steps = 10[0m
[32m[2022-09-15 15:28:49,899] [    INFO][0m - eval_loss: 2.9232311248779297, eval_accuracy: 0.725, eval_runtime: 3.0821, eval_samples_per_second: 51.912, eval_steps_per_second: 3.245, epoch: 50.0[0m
[32m[2022-09-15 15:28:49,900] [    INFO][0m - Saving model checkpoint to ./checkpoints/checkpoint-500[0m
[32m[2022-09-15 15:28:49,900] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-15 15:28:53,454] [    INFO][0m - tokenizer config file saved in ./checkpoints/checkpoint-500/tokenizer_config.json[0m
[32m[2022-09-15 15:28:53,455] [    INFO][0m - Special tokens file saved in ./checkpoints/checkpoint-500/special_tokens_map.json[0m
[32m[2022-09-15 15:29:00,351] [    INFO][0m - 
Training completed. 
[0m
[32m[2022-09-15 15:29:00,351] [    INFO][0m - Loading best model from ./checkpoints/checkpoint-500 (score: 0.725).[0m
[32m[2022-09-15 15:29:03,259] [    INFO][0m - train_runtime: 408.2749, train_samples_per_second: 19.595, train_steps_per_second: 1.225, train_loss: 0.16746819826948922, epoch: 50.0[0m
[32m[2022-09-15 15:29:03,261] [    INFO][0m - Saving model checkpoint to ./checkpoints/[0m
[32m[2022-09-15 15:29:03,261] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-15 15:29:10,443] [    INFO][0m - tokenizer config file saved in ./checkpoints/tokenizer_config.json[0m
[32m[2022-09-15 15:29:10,444] [    INFO][0m - Special tokens file saved in ./checkpoints/special_tokens_map.json[0m
[32m[2022-09-15 15:29:10,445] [    INFO][0m - ***** train metrics *****[0m
[32m[2022-09-15 15:29:10,445] [    INFO][0m -   epoch                    =       50.0[0m
[32m[2022-09-15 15:29:10,445] [    INFO][0m -   train_loss               =     0.1675[0m
[32m[2022-09-15 15:29:10,445] [    INFO][0m -   train_runtime            = 0:06:48.27[0m
[32m[2022-09-15 15:29:10,445] [    INFO][0m -   train_samples_per_second =     19.595[0m
[32m[2022-09-15 15:29:10,446] [    INFO][0m -   train_steps_per_second   =      1.225[0m
[32m[2022-09-15 15:29:10,448] [    INFO][0m - ***** Running Prediction *****[0m
[32m[2022-09-15 15:29:10,448] [    INFO][0m -   Num examples = 2520[0m
[32m[2022-09-15 15:29:10,449] [    INFO][0m -   Pre device batch size = 16[0m
[32m[2022-09-15 15:29:10,449] [    INFO][0m -   Total Batch size = 16[0m
[32m[2022-09-15 15:29:10,449] [    INFO][0m -   Total prediction steps = 158[0m
[32m[2022-09-15 15:29:58,612] [    INFO][0m - ***** test metrics *****[0m
[32m[2022-09-15 15:29:58,613] [    INFO][0m -   test_accuracy           =     0.7071[0m
[32m[2022-09-15 15:29:58,613] [    INFO][0m -   test_loss               =     2.8245[0m
[32m[2022-09-15 15:29:58,613] [    INFO][0m -   test_runtime            = 0:00:48.16[0m
[32m[2022-09-15 15:29:58,613] [    INFO][0m -   test_samples_per_second =     52.322[0m
[32m[2022-09-15 15:29:58,613] [    INFO][0m -   test_steps_per_second   =       3.28[0m
[32m[2022-09-15 15:29:58,614] [    INFO][0m - ***** Running Prediction *****[0m
[32m[2022-09-15 15:29:58,614] [    INFO][0m -   Num examples = 3000[0m
[32m[2022-09-15 15:29:58,614] [    INFO][0m -   Pre device batch size = 16[0m
[32m[2022-09-15 15:29:58,614] [    INFO][0m -   Total Batch size = 16[0m
[32m[2022-09-15 15:29:58,614] [    INFO][0m -   Total prediction steps = 188[0m
[32m[2022-09-15 15:30:57,449] [    INFO][0m - Predictions for ocnlif saved to ./fewclue_submit_examples.[0m
{
  "labels": 2,
  "text_a": "\u4e03\u4e94\u671f\u95f4\u5f00\u59cb,\u56fd\u5bb6\u53c8\u6295\u8d44\u5c06\u6b66\u6c49\u5e02\u533a\u7684\u90e8\u5206\u571f\u5824\u6539\u5efa\u4e3a\u94a2\u7b4b\u6ce5\u51dd\u571f\u9632\u6c34\u5899",
  "text_b": "\u516b\u4e94\u671f\u95f4\u4f1a\u628a\u5269\u4e0b\u7684\u571f\u5824\u90fd\u6539\u5efa\u5b8c",
  "uid": 0
}

