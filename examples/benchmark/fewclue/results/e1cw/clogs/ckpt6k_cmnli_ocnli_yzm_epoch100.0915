[33m[2022-09-15 17:01:05,290] [ WARNING][0m - evaluation_strategy reset to IntervalStrategy.STEPS for do_eval is True. you can also set evaluation_strategy='epoch'.[0m
[32m[2022-09-15 17:01:05,290] [    INFO][0m - The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).[0m
[32m[2022-09-15 17:01:05,290] [    INFO][0m - ============================================================[0m
[32m[2022-09-15 17:01:05,290] [    INFO][0m -      Model Configuration Arguments      [0m
[32m[2022-09-15 17:01:05,290] [    INFO][0m - paddle commit id              :269bd1fe1f9b7d4bf043b9d7a039b9f4cd53ebb7[0m
[32m[2022-09-15 17:01:05,290] [    INFO][0m - do_save                       :True[0m
[32m[2022-09-15 17:01:05,290] [    INFO][0m - do_test                       :True[0m
[32m[2022-09-15 17:01:05,291] [    INFO][0m - early_stop_patience           :4[0m
[32m[2022-09-15 17:01:05,291] [    INFO][0m - export_type                   :paddle[0m
[32m[2022-09-15 17:01:05,291] [    INFO][0m - model_name_or_path            :ernie-1.0-large-zh-cw[0m
[32m[2022-09-15 17:01:05,291] [    INFO][0m - [0m
[32m[2022-09-15 17:01:05,291] [    INFO][0m - ============================================================[0m
[32m[2022-09-15 17:01:05,291] [    INFO][0m -       Data Configuration Arguments      [0m
[32m[2022-09-15 17:01:05,291] [    INFO][0m - paddle commit id              :269bd1fe1f9b7d4bf043b9d7a039b9f4cd53ebb7[0m
[32m[2022-09-15 17:01:05,291] [    INFO][0m - encoder_hidden_size           :200[0m
[32m[2022-09-15 17:01:05,291] [    INFO][0m - pretrained                    :./checkpoints_cmnli/checkpoint-6000/model_state.pdparams[0m
[32m[2022-09-15 17:01:05,291] [    INFO][0m - prompt                        :‚Äú{'text':'text_a'}‚ÄùÂíå‚Äú{'text':'text_b'}‚Äù‰πãÈó¥ÁöÑÈÄªËæëÂÖ≥Á≥ªÊòØ{'mask'}{'mask'}„ÄÇ[0m
[32m[2022-09-15 17:01:05,291] [    INFO][0m - soft_encoder                  :lstm[0m
[32m[2022-09-15 17:01:05,291] [    INFO][0m - split_id                      :few_all[0m
[32m[2022-09-15 17:01:05,291] [    INFO][0m - task_name                     :ocnli[0m
[32m[2022-09-15 17:01:05,292] [    INFO][0m - [0m
[32m[2022-09-15 17:01:05,292] [    INFO][0m - Already cached /ssd2/wanghuijuan03/.paddlenlp/models/ernie-1.0-large-zh-cw/ernie_1.0_large_zh_cw.pdparams[0m
W0915 17:01:05.293748 41791 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2
W0915 17:01:05.298647 41791 gpu_resources.cc:91] device: 0, cuDNN Version: 8.1.
[32m[2022-09-15 17:01:13,067] [    INFO][0m - Already cached /ssd2/wanghuijuan03/.paddlenlp/models/ernie-1.0-large-zh-cw/vocab.txt[0m
[32m[2022-09-15 17:01:13,079] [    INFO][0m - tokenizer config file saved in /ssd2/wanghuijuan03/.paddlenlp/models/ernie-1.0-large-zh-cw/tokenizer_config.json[0m
[32m[2022-09-15 17:01:13,079] [    INFO][0m - Special tokens file saved in /ssd2/wanghuijuan03/.paddlenlp/models/ernie-1.0-large-zh-cw/special_tokens_map.json[0m
[32m[2022-09-15 17:01:13,080] [    INFO][0m - Using template: [{'add_prefix_space': '', 'hard': '‚Äú'}, {'add_prefix_space': '', 'text': 'text_a'}, {'add_prefix_space': '', 'hard': '‚ÄùÂíå‚Äú'}, {'add_prefix_space': '', 'text': 'text_b'}, {'add_prefix_space': '', 'hard': '‚Äù‰πãÈó¥ÁöÑÈÄªËæëÂÖ≥Á≥ªÊòØ'}, {'add_prefix_space': '', 'mask': None}, {'add_prefix_space': '', 'mask': None}, {'add_prefix_space': '', 'hard': '„ÄÇ'}][0m
[32m[2022-09-15 17:01:14,960] [    INFO][0m - ============================================================[0m
[32m[2022-09-15 17:01:14,961] [    INFO][0m -     Training Configuration Arguments    [0m
[32m[2022-09-15 17:01:14,961] [    INFO][0m - paddle commit id              :269bd1fe1f9b7d4bf043b9d7a039b9f4cd53ebb7[0m
[32m[2022-09-15 17:01:14,961] [    INFO][0m - _no_sync_in_gradient_accumulation:True[0m
[32m[2022-09-15 17:01:14,961] [    INFO][0m - adam_beta1                    :0.9[0m
[32m[2022-09-15 17:01:14,961] [    INFO][0m - adam_beta2                    :0.999[0m
[32m[2022-09-15 17:01:14,961] [    INFO][0m - adam_epsilon                  :1e-08[0m
[32m[2022-09-15 17:01:14,961] [    INFO][0m - alpha_rdrop                   :5.0[0m
[32m[2022-09-15 17:01:14,961] [    INFO][0m - alpha_rgl                     :0.5[0m
[32m[2022-09-15 17:01:14,961] [    INFO][0m - current_device                :gpu:0[0m
[32m[2022-09-15 17:01:14,962] [    INFO][0m - dataloader_drop_last          :False[0m
[32m[2022-09-15 17:01:14,962] [    INFO][0m - dataloader_num_workers        :0[0m
[32m[2022-09-15 17:01:14,962] [    INFO][0m - device                        :gpu[0m
[32m[2022-09-15 17:01:14,962] [    INFO][0m - disable_tqdm                  :True[0m
[32m[2022-09-15 17:01:14,962] [    INFO][0m - do_eval                       :True[0m
[32m[2022-09-15 17:01:14,962] [    INFO][0m - do_export                     :False[0m
[32m[2022-09-15 17:01:14,962] [    INFO][0m - do_predict                    :True[0m
[32m[2022-09-15 17:01:14,962] [    INFO][0m - do_train                      :True[0m
[32m[2022-09-15 17:01:14,962] [    INFO][0m - eval_batch_size               :16[0m
[32m[2022-09-15 17:01:14,962] [    INFO][0m - eval_steps                    :200[0m
[32m[2022-09-15 17:01:14,962] [    INFO][0m - evaluation_strategy           :IntervalStrategy.STEPS[0m
[32m[2022-09-15 17:01:14,962] [    INFO][0m - first_max_length              :None[0m
[32m[2022-09-15 17:01:14,963] [    INFO][0m - fp16                          :False[0m
[32m[2022-09-15 17:01:14,963] [    INFO][0m - fp16_opt_level                :O1[0m
[32m[2022-09-15 17:01:14,963] [    INFO][0m - freeze_dropout                :False[0m
[32m[2022-09-15 17:01:14,963] [    INFO][0m - freeze_plm                    :False[0m
[32m[2022-09-15 17:01:14,963] [    INFO][0m - gradient_accumulation_steps   :1[0m
[32m[2022-09-15 17:01:14,963] [    INFO][0m - greater_is_better             :True[0m
[32m[2022-09-15 17:01:14,963] [    INFO][0m - ignore_data_skip              :False[0m
[32m[2022-09-15 17:01:14,963] [    INFO][0m - label_names                   :None[0m
[32m[2022-09-15 17:01:14,963] [    INFO][0m - learning_rate                 :3e-06[0m
[32m[2022-09-15 17:01:14,963] [    INFO][0m - load_best_model_at_end        :True[0m
[32m[2022-09-15 17:01:14,963] [    INFO][0m - local_process_index           :0[0m
[32m[2022-09-15 17:01:14,963] [    INFO][0m - local_rank                    :-1[0m
[32m[2022-09-15 17:01:14,963] [    INFO][0m - log_level                     :-1[0m
[32m[2022-09-15 17:01:14,964] [    INFO][0m - log_level_replica             :-1[0m
[32m[2022-09-15 17:01:14,964] [    INFO][0m - log_on_each_node              :True[0m
[32m[2022-09-15 17:01:14,964] [    INFO][0m - logging_dir                   :./checkpoints/runs/Sep15_17-01-05_instance-3bwob41y-01[0m
[32m[2022-09-15 17:01:14,964] [    INFO][0m - logging_first_step            :False[0m
[32m[2022-09-15 17:01:14,964] [    INFO][0m - logging_steps                 :10[0m
[32m[2022-09-15 17:01:14,964] [    INFO][0m - logging_strategy              :IntervalStrategy.STEPS[0m
[32m[2022-09-15 17:01:14,964] [    INFO][0m - lr_scheduler_type             :SchedulerType.LINEAR[0m
[32m[2022-09-15 17:01:14,964] [    INFO][0m - max_grad_norm                 :1.0[0m
[32m[2022-09-15 17:01:14,964] [    INFO][0m - max_seq_length                :128[0m
[32m[2022-09-15 17:01:14,964] [    INFO][0m - max_steps                     :-1[0m
[32m[2022-09-15 17:01:14,964] [    INFO][0m - metric_for_best_model         :accuracy[0m
[32m[2022-09-15 17:01:14,964] [    INFO][0m - minimum_eval_times            :None[0m
[32m[2022-09-15 17:01:14,964] [    INFO][0m - no_cuda                       :False[0m
[32m[2022-09-15 17:01:14,964] [    INFO][0m - num_train_epochs              :100.0[0m
[32m[2022-09-15 17:01:14,965] [    INFO][0m - optim                         :OptimizerNames.ADAMW[0m
[32m[2022-09-15 17:01:14,965] [    INFO][0m - other_max_length              :None[0m
[32m[2022-09-15 17:01:14,965] [    INFO][0m - output_dir                    :./checkpoints/[0m
[32m[2022-09-15 17:01:14,965] [    INFO][0m - overwrite_output_dir          :False[0m
[32m[2022-09-15 17:01:14,965] [    INFO][0m - past_index                    :-1[0m
[32m[2022-09-15 17:01:14,965] [    INFO][0m - per_device_eval_batch_size    :16[0m
[32m[2022-09-15 17:01:14,965] [    INFO][0m - per_device_train_batch_size   :16[0m
[32m[2022-09-15 17:01:14,965] [    INFO][0m - ppt_adam_beta1                :0.9[0m
[32m[2022-09-15 17:01:14,965] [    INFO][0m - ppt_adam_beta2                :0.999[0m
[32m[2022-09-15 17:01:14,965] [    INFO][0m - ppt_adam_epsilon              :1e-08[0m
[32m[2022-09-15 17:01:14,965] [    INFO][0m - ppt_learning_rate             :3e-05[0m
[32m[2022-09-15 17:01:14,965] [    INFO][0m - ppt_weight_decay              :0.0[0m
[32m[2022-09-15 17:01:14,965] [    INFO][0m - prediction_loss_only          :False[0m
[32m[2022-09-15 17:01:14,966] [    INFO][0m - process_index                 :0[0m
[32m[2022-09-15 17:01:14,966] [    INFO][0m - remove_unused_columns         :True[0m
[32m[2022-09-15 17:01:14,966] [    INFO][0m - report_to                     :['visualdl'][0m
[32m[2022-09-15 17:01:14,966] [    INFO][0m - resume_from_checkpoint        :None[0m
[32m[2022-09-15 17:01:14,966] [    INFO][0m - run_name                      :./checkpoints/[0m
[32m[2022-09-15 17:01:14,966] [    INFO][0m - save_on_each_node             :False[0m
[32m[2022-09-15 17:01:14,966] [    INFO][0m - save_steps                    :200[0m
[32m[2022-09-15 17:01:14,966] [    INFO][0m - save_strategy                 :IntervalStrategy.STEPS[0m
[32m[2022-09-15 17:01:14,966] [    INFO][0m - save_total_limit              :None[0m
[32m[2022-09-15 17:01:14,966] [    INFO][0m - scale_loss                    :32768[0m
[32m[2022-09-15 17:01:14,966] [    INFO][0m - seed                          :42[0m
[32m[2022-09-15 17:01:14,966] [    INFO][0m - should_log                    :True[0m
[32m[2022-09-15 17:01:14,966] [    INFO][0m - should_save                   :True[0m
[32m[2022-09-15 17:01:14,966] [    INFO][0m - task_type                     :multi-class[0m
[32m[2022-09-15 17:01:14,967] [    INFO][0m - train_batch_size              :16[0m
[32m[2022-09-15 17:01:14,967] [    INFO][0m - truncate_mode                 :tail[0m
[32m[2022-09-15 17:01:14,967] [    INFO][0m - use_rdrop                     :False[0m
[32m[2022-09-15 17:01:14,967] [    INFO][0m - use_rgl                       :False[0m
[32m[2022-09-15 17:01:14,967] [    INFO][0m - warmup_ratio                  :0.0[0m
[32m[2022-09-15 17:01:14,967] [    INFO][0m - warmup_steps                  :0[0m
[32m[2022-09-15 17:01:14,967] [    INFO][0m - weight_decay                  :0.0[0m
[32m[2022-09-15 17:01:14,967] [    INFO][0m - world_size                    :1[0m
[32m[2022-09-15 17:01:14,967] [    INFO][0m - [0m
[32m[2022-09-15 17:01:14,970] [    INFO][0m - ***** Running training *****[0m
[32m[2022-09-15 17:01:14,970] [    INFO][0m -   Num examples = 160[0m
[32m[2022-09-15 17:01:14,970] [    INFO][0m -   Num Epochs = 100[0m
[32m[2022-09-15 17:01:14,970] [    INFO][0m -   Instantaneous batch size per device = 16[0m
[32m[2022-09-15 17:01:14,970] [    INFO][0m -   Total train batch size (w. parallel, distributed & accumulation) = 16[0m
[32m[2022-09-15 17:01:14,970] [    INFO][0m -   Gradient Accumulation steps = 1[0m
[32m[2022-09-15 17:01:14,971] [    INFO][0m -   Total optimization steps = 1000.0[0m
[32m[2022-09-15 17:01:14,971] [    INFO][0m -   Total num train samples = 16000[0m
[32m[2022-09-15 17:01:19,599] [    INFO][0m - loss: 0.66741209, learning_rate: 2.97e-06, global_step: 10, interval_runtime: 4.6271, interval_samples_per_second: 3.458, interval_steps_per_second: 2.161, epoch: 1.0[0m
[32m[2022-09-15 17:01:23,016] [    INFO][0m - loss: 0.54660683, learning_rate: 2.9400000000000002e-06, global_step: 20, interval_runtime: 3.4168, interval_samples_per_second: 4.683, interval_steps_per_second: 2.927, epoch: 2.0[0m
[32m[2022-09-15 17:01:26,423] [    INFO][0m - loss: 0.41750984, learning_rate: 2.91e-06, global_step: 30, interval_runtime: 3.4076, interval_samples_per_second: 4.695, interval_steps_per_second: 2.935, epoch: 3.0[0m
[32m[2022-09-15 17:01:29,829] [    INFO][0m - loss: 0.33599036, learning_rate: 2.88e-06, global_step: 40, interval_runtime: 3.4061, interval_samples_per_second: 4.697, interval_steps_per_second: 2.936, epoch: 4.0[0m
[32m[2022-09-15 17:01:33,251] [    INFO][0m - loss: 0.24513106, learning_rate: 2.85e-06, global_step: 50, interval_runtime: 3.4221, interval_samples_per_second: 4.676, interval_steps_per_second: 2.922, epoch: 5.0[0m
[32m[2022-09-15 17:01:36,668] [    INFO][0m - loss: 0.18188339, learning_rate: 2.82e-06, global_step: 60, interval_runtime: 3.4168, interval_samples_per_second: 4.683, interval_steps_per_second: 2.927, epoch: 6.0[0m
[32m[2022-09-15 17:01:40,080] [    INFO][0m - loss: 0.14436128, learning_rate: 2.7900000000000004e-06, global_step: 70, interval_runtime: 3.4124, interval_samples_per_second: 4.689, interval_steps_per_second: 2.93, epoch: 7.0[0m
[32m[2022-09-15 17:01:43,521] [    INFO][0m - loss: 0.10286493, learning_rate: 2.7600000000000003e-06, global_step: 80, interval_runtime: 3.4402, interval_samples_per_second: 4.651, interval_steps_per_second: 2.907, epoch: 8.0[0m
[32m[2022-09-15 17:01:46,961] [    INFO][0m - loss: 0.08694622, learning_rate: 2.73e-06, global_step: 90, interval_runtime: 3.4401, interval_samples_per_second: 4.651, interval_steps_per_second: 2.907, epoch: 9.0[0m
[32m[2022-09-15 17:01:50,414] [    INFO][0m - loss: 0.05454633, learning_rate: 2.7e-06, global_step: 100, interval_runtime: 3.4537, interval_samples_per_second: 4.633, interval_steps_per_second: 2.895, epoch: 10.0[0m
[32m[2022-09-15 17:01:53,855] [    INFO][0m - loss: 0.04449635, learning_rate: 2.6700000000000003e-06, global_step: 110, interval_runtime: 3.4411, interval_samples_per_second: 4.65, interval_steps_per_second: 2.906, epoch: 11.0[0m
[32m[2022-09-15 17:01:57,309] [    INFO][0m - loss: 0.0326607, learning_rate: 2.64e-06, global_step: 120, interval_runtime: 3.4536, interval_samples_per_second: 4.633, interval_steps_per_second: 2.896, epoch: 12.0[0m
[32m[2022-09-15 17:02:00,750] [    INFO][0m - loss: 0.03835067, learning_rate: 2.61e-06, global_step: 130, interval_runtime: 3.4406, interval_samples_per_second: 4.65, interval_steps_per_second: 2.906, epoch: 13.0[0m
[32m[2022-09-15 17:02:04,205] [    INFO][0m - loss: 0.00750341, learning_rate: 2.58e-06, global_step: 140, interval_runtime: 3.4554, interval_samples_per_second: 4.63, interval_steps_per_second: 2.894, epoch: 14.0[0m
[32m[2022-09-15 17:02:07,651] [    INFO][0m - loss: 0.00226768, learning_rate: 2.55e-06, global_step: 150, interval_runtime: 3.4463, interval_samples_per_second: 4.643, interval_steps_per_second: 2.902, epoch: 15.0[0m
[32m[2022-09-15 17:02:11,117] [    INFO][0m - loss: 0.00092956, learning_rate: 2.52e-06, global_step: 160, interval_runtime: 3.4657, interval_samples_per_second: 4.617, interval_steps_per_second: 2.885, epoch: 16.0[0m
[32m[2022-09-15 17:02:14,557] [    INFO][0m - loss: 0.00027191, learning_rate: 2.49e-06, global_step: 170, interval_runtime: 3.4402, interval_samples_per_second: 4.651, interval_steps_per_second: 2.907, epoch: 17.0[0m
[32m[2022-09-15 17:02:17,997] [    INFO][0m - loss: 0.0003123, learning_rate: 2.4599999999999997e-06, global_step: 180, interval_runtime: 3.4392, interval_samples_per_second: 4.652, interval_steps_per_second: 2.908, epoch: 18.0[0m
[32m[2022-09-15 17:02:21,433] [    INFO][0m - loss: 9.395e-05, learning_rate: 2.43e-06, global_step: 190, interval_runtime: 3.4359, interval_samples_per_second: 4.657, interval_steps_per_second: 2.91, epoch: 19.0[0m
[32m[2022-09-15 17:02:24,856] [    INFO][0m - loss: 8.82e-05, learning_rate: 2.4000000000000003e-06, global_step: 200, interval_runtime: 3.4232, interval_samples_per_second: 4.674, interval_steps_per_second: 2.921, epoch: 20.0[0m
[32m[2022-09-15 17:02:24,856] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-15 17:02:24,856] [    INFO][0m -   Num examples = 160[0m
[32m[2022-09-15 17:02:24,857] [    INFO][0m -   Pre device batch size = 16[0m
[32m[2022-09-15 17:02:24,857] [    INFO][0m -   Total Batch size = 16[0m
[32m[2022-09-15 17:02:24,857] [    INFO][0m -   Total prediction steps = 10[0m
[32m[2022-09-15 17:02:26,186] [    INFO][0m - eval_loss: 2.135694980621338, eval_accuracy: 0.7125, eval_runtime: 1.3293, eval_samples_per_second: 120.368, eval_steps_per_second: 7.523, epoch: 20.0[0m
[32m[2022-09-15 17:02:26,187] [    INFO][0m - Saving model checkpoint to ./checkpoints/checkpoint-200[0m
[32m[2022-09-15 17:02:26,187] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-15 17:02:28,962] [    INFO][0m - tokenizer config file saved in ./checkpoints/checkpoint-200/tokenizer_config.json[0m
[32m[2022-09-15 17:02:28,962] [    INFO][0m - Special tokens file saved in ./checkpoints/checkpoint-200/special_tokens_map.json[0m
[32m[2022-09-15 17:02:37,805] [    INFO][0m - loss: 0.00019859, learning_rate: 2.37e-06, global_step: 210, interval_runtime: 12.9489, interval_samples_per_second: 1.236, interval_steps_per_second: 0.772, epoch: 21.0[0m
[32m[2022-09-15 17:02:41,236] [    INFO][0m - loss: 0.00023846, learning_rate: 2.34e-06, global_step: 220, interval_runtime: 3.4313, interval_samples_per_second: 4.663, interval_steps_per_second: 2.914, epoch: 22.0[0m
[32m[2022-09-15 17:02:44,654] [    INFO][0m - loss: 0.00034028, learning_rate: 2.31e-06, global_step: 230, interval_runtime: 3.4177, interval_samples_per_second: 4.681, interval_steps_per_second: 2.926, epoch: 23.0[0m
[32m[2022-09-15 17:02:48,091] [    INFO][0m - loss: 7.767e-05, learning_rate: 2.28e-06, global_step: 240, interval_runtime: 3.4378, interval_samples_per_second: 4.654, interval_steps_per_second: 2.909, epoch: 24.0[0m
[32m[2022-09-15 17:02:51,517] [    INFO][0m - loss: 9.724e-05, learning_rate: 2.25e-06, global_step: 250, interval_runtime: 3.425, interval_samples_per_second: 4.672, interval_steps_per_second: 2.92, epoch: 25.0[0m
[32m[2022-09-15 17:02:54,957] [    INFO][0m - loss: 6.523e-05, learning_rate: 2.22e-06, global_step: 260, interval_runtime: 3.4402, interval_samples_per_second: 4.651, interval_steps_per_second: 2.907, epoch: 26.0[0m
[32m[2022-09-15 17:02:58,388] [    INFO][0m - loss: 8.589e-05, learning_rate: 2.19e-06, global_step: 270, interval_runtime: 3.4307, interval_samples_per_second: 4.664, interval_steps_per_second: 2.915, epoch: 27.0[0m
[32m[2022-09-15 17:03:01,823] [    INFO][0m - loss: 7.389e-05, learning_rate: 2.16e-06, global_step: 280, interval_runtime: 3.4354, interval_samples_per_second: 4.657, interval_steps_per_second: 2.911, epoch: 28.0[0m
[32m[2022-09-15 17:03:05,268] [    INFO][0m - loss: 8.4e-05, learning_rate: 2.13e-06, global_step: 290, interval_runtime: 3.4446, interval_samples_per_second: 4.645, interval_steps_per_second: 2.903, epoch: 29.0[0m
[32m[2022-09-15 17:03:08,708] [    INFO][0m - loss: 5.354e-05, learning_rate: 2.1e-06, global_step: 300, interval_runtime: 3.4405, interval_samples_per_second: 4.651, interval_steps_per_second: 2.907, epoch: 30.0[0m
[32m[2022-09-15 17:03:12,152] [    INFO][0m - loss: 4.075e-05, learning_rate: 2.07e-06, global_step: 310, interval_runtime: 3.4439, interval_samples_per_second: 4.646, interval_steps_per_second: 2.904, epoch: 31.0[0m
[32m[2022-09-15 17:03:15,595] [    INFO][0m - loss: 2.714e-05, learning_rate: 2.0400000000000004e-06, global_step: 320, interval_runtime: 3.4433, interval_samples_per_second: 4.647, interval_steps_per_second: 2.904, epoch: 32.0[0m
[32m[2022-09-15 17:03:19,048] [    INFO][0m - loss: 3.286e-05, learning_rate: 2.0100000000000002e-06, global_step: 330, interval_runtime: 3.4523, interval_samples_per_second: 4.635, interval_steps_per_second: 2.897, epoch: 33.0[0m
[32m[2022-09-15 17:03:22,490] [    INFO][0m - loss: 4.373e-05, learning_rate: 1.98e-06, global_step: 340, interval_runtime: 3.4425, interval_samples_per_second: 4.648, interval_steps_per_second: 2.905, epoch: 34.0[0m
[32m[2022-09-15 17:03:25,942] [    INFO][0m - loss: 7.944e-05, learning_rate: 1.95e-06, global_step: 350, interval_runtime: 3.4515, interval_samples_per_second: 4.636, interval_steps_per_second: 2.897, epoch: 35.0[0m
[32m[2022-09-15 17:03:29,384] [    INFO][0m - loss: 2.064e-05, learning_rate: 1.9200000000000003e-06, global_step: 360, interval_runtime: 3.4427, interval_samples_per_second: 4.648, interval_steps_per_second: 2.905, epoch: 36.0[0m
[32m[2022-09-15 17:03:32,840] [    INFO][0m - loss: 3.416e-05, learning_rate: 1.8900000000000001e-06, global_step: 370, interval_runtime: 3.4555, interval_samples_per_second: 4.63, interval_steps_per_second: 2.894, epoch: 37.0[0m
[32m[2022-09-15 17:03:36,280] [    INFO][0m - loss: 3.008e-05, learning_rate: 1.86e-06, global_step: 380, interval_runtime: 3.4397, interval_samples_per_second: 4.652, interval_steps_per_second: 2.907, epoch: 38.0[0m
[32m[2022-09-15 17:03:39,723] [    INFO][0m - loss: 2.041e-05, learning_rate: 1.83e-06, global_step: 390, interval_runtime: 3.4433, interval_samples_per_second: 4.647, interval_steps_per_second: 2.904, epoch: 39.0[0m
[32m[2022-09-15 17:03:43,172] [    INFO][0m - loss: 1.669e-05, learning_rate: 1.8e-06, global_step: 400, interval_runtime: 3.4495, interval_samples_per_second: 4.638, interval_steps_per_second: 2.899, epoch: 40.0[0m
[32m[2022-09-15 17:03:43,173] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-15 17:03:43,173] [    INFO][0m -   Num examples = 160[0m
[32m[2022-09-15 17:03:43,173] [    INFO][0m -   Pre device batch size = 16[0m
[32m[2022-09-15 17:03:43,173] [    INFO][0m -   Total Batch size = 16[0m
[32m[2022-09-15 17:03:43,173] [    INFO][0m -   Total prediction steps = 10[0m
[32m[2022-09-15 17:03:44,503] [    INFO][0m - eval_loss: 2.4722800254821777, eval_accuracy: 0.70625, eval_runtime: 1.3293, eval_samples_per_second: 120.365, eval_steps_per_second: 7.523, epoch: 40.0[0m
[32m[2022-09-15 17:03:44,503] [    INFO][0m - Saving model checkpoint to ./checkpoints/checkpoint-400[0m
[32m[2022-09-15 17:03:44,503] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-15 17:03:47,345] [    INFO][0m - tokenizer config file saved in ./checkpoints/checkpoint-400/tokenizer_config.json[0m
[32m[2022-09-15 17:03:47,346] [    INFO][0m - Special tokens file saved in ./checkpoints/checkpoint-400/special_tokens_map.json[0m
[32m[2022-09-15 17:03:56,330] [    INFO][0m - loss: 1.456e-05, learning_rate: 1.77e-06, global_step: 410, interval_runtime: 13.1572, interval_samples_per_second: 1.216, interval_steps_per_second: 0.76, epoch: 41.0[0m
[32m[2022-09-15 17:03:59,768] [    INFO][0m - loss: 3.677e-05, learning_rate: 1.7399999999999999e-06, global_step: 420, interval_runtime: 3.4387, interval_samples_per_second: 4.653, interval_steps_per_second: 2.908, epoch: 42.0[0m
[32m[2022-09-15 17:04:03,191] [    INFO][0m - loss: 1.351e-05, learning_rate: 1.71e-06, global_step: 430, interval_runtime: 3.423, interval_samples_per_second: 4.674, interval_steps_per_second: 2.921, epoch: 43.0[0m
[32m[2022-09-15 17:04:06,652] [    INFO][0m - loss: 2.767e-05, learning_rate: 1.6800000000000002e-06, global_step: 440, interval_runtime: 3.4605, interval_samples_per_second: 4.624, interval_steps_per_second: 2.89, epoch: 44.0[0m
[32m[2022-09-15 17:04:10,112] [    INFO][0m - loss: 1.758e-05, learning_rate: 1.65e-06, global_step: 450, interval_runtime: 3.4599, interval_samples_per_second: 4.624, interval_steps_per_second: 2.89, epoch: 45.0[0m
[32m[2022-09-15 17:04:13,586] [    INFO][0m - loss: 2.338e-05, learning_rate: 1.6200000000000002e-06, global_step: 460, interval_runtime: 3.4744, interval_samples_per_second: 4.605, interval_steps_per_second: 2.878, epoch: 46.0[0m
[32m[2022-09-15 17:04:17,041] [    INFO][0m - loss: 2.325e-05, learning_rate: 1.59e-06, global_step: 470, interval_runtime: 3.4551, interval_samples_per_second: 4.631, interval_steps_per_second: 2.894, epoch: 47.0[0m
[32m[2022-09-15 17:04:20,483] [    INFO][0m - loss: 1.131e-05, learning_rate: 1.56e-06, global_step: 480, interval_runtime: 3.4417, interval_samples_per_second: 4.649, interval_steps_per_second: 2.906, epoch: 48.0[0m
[32m[2022-09-15 17:04:25,378] [    INFO][0m - loss: 1.198e-05, learning_rate: 1.53e-06, global_step: 490, interval_runtime: 3.4672, interval_samples_per_second: 4.615, interval_steps_per_second: 2.884, epoch: 49.0[0m
[32m[2022-09-15 17:04:28,823] [    INFO][0m - loss: 1.645e-05, learning_rate: 1.5e-06, global_step: 500, interval_runtime: 4.8726, interval_samples_per_second: 3.284, interval_steps_per_second: 2.052, epoch: 50.0[0m
[32m[2022-09-15 17:04:32,266] [    INFO][0m - loss: 9.69e-06, learning_rate: 1.4700000000000001e-06, global_step: 510, interval_runtime: 3.4428, interval_samples_per_second: 4.647, interval_steps_per_second: 2.905, epoch: 51.0[0m
[32m[2022-09-15 17:04:35,700] [    INFO][0m - loss: 4.431e-05, learning_rate: 1.44e-06, global_step: 520, interval_runtime: 3.434, interval_samples_per_second: 4.659, interval_steps_per_second: 2.912, epoch: 52.0[0m
[32m[2022-09-15 17:04:39,152] [    INFO][0m - loss: 0.00013436, learning_rate: 1.41e-06, global_step: 530, interval_runtime: 3.4525, interval_samples_per_second: 4.634, interval_steps_per_second: 2.896, epoch: 53.0[0m
[32m[2022-09-15 17:04:43,743] [    INFO][0m - loss: 1.232e-05, learning_rate: 1.3800000000000001e-06, global_step: 540, interval_runtime: 3.4487, interval_samples_per_second: 4.639, interval_steps_per_second: 2.9, epoch: 54.0[0m
[32m[2022-09-15 17:04:47,193] [    INFO][0m - loss: 9.08e-06, learning_rate: 1.35e-06, global_step: 550, interval_runtime: 4.5915, interval_samples_per_second: 3.485, interval_steps_per_second: 2.178, epoch: 55.0[0m
[32m[2022-09-15 17:04:50,625] [    INFO][0m - loss: 1.076e-05, learning_rate: 1.32e-06, global_step: 560, interval_runtime: 3.4328, interval_samples_per_second: 4.661, interval_steps_per_second: 2.913, epoch: 56.0[0m
[32m[2022-09-15 17:04:54,077] [    INFO][0m - loss: 3.083e-05, learning_rate: 1.29e-06, global_step: 570, interval_runtime: 3.4518, interval_samples_per_second: 4.635, interval_steps_per_second: 2.897, epoch: 57.0[0m
[32m[2022-09-15 17:04:57,516] [    INFO][0m - loss: 9.69e-06, learning_rate: 1.26e-06, global_step: 580, interval_runtime: 3.4391, interval_samples_per_second: 4.652, interval_steps_per_second: 2.908, epoch: 58.0[0m
[32m[2022-09-15 17:05:00,967] [    INFO][0m - loss: 1.073e-05, learning_rate: 1.2299999999999999e-06, global_step: 590, interval_runtime: 3.4512, interval_samples_per_second: 4.636, interval_steps_per_second: 2.898, epoch: 59.0[0m
[32m[2022-09-15 17:05:04,411] [    INFO][0m - loss: 1.285e-05, learning_rate: 1.2000000000000002e-06, global_step: 600, interval_runtime: 3.4435, interval_samples_per_second: 4.646, interval_steps_per_second: 2.904, epoch: 60.0[0m
[32m[2022-09-15 17:05:04,411] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-15 17:05:04,412] [    INFO][0m -   Num examples = 160[0m
[32m[2022-09-15 17:05:04,412] [    INFO][0m -   Pre device batch size = 16[0m
[32m[2022-09-15 17:05:04,412] [    INFO][0m -   Total Batch size = 16[0m
[32m[2022-09-15 17:05:04,412] [    INFO][0m -   Total prediction steps = 10[0m
[32m[2022-09-15 17:05:05,735] [    INFO][0m - eval_loss: 2.648045778274536, eval_accuracy: 0.70625, eval_runtime: 1.3226, eval_samples_per_second: 120.978, eval_steps_per_second: 7.561, epoch: 60.0[0m
[32m[2022-09-15 17:05:05,735] [    INFO][0m - Saving model checkpoint to ./checkpoints/checkpoint-600[0m
[32m[2022-09-15 17:05:05,735] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-15 17:05:08,504] [    INFO][0m - tokenizer config file saved in ./checkpoints/checkpoint-600/tokenizer_config.json[0m
[32m[2022-09-15 17:05:08,504] [    INFO][0m - Special tokens file saved in ./checkpoints/checkpoint-600/special_tokens_map.json[0m
[32m[2022-09-15 17:05:17,326] [    INFO][0m - loss: 1.62e-05, learning_rate: 1.17e-06, global_step: 610, interval_runtime: 12.9154, interval_samples_per_second: 1.239, interval_steps_per_second: 0.774, epoch: 61.0[0m
[32m[2022-09-15 17:05:20,770] [    INFO][0m - loss: 1.369e-05, learning_rate: 1.14e-06, global_step: 620, interval_runtime: 3.444, interval_samples_per_second: 4.646, interval_steps_per_second: 2.904, epoch: 62.0[0m
[32m[2022-09-15 17:05:24,209] [    INFO][0m - loss: 1.058e-05, learning_rate: 1.11e-06, global_step: 630, interval_runtime: 3.4389, interval_samples_per_second: 4.653, interval_steps_per_second: 2.908, epoch: 63.0[0m
[32m[2022-09-15 17:05:27,678] [    INFO][0m - loss: 7.33e-06, learning_rate: 1.08e-06, global_step: 640, interval_runtime: 3.4684, interval_samples_per_second: 4.613, interval_steps_per_second: 2.883, epoch: 64.0[0m
[32m[2022-09-15 17:05:31,124] [    INFO][0m - loss: 1.684e-05, learning_rate: 1.05e-06, global_step: 650, interval_runtime: 3.4466, interval_samples_per_second: 4.642, interval_steps_per_second: 2.901, epoch: 65.0[0m
[32m[2022-09-15 17:05:34,594] [    INFO][0m - loss: 1.106e-05, learning_rate: 1.0200000000000002e-06, global_step: 660, interval_runtime: 3.4695, interval_samples_per_second: 4.612, interval_steps_per_second: 2.882, epoch: 66.0[0m
[32m[2022-09-15 17:05:38,041] [    INFO][0m - loss: 1.609e-05, learning_rate: 9.9e-07, global_step: 670, interval_runtime: 3.4468, interval_samples_per_second: 4.642, interval_steps_per_second: 2.901, epoch: 67.0[0m
[32m[2022-09-15 17:05:45,498] [    INFO][0m - loss: 6.76e-06, learning_rate: 9.600000000000001e-07, global_step: 680, interval_runtime: 3.4336, interval_samples_per_second: 4.66, interval_steps_per_second: 2.912, epoch: 68.0[0m
[32m[2022-09-15 17:05:48,949] [    INFO][0m - loss: 1.226e-05, learning_rate: 9.3e-07, global_step: 690, interval_runtime: 7.4748, interval_samples_per_second: 2.141, interval_steps_per_second: 1.338, epoch: 69.0[0m
[32m[2022-09-15 17:05:52,392] [    INFO][0m - loss: 8.53e-06, learning_rate: 9e-07, global_step: 700, interval_runtime: 3.4428, interval_samples_per_second: 4.647, interval_steps_per_second: 2.905, epoch: 70.0[0m
[32m[2022-09-15 17:05:55,847] [    INFO][0m - loss: 8.28e-06, learning_rate: 8.699999999999999e-07, global_step: 710, interval_runtime: 3.4553, interval_samples_per_second: 4.631, interval_steps_per_second: 2.894, epoch: 71.0[0m
[32m[2022-09-15 17:05:59,283] [    INFO][0m - loss: 9.58e-06, learning_rate: 8.400000000000001e-07, global_step: 720, interval_runtime: 3.4358, interval_samples_per_second: 4.657, interval_steps_per_second: 2.911, epoch: 72.0[0m
[32m[2022-09-15 17:06:02,740] [    INFO][0m - loss: 1.151e-05, learning_rate: 8.100000000000001e-07, global_step: 730, interval_runtime: 3.4573, interval_samples_per_second: 4.628, interval_steps_per_second: 2.892, epoch: 73.0[0m
[32m[2022-09-15 17:06:06,199] [    INFO][0m - loss: 3.144e-05, learning_rate: 7.8e-07, global_step: 740, interval_runtime: 3.4586, interval_samples_per_second: 4.626, interval_steps_per_second: 2.891, epoch: 74.0[0m
[32m[2022-09-15 17:06:09,650] [    INFO][0m - loss: 2.173e-05, learning_rate: 7.5e-07, global_step: 750, interval_runtime: 3.4511, interval_samples_per_second: 4.636, interval_steps_per_second: 2.898, epoch: 75.0[0m
[32m[2022-09-15 17:06:13,115] [    INFO][0m - loss: 6.18e-06, learning_rate: 7.2e-07, global_step: 760, interval_runtime: 3.4647, interval_samples_per_second: 4.618, interval_steps_per_second: 2.886, epoch: 76.0[0m
[32m[2022-09-15 17:06:16,560] [    INFO][0m - loss: 6.33e-06, learning_rate: 6.900000000000001e-07, global_step: 770, interval_runtime: 3.4445, interval_samples_per_second: 4.645, interval_steps_per_second: 2.903, epoch: 77.0[0m
[32m[2022-09-15 17:06:20,038] [    INFO][0m - loss: 3.236e-05, learning_rate: 6.6e-07, global_step: 780, interval_runtime: 3.4787, interval_samples_per_second: 4.599, interval_steps_per_second: 2.875, epoch: 78.0[0m
[32m[2022-09-15 17:06:23,480] [    INFO][0m - loss: 6.57e-06, learning_rate: 6.3e-07, global_step: 790, interval_runtime: 3.4423, interval_samples_per_second: 4.648, interval_steps_per_second: 2.905, epoch: 79.0[0m
[32m[2022-09-15 17:06:26,934] [    INFO][0m - loss: 1.122e-05, learning_rate: 6.000000000000001e-07, global_step: 800, interval_runtime: 3.454, interval_samples_per_second: 4.632, interval_steps_per_second: 2.895, epoch: 80.0[0m
[32m[2022-09-15 17:06:26,935] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-15 17:06:26,935] [    INFO][0m -   Num examples = 160[0m
[32m[2022-09-15 17:06:26,935] [    INFO][0m -   Pre device batch size = 16[0m
[32m[2022-09-15 17:06:26,935] [    INFO][0m -   Total Batch size = 16[0m
[32m[2022-09-15 17:06:26,935] [    INFO][0m -   Total prediction steps = 10[0m
[32m[2022-09-15 17:06:28,260] [    INFO][0m - eval_loss: 2.7111563682556152, eval_accuracy: 0.70625, eval_runtime: 1.3243, eval_samples_per_second: 120.82, eval_steps_per_second: 7.551, epoch: 80.0[0m
[32m[2022-09-15 17:06:28,260] [    INFO][0m - Saving model checkpoint to ./checkpoints/checkpoint-800[0m
[32m[2022-09-15 17:06:28,260] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-15 17:06:31,060] [    INFO][0m - tokenizer config file saved in ./checkpoints/checkpoint-800/tokenizer_config.json[0m
[32m[2022-09-15 17:06:31,060] [    INFO][0m - Special tokens file saved in ./checkpoints/checkpoint-800/special_tokens_map.json[0m
[32m[2022-09-15 17:06:39,898] [    INFO][0m - loss: 8.22e-06, learning_rate: 5.7e-07, global_step: 810, interval_runtime: 12.964, interval_samples_per_second: 1.234, interval_steps_per_second: 0.771, epoch: 81.0[0m
[32m[2022-09-15 17:06:43,360] [    INFO][0m - loss: 2.327e-05, learning_rate: 5.4e-07, global_step: 820, interval_runtime: 3.4616, interval_samples_per_second: 4.622, interval_steps_per_second: 2.889, epoch: 82.0[0m
[32m[2022-09-15 17:06:46,806] [    INFO][0m - loss: 1.957e-05, learning_rate: 5.100000000000001e-07, global_step: 830, interval_runtime: 3.4459, interval_samples_per_second: 4.643, interval_steps_per_second: 2.902, epoch: 83.0[0m
[32m[2022-09-15 17:06:50,243] [    INFO][0m - loss: 1.076e-05, learning_rate: 4.800000000000001e-07, global_step: 840, interval_runtime: 3.4367, interval_samples_per_second: 4.656, interval_steps_per_second: 2.91, epoch: 84.0[0m
[32m[2022-09-15 17:06:53,692] [    INFO][0m - loss: 1.325e-05, learning_rate: 4.5e-07, global_step: 850, interval_runtime: 3.4497, interval_samples_per_second: 4.638, interval_steps_per_second: 2.899, epoch: 85.0[0m
[32m[2022-09-15 17:06:57,135] [    INFO][0m - loss: 7.54e-06, learning_rate: 4.2000000000000006e-07, global_step: 860, interval_runtime: 3.4432, interval_samples_per_second: 4.647, interval_steps_per_second: 2.904, epoch: 86.0[0m
[32m[2022-09-15 17:07:00,588] [    INFO][0m - loss: 8.48e-06, learning_rate: 3.9e-07, global_step: 870, interval_runtime: 3.4524, interval_samples_per_second: 4.634, interval_steps_per_second: 2.897, epoch: 87.0[0m
[32m[2022-09-15 17:07:04,038] [    INFO][0m - loss: 9.53e-06, learning_rate: 3.6e-07, global_step: 880, interval_runtime: 3.4497, interval_samples_per_second: 4.638, interval_steps_per_second: 2.899, epoch: 88.0[0m
[32m[2022-09-15 17:07:07,496] [    INFO][0m - loss: 7.86e-06, learning_rate: 3.3e-07, global_step: 890, interval_runtime: 3.4581, interval_samples_per_second: 4.627, interval_steps_per_second: 2.892, epoch: 89.0[0m
[32m[2022-09-15 17:07:10,946] [    INFO][0m - loss: 7.8e-06, learning_rate: 3.0000000000000004e-07, global_step: 900, interval_runtime: 3.45, interval_samples_per_second: 4.638, interval_steps_per_second: 2.899, epoch: 90.0[0m
[32m[2022-09-15 17:07:14,400] [    INFO][0m - loss: 3.622e-05, learning_rate: 2.7e-07, global_step: 910, interval_runtime: 3.4541, interval_samples_per_second: 4.632, interval_steps_per_second: 2.895, epoch: 91.0[0m
[32m[2022-09-15 17:07:17,856] [    INFO][0m - loss: 4.67e-06, learning_rate: 2.4000000000000003e-07, global_step: 920, interval_runtime: 3.4562, interval_samples_per_second: 4.629, interval_steps_per_second: 2.893, epoch: 92.0[0m
[32m[2022-09-15 17:07:21,299] [    INFO][0m - loss: 5.31e-06, learning_rate: 2.1000000000000003e-07, global_step: 930, interval_runtime: 3.4429, interval_samples_per_second: 4.647, interval_steps_per_second: 2.905, epoch: 93.0[0m
[32m[2022-09-15 17:07:24,756] [    INFO][0m - loss: 6.23e-06, learning_rate: 1.8e-07, global_step: 940, interval_runtime: 3.4574, interval_samples_per_second: 4.628, interval_steps_per_second: 2.892, epoch: 94.0[0m
[32m[2022-09-15 17:07:28,218] [    INFO][0m - loss: 1.302e-05, learning_rate: 1.5000000000000002e-07, global_step: 950, interval_runtime: 3.4621, interval_samples_per_second: 4.622, interval_steps_per_second: 2.888, epoch: 95.0[0m
[32m[2022-09-15 17:07:31,673] [    INFO][0m - loss: 8.04e-06, learning_rate: 1.2000000000000002e-07, global_step: 960, interval_runtime: 3.4551, interval_samples_per_second: 4.631, interval_steps_per_second: 2.894, epoch: 96.0[0m
[32m[2022-09-15 17:07:35,108] [    INFO][0m - loss: 9.65e-06, learning_rate: 9e-08, global_step: 970, interval_runtime: 3.4349, interval_samples_per_second: 4.658, interval_steps_per_second: 2.911, epoch: 97.0[0m
[32m[2022-09-15 17:07:38,563] [    INFO][0m - loss: 9.13e-06, learning_rate: 6.000000000000001e-08, global_step: 980, interval_runtime: 3.4542, interval_samples_per_second: 4.632, interval_steps_per_second: 2.895, epoch: 98.0[0m
[32m[2022-09-15 17:07:41,998] [    INFO][0m - loss: 6.4e-06, learning_rate: 3.0000000000000004e-08, global_step: 990, interval_runtime: 3.4352, interval_samples_per_second: 4.658, interval_steps_per_second: 2.911, epoch: 99.0[0m
[32m[2022-09-15 17:07:45,455] [    INFO][0m - loss: 0.02044553, learning_rate: 0.0, global_step: 1000, interval_runtime: 3.4572, interval_samples_per_second: 4.628, interval_steps_per_second: 2.893, epoch: 100.0[0m
[32m[2022-09-15 17:07:45,456] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-15 17:07:45,456] [    INFO][0m -   Num examples = 160[0m
[32m[2022-09-15 17:07:45,456] [    INFO][0m -   Pre device batch size = 16[0m
[32m[2022-09-15 17:07:45,456] [    INFO][0m -   Total Batch size = 16[0m
[32m[2022-09-15 17:07:45,456] [    INFO][0m -   Total prediction steps = 10[0m
[32m[2022-09-15 17:07:46,779] [    INFO][0m - eval_loss: 2.719600200653076, eval_accuracy: 0.7125, eval_runtime: 1.3222, eval_samples_per_second: 121.008, eval_steps_per_second: 7.563, epoch: 100.0[0m
[32m[2022-09-15 17:07:46,779] [    INFO][0m - Saving model checkpoint to ./checkpoints/checkpoint-1000[0m
[32m[2022-09-15 17:07:46,779] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-15 17:07:49,584] [    INFO][0m - tokenizer config file saved in ./checkpoints/checkpoint-1000/tokenizer_config.json[0m
[32m[2022-09-15 17:07:49,585] [    INFO][0m - Special tokens file saved in ./checkpoints/checkpoint-1000/special_tokens_map.json[0m
[32m[2022-09-15 17:07:55,021] [    INFO][0m - 
Training completed. 
[0m
[32m[2022-09-15 17:07:55,021] [    INFO][0m - Loading best model from ./checkpoints/checkpoint-200 (score: 0.7125).[0m
[32m[2022-09-15 17:07:56,772] [    INFO][0m - train_runtime: 401.8006, train_samples_per_second: 39.821, train_steps_per_second: 2.489, train_loss: 0.029332938681647647, epoch: 100.0[0m
[32m[2022-09-15 17:07:56,774] [    INFO][0m - Saving model checkpoint to ./checkpoints/[0m
[32m[2022-09-15 17:07:56,774] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-15 17:07:59,438] [    INFO][0m - tokenizer config file saved in ./checkpoints/tokenizer_config.json[0m
[32m[2022-09-15 17:07:59,439] [    INFO][0m - Special tokens file saved in ./checkpoints/special_tokens_map.json[0m
[32m[2022-09-15 17:07:59,440] [    INFO][0m - ***** train metrics *****[0m
[32m[2022-09-15 17:07:59,440] [    INFO][0m -   epoch                    =      100.0[0m
[32m[2022-09-15 17:07:59,440] [    INFO][0m -   train_loss               =     0.0293[0m
[32m[2022-09-15 17:07:59,440] [    INFO][0m -   train_runtime            = 0:06:41.80[0m
[32m[2022-09-15 17:07:59,440] [    INFO][0m -   train_samples_per_second =     39.821[0m
[32m[2022-09-15 17:07:59,440] [    INFO][0m -   train_steps_per_second   =      2.489[0m
[32m[2022-09-15 17:07:59,445] [    INFO][0m - ***** Running Prediction *****[0m
[32m[2022-09-15 17:07:59,445] [    INFO][0m -   Num examples = 2520[0m
[32m[2022-09-15 17:07:59,445] [    INFO][0m -   Pre device batch size = 16[0m
[32m[2022-09-15 17:07:59,445] [    INFO][0m -   Total Batch size = 16[0m
[32m[2022-09-15 17:07:59,445] [    INFO][0m -   Total prediction steps = 158[0m
[32m[2022-09-15 17:08:20,989] [    INFO][0m - ***** test metrics *****[0m
[32m[2022-09-15 17:08:20,989] [    INFO][0m -   test_accuracy           =     0.7512[0m
[32m[2022-09-15 17:08:20,990] [    INFO][0m -   test_loss               =     1.7191[0m
[32m[2022-09-15 17:08:20,990] [    INFO][0m -   test_runtime            = 0:00:21.54[0m
[32m[2022-09-15 17:08:20,990] [    INFO][0m -   test_samples_per_second =    116.969[0m
[32m[2022-09-15 17:08:20,990] [    INFO][0m -   test_steps_per_second   =      7.334[0m
[32m[2022-09-15 17:08:20,990] [    INFO][0m - ***** Running Prediction *****[0m
[32m[2022-09-15 17:08:20,990] [    INFO][0m -   Num examples = 3000[0m
[32m[2022-09-15 17:08:20,990] [    INFO][0m -   Pre device batch size = 16[0m
[32m[2022-09-15 17:08:20,990] [    INFO][0m -   Total Batch size = 16[0m
[32m[2022-09-15 17:08:20,990] [    INFO][0m -   Total prediction steps = 188[0m
[32m[2022-09-15 17:08:49,209] [    INFO][0m - Predictions for ocnlif saved to ./fewclue_submit_examples.[0m
{
  "labels": 2,
  "text_a": "\u4e03\u4e94\u671f\u95f4\u5f00\u59cb,\u56fd\u5bb6\u53c8\u6295\u8d44\u5c06\u6b66\u6c49\u5e02\u533a\u7684\u90e8\u5206\u571f\u5824\u6539\u5efa\u4e3a\u94a2\u7b4b\u6ce5\u51dd\u571f\u9632\u6c34\u5899",
  "text_b": "\u516b\u4e94\u671f\u95f4\u4f1a\u628a\u5269\u4e0b\u7684\u571f\u5824\u90fd\u6539\u5efa\u5b8c",
  "uid": 0
}

