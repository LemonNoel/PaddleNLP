[33m[2022-09-05 12:55:34,966] [ WARNING][0m - evaluation_strategy reset to IntervalStrategy.STEPS for do_eval is True. you can also set evaluation_strategy='epoch'.[0m
[32m[2022-09-05 12:55:34,967] [    INFO][0m - The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).[0m
[32m[2022-09-05 12:55:34,967] [    INFO][0m - ============================================================[0m
[32m[2022-09-05 12:55:34,967] [    INFO][0m -      Model Configuration Arguments      [0m
[32m[2022-09-05 12:55:34,967] [    INFO][0m - paddle commit id              :65f388690048d0965ec7d3b43fb6ee9d8c6dee7c[0m
[32m[2022-09-05 12:55:34,967] [    INFO][0m - do_save                       :True[0m
[32m[2022-09-05 12:55:34,967] [    INFO][0m - do_test                       :True[0m
[32m[2022-09-05 12:55:34,967] [    INFO][0m - early_stop_patience           :4[0m
[32m[2022-09-05 12:55:34,967] [    INFO][0m - export_type                   :paddle[0m
[32m[2022-09-05 12:55:34,968] [    INFO][0m - model_name_or_path            :ernie-3.0-base-zh[0m
[32m[2022-09-05 12:55:34,968] [    INFO][0m - [0m
[32m[2022-09-05 12:55:34,968] [    INFO][0m - ============================================================[0m
[32m[2022-09-05 12:55:34,968] [    INFO][0m -       Data Configuration Arguments      [0m
[32m[2022-09-05 12:55:34,968] [    INFO][0m - paddle commit id              :65f388690048d0965ec7d3b43fb6ee9d8c6dee7c[0m
[32m[2022-09-05 12:55:34,968] [    INFO][0m - encoder_hidden_size           :200[0m
[32m[2022-09-05 12:55:34,968] [    INFO][0m - prompt                        :[0m
[32m[2022-09-05 12:55:34,968] [    INFO][0m - soft_encoder                  :lstm[0m
[32m[2022-09-05 12:55:34,968] [    INFO][0m - split_id                      :few_all[0m
[32m[2022-09-05 12:55:34,968] [    INFO][0m - task_name                     :chid[0m
[32m[2022-09-05 12:55:34,968] [    INFO][0m - [0m
[32m[2022-09-05 12:55:34,969] [    INFO][0m - Already cached /ssd2/wanghuijuan03/.paddlenlp/models/ernie-3.0-base-zh/ernie_3.0_base_zh.pdparams[0m
W0905 12:55:34.970021 66486 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2
W0905 12:55:34.974025 66486 gpu_resources.cc:91] device: 0, cuDNN Version: 8.1.
[32m[2022-09-05 12:55:41,020] [    INFO][0m - Already cached /ssd2/wanghuijuan03/.paddlenlp/models/ernie-3.0-base-zh/ernie_3.0_base_zh_vocab.txt[0m
[32m[2022-09-05 12:55:41,045] [    INFO][0m - tokenizer config file saved in /ssd2/wanghuijuan03/.paddlenlp/models/ernie-3.0-base-zh/tokenizer_config.json[0m
[32m[2022-09-05 12:55:41,045] [    INFO][0m - Special tokens file saved in /ssd2/wanghuijuan03/.paddlenlp/models/ernie-3.0-base-zh/special_tokens_map.json[0m
[32m[2022-09-05 12:55:41,046] [    INFO][0m - Using template: [{'add_prefix_space': '', 'text': 'text_a'}, {'add_prefix_space': '', 'sep': None}, {'add_prefix_space': '', 'hard': 'ËøôÂè•ËØù‰∏≠ÁöÑÊàêËØ≠‰ΩøÁî®'}, {'add_prefix_space': '', 'mask': None}, {'add_prefix_space': '', 'mask': None}][0m
2022-09-05 12:55:41,050 INFO [download.py:119] unique_endpoints {''}
[32m[2022-09-05 12:55:41,344] [    INFO][0m - ============================================================[0m
[32m[2022-09-05 12:55:41,344] [    INFO][0m -     Training Configuration Arguments    [0m
[32m[2022-09-05 12:55:41,344] [    INFO][0m - paddle commit id              :65f388690048d0965ec7d3b43fb6ee9d8c6dee7c[0m
[32m[2022-09-05 12:55:41,344] [    INFO][0m - _no_sync_in_gradient_accumulation:True[0m
[32m[2022-09-05 12:55:41,345] [    INFO][0m - adam_beta1                    :0.9[0m
[32m[2022-09-05 12:55:41,345] [    INFO][0m - adam_beta2                    :0.999[0m
[32m[2022-09-05 12:55:41,345] [    INFO][0m - adam_epsilon                  :1e-08[0m
[32m[2022-09-05 12:55:41,345] [    INFO][0m - alpha_rdrop                   :5.0[0m
[32m[2022-09-05 12:55:41,345] [    INFO][0m - alpha_rgl                     :0.5[0m
[32m[2022-09-05 12:55:41,345] [    INFO][0m - current_device                :gpu:0[0m
[32m[2022-09-05 12:55:41,345] [    INFO][0m - dataloader_drop_last          :False[0m
[32m[2022-09-05 12:55:41,345] [    INFO][0m - dataloader_num_workers        :0[0m
[32m[2022-09-05 12:55:41,345] [    INFO][0m - device                        :gpu[0m
[32m[2022-09-05 12:55:41,345] [    INFO][0m - disable_tqdm                  :True[0m
[32m[2022-09-05 12:55:41,345] [    INFO][0m - do_eval                       :True[0m
[32m[2022-09-05 12:55:41,345] [    INFO][0m - do_export                     :False[0m
[32m[2022-09-05 12:55:41,346] [    INFO][0m - do_predict                    :False[0m
[32m[2022-09-05 12:55:41,346] [    INFO][0m - do_train                      :True[0m
[32m[2022-09-05 12:55:41,346] [    INFO][0m - eval_batch_size               :8[0m
[32m[2022-09-05 12:55:41,346] [    INFO][0m - eval_steps                    :100[0m
[32m[2022-09-05 12:55:41,346] [    INFO][0m - evaluation_strategy           :IntervalStrategy.STEPS[0m
[32m[2022-09-05 12:55:41,346] [    INFO][0m - first_max_length              :None[0m
[32m[2022-09-05 12:55:41,346] [    INFO][0m - fp16                          :False[0m
[32m[2022-09-05 12:55:41,346] [    INFO][0m - fp16_opt_level                :O1[0m
[32m[2022-09-05 12:55:41,346] [    INFO][0m - freeze_dropout                :False[0m
[32m[2022-09-05 12:55:41,346] [    INFO][0m - freeze_plm                    :False[0m
[32m[2022-09-05 12:55:41,346] [    INFO][0m - gradient_accumulation_steps   :1[0m
[32m[2022-09-05 12:55:41,346] [    INFO][0m - greater_is_better             :True[0m
[32m[2022-09-05 12:55:41,346] [    INFO][0m - ignore_data_skip              :False[0m
[32m[2022-09-05 12:55:41,347] [    INFO][0m - label_names                   :None[0m
[32m[2022-09-05 12:55:41,347] [    INFO][0m - learning_rate                 :1e-05[0m
[32m[2022-09-05 12:55:41,347] [    INFO][0m - load_best_model_at_end        :True[0m
[32m[2022-09-05 12:55:41,347] [    INFO][0m - local_process_index           :0[0m
[32m[2022-09-05 12:55:41,347] [    INFO][0m - local_rank                    :-1[0m
[32m[2022-09-05 12:55:41,347] [    INFO][0m - log_level                     :-1[0m
[32m[2022-09-05 12:55:41,347] [    INFO][0m - log_level_replica             :-1[0m
[32m[2022-09-05 12:55:41,347] [    INFO][0m - log_on_each_node              :True[0m
[32m[2022-09-05 12:55:41,347] [    INFO][0m - logging_dir                   :./checkpoints_chid/runs/Sep05_12-55-34_instance-3bwob41y-01[0m
[32m[2022-09-05 12:55:41,347] [    INFO][0m - logging_first_step            :False[0m
[32m[2022-09-05 12:55:41,347] [    INFO][0m - logging_steps                 :10[0m
[32m[2022-09-05 12:55:41,347] [    INFO][0m - logging_strategy              :IntervalStrategy.STEPS[0m
[32m[2022-09-05 12:55:41,347] [    INFO][0m - lr_scheduler_type             :SchedulerType.LINEAR[0m
[32m[2022-09-05 12:55:41,348] [    INFO][0m - max_grad_norm                 :1.0[0m
[32m[2022-09-05 12:55:41,348] [    INFO][0m - max_seq_length                :256[0m
[32m[2022-09-05 12:55:41,348] [    INFO][0m - max_steps                     :-1[0m
[32m[2022-09-05 12:55:41,348] [    INFO][0m - metric_for_best_model         :accuracy[0m
[32m[2022-09-05 12:55:41,348] [    INFO][0m - minimum_eval_times            :None[0m
[32m[2022-09-05 12:55:41,348] [    INFO][0m - no_cuda                       :False[0m
[32m[2022-09-05 12:55:41,348] [    INFO][0m - num_train_epochs              :50.0[0m
[32m[2022-09-05 12:55:41,348] [    INFO][0m - optim                         :OptimizerNames.ADAMW[0m
[32m[2022-09-05 12:55:41,348] [    INFO][0m - other_max_length              :None[0m
[32m[2022-09-05 12:55:41,348] [    INFO][0m - output_dir                    :./checkpoints_chid/[0m
[32m[2022-09-05 12:55:41,348] [    INFO][0m - overwrite_output_dir          :False[0m
[32m[2022-09-05 12:55:41,348] [    INFO][0m - past_index                    :-1[0m
[32m[2022-09-05 12:55:41,348] [    INFO][0m - per_device_eval_batch_size    :8[0m
[32m[2022-09-05 12:55:41,348] [    INFO][0m - per_device_train_batch_size   :8[0m
[32m[2022-09-05 12:55:41,349] [    INFO][0m - ppt_adam_beta1                :0.9[0m
[32m[2022-09-05 12:55:41,349] [    INFO][0m - ppt_adam_beta2                :0.999[0m
[32m[2022-09-05 12:55:41,349] [    INFO][0m - ppt_adam_epsilon              :1e-08[0m
[32m[2022-09-05 12:55:41,349] [    INFO][0m - ppt_learning_rate             :1e-05[0m
[32m[2022-09-05 12:55:41,349] [    INFO][0m - ppt_weight_decay              :0.0[0m
[32m[2022-09-05 12:55:41,349] [    INFO][0m - prediction_loss_only          :False[0m
[32m[2022-09-05 12:55:41,349] [    INFO][0m - process_index                 :0[0m
[32m[2022-09-05 12:55:41,349] [    INFO][0m - remove_unused_columns         :True[0m
[32m[2022-09-05 12:55:41,349] [    INFO][0m - report_to                     :['visualdl'][0m
[32m[2022-09-05 12:55:41,349] [    INFO][0m - resume_from_checkpoint        :None[0m
[32m[2022-09-05 12:55:41,349] [    INFO][0m - run_name                      :./checkpoints_chid/[0m
[32m[2022-09-05 12:55:41,349] [    INFO][0m - save_on_each_node             :False[0m
[32m[2022-09-05 12:55:41,349] [    INFO][0m - save_steps                    :100[0m
[32m[2022-09-05 12:55:41,350] [    INFO][0m - save_strategy                 :IntervalStrategy.STEPS[0m
[32m[2022-09-05 12:55:41,350] [    INFO][0m - save_total_limit              :None[0m
[32m[2022-09-05 12:55:41,350] [    INFO][0m - scale_loss                    :32768[0m
[32m[2022-09-05 12:55:41,350] [    INFO][0m - seed                          :42[0m
[32m[2022-09-05 12:55:41,350] [    INFO][0m - should_log                    :True[0m
[32m[2022-09-05 12:55:41,350] [    INFO][0m - should_save                   :True[0m
[32m[2022-09-05 12:55:41,350] [    INFO][0m - task_type                     :multi-class[0m
[32m[2022-09-05 12:55:41,350] [    INFO][0m - train_batch_size              :8[0m
[32m[2022-09-05 12:55:41,350] [    INFO][0m - truncate_mode                 :tail[0m
[32m[2022-09-05 12:55:41,350] [    INFO][0m - use_rdrop                     :False[0m
[32m[2022-09-05 12:55:41,350] [    INFO][0m - use_rgl                       :False[0m
[32m[2022-09-05 12:55:41,350] [    INFO][0m - warmup_ratio                  :0.0[0m
[32m[2022-09-05 12:55:41,350] [    INFO][0m - warmup_steps                  :0[0m
[32m[2022-09-05 12:55:41,351] [    INFO][0m - weight_decay                  :0.0[0m
[32m[2022-09-05 12:55:41,351] [    INFO][0m - world_size                    :1[0m
[32m[2022-09-05 12:55:41,351] [    INFO][0m - [0m
[32m[2022-09-05 12:55:41,352] [    INFO][0m - ***** Running training *****[0m
[32m[2022-09-05 12:55:41,352] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 12:55:41,352] [    INFO][0m -   Num Epochs = 50[0m
[32m[2022-09-05 12:55:41,352] [    INFO][0m -   Instantaneous batch size per device = 8[0m
[32m[2022-09-05 12:55:41,353] [    INFO][0m -   Total train batch size (w. parallel, distributed & accumulation) = 8[0m
[32m[2022-09-05 12:55:41,353] [    INFO][0m -   Gradient Accumulation steps = 1[0m
[32m[2022-09-05 12:55:41,353] [    INFO][0m -   Total optimization steps = 8850.0[0m
[32m[2022-09-05 12:55:41,353] [    INFO][0m -   Total num train samples = 70700[0m
[32m[2022-09-05 12:55:44,109] [    INFO][0m - loss: 5.04105568, learning_rate: 9.988700564971753e-06, global_step: 10, interval_runtime: 2.7549, interval_samples_per_second: 2.904, interval_steps_per_second: 3.63, epoch: 0.0565[0m
[32m[2022-09-05 12:55:45,592] [    INFO][0m - loss: 0.88348875, learning_rate: 9.977401129943504e-06, global_step: 20, interval_runtime: 1.4832, interval_samples_per_second: 5.394, interval_steps_per_second: 6.742, epoch: 0.113[0m
[32m[2022-09-05 12:55:47,077] [    INFO][0m - loss: 0.59678407, learning_rate: 9.966101694915256e-06, global_step: 30, interval_runtime: 1.4851, interval_samples_per_second: 5.387, interval_steps_per_second: 6.734, epoch: 0.1695[0m
[32m[2022-09-05 12:55:48,563] [    INFO][0m - loss: 0.58862023, learning_rate: 9.954802259887007e-06, global_step: 40, interval_runtime: 1.4864, interval_samples_per_second: 5.382, interval_steps_per_second: 6.727, epoch: 0.226[0m
[32m[2022-09-05 12:55:50,220] [    INFO][0m - loss: 0.43213692, learning_rate: 9.943502824858759e-06, global_step: 50, interval_runtime: 1.4869, interval_samples_per_second: 5.38, interval_steps_per_second: 6.725, epoch: 0.2825[0m
[32m[2022-09-05 12:55:51,705] [    INFO][0m - loss: 0.27448006, learning_rate: 9.93220338983051e-06, global_step: 60, interval_runtime: 1.6545, interval_samples_per_second: 4.835, interval_steps_per_second: 6.044, epoch: 0.339[0m
[32m[2022-09-05 12:55:53,192] [    INFO][0m - loss: 0.89736786, learning_rate: 9.92090395480226e-06, global_step: 70, interval_runtime: 1.4876, interval_samples_per_second: 5.378, interval_steps_per_second: 6.722, epoch: 0.3955[0m
[32m[2022-09-05 12:55:54,684] [    INFO][0m - loss: 0.69651885, learning_rate: 9.909604519774013e-06, global_step: 80, interval_runtime: 1.4915, interval_samples_per_second: 5.364, interval_steps_per_second: 6.705, epoch: 0.452[0m
[32m[2022-09-05 12:55:56,168] [    INFO][0m - loss: 0.53123441, learning_rate: 9.898305084745763e-06, global_step: 90, interval_runtime: 1.4842, interval_samples_per_second: 5.39, interval_steps_per_second: 6.738, epoch: 0.5085[0m
[32m[2022-09-05 12:55:57,653] [    INFO][0m - loss: 0.43761106, learning_rate: 9.887005649717516e-06, global_step: 100, interval_runtime: 1.4855, interval_samples_per_second: 5.386, interval_steps_per_second: 6.732, epoch: 0.565[0m
[32m[2022-09-05 12:55:57,654] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 12:55:57,654] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 12:55:57,654] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 12:55:57,654] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 12:55:57,655] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 12:56:09,619] [    INFO][0m - eval_loss: 0.44465699791908264, eval_accuracy: 0.13861386138613863, eval_runtime: 11.964, eval_samples_per_second: 118.188, eval_steps_per_second: 14.794, epoch: 0.565[0m
[32m[2022-09-05 12:56:09,662] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-100[0m
[32m[2022-09-05 12:56:09,662] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 12:56:14,085] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-100/tokenizer_config.json[0m
[32m[2022-09-05 12:56:14,085] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-100/special_tokens_map.json[0m
[32m[2022-09-05 12:56:21,030] [    INFO][0m - loss: 0.47870545, learning_rate: 9.875706214689266e-06, global_step: 110, interval_runtime: 23.3759, interval_samples_per_second: 0.342, interval_steps_per_second: 0.428, epoch: 0.6215[0m
[32m[2022-09-05 12:56:22,513] [    INFO][0m - loss: 0.40551772, learning_rate: 9.864406779661017e-06, global_step: 120, interval_runtime: 1.4828, interval_samples_per_second: 5.395, interval_steps_per_second: 6.744, epoch: 0.678[0m
[32m[2022-09-05 12:56:23,999] [    INFO][0m - loss: 0.62542768, learning_rate: 9.85310734463277e-06, global_step: 130, interval_runtime: 1.4872, interval_samples_per_second: 5.379, interval_steps_per_second: 6.724, epoch: 0.7345[0m
[32m[2022-09-05 12:56:25,481] [    INFO][0m - loss: 0.53814726, learning_rate: 9.84180790960452e-06, global_step: 140, interval_runtime: 1.4816, interval_samples_per_second: 5.4, interval_steps_per_second: 6.749, epoch: 0.791[0m
[32m[2022-09-05 12:56:26,965] [    INFO][0m - loss: 0.59579782, learning_rate: 9.830508474576272e-06, global_step: 150, interval_runtime: 1.4839, interval_samples_per_second: 5.391, interval_steps_per_second: 6.739, epoch: 0.8475[0m
[32m[2022-09-05 12:56:28,450] [    INFO][0m - loss: 0.47150183, learning_rate: 9.819209039548023e-06, global_step: 160, interval_runtime: 1.4848, interval_samples_per_second: 5.388, interval_steps_per_second: 6.735, epoch: 0.904[0m
[32m[2022-09-05 12:56:29,933] [    INFO][0m - loss: 0.4488019, learning_rate: 9.807909604519775e-06, global_step: 170, interval_runtime: 1.4839, interval_samples_per_second: 5.391, interval_steps_per_second: 6.739, epoch: 0.9605[0m
[32m[2022-09-05 12:56:31,442] [    INFO][0m - loss: 0.47392521, learning_rate: 9.796610169491526e-06, global_step: 180, interval_runtime: 1.509, interval_samples_per_second: 5.302, interval_steps_per_second: 6.627, epoch: 1.0169[0m
[32m[2022-09-05 12:56:32,932] [    INFO][0m - loss: 0.51510801, learning_rate: 9.785310734463278e-06, global_step: 190, interval_runtime: 1.4893, interval_samples_per_second: 5.372, interval_steps_per_second: 6.714, epoch: 1.0734[0m
[32m[2022-09-05 12:56:34,418] [    INFO][0m - loss: 0.4242383, learning_rate: 9.774011299435029e-06, global_step: 200, interval_runtime: 1.4867, interval_samples_per_second: 5.381, interval_steps_per_second: 6.726, epoch: 1.1299[0m
[32m[2022-09-05 12:56:34,419] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 12:56:34,419] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 12:56:34,419] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 12:56:34,419] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 12:56:34,419] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 12:56:46,555] [    INFO][0m - eval_loss: 0.4149458408355713, eval_accuracy: 0.09405940594059406, eval_runtime: 12.1351, eval_samples_per_second: 116.521, eval_steps_per_second: 14.586, epoch: 1.1299[0m
[32m[2022-09-05 12:56:46,615] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-200[0m
[32m[2022-09-05 12:56:46,615] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 12:56:50,110] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-200/tokenizer_config.json[0m
[32m[2022-09-05 12:56:50,110] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-200/special_tokens_map.json[0m
[32m[2022-09-05 12:56:58,287] [    INFO][0m - loss: 0.38080652, learning_rate: 9.762711864406781e-06, global_step: 210, interval_runtime: 23.8683, interval_samples_per_second: 0.335, interval_steps_per_second: 0.419, epoch: 1.1864[0m
[32m[2022-09-05 12:56:59,777] [    INFO][0m - loss: 0.65362511, learning_rate: 9.751412429378532e-06, global_step: 220, interval_runtime: 1.4899, interval_samples_per_second: 5.369, interval_steps_per_second: 6.712, epoch: 1.2429[0m
[32m[2022-09-05 12:57:01,267] [    INFO][0m - loss: 0.47600217, learning_rate: 9.740112994350284e-06, global_step: 230, interval_runtime: 1.49, interval_samples_per_second: 5.369, interval_steps_per_second: 6.711, epoch: 1.2994[0m
[32m[2022-09-05 12:57:02,751] [    INFO][0m - loss: 0.46359177, learning_rate: 9.728813559322035e-06, global_step: 240, interval_runtime: 1.4842, interval_samples_per_second: 5.39, interval_steps_per_second: 6.737, epoch: 1.3559[0m
[32m[2022-09-05 12:57:04,236] [    INFO][0m - loss: 0.31637487, learning_rate: 9.717514124293787e-06, global_step: 250, interval_runtime: 1.4848, interval_samples_per_second: 5.388, interval_steps_per_second: 6.735, epoch: 1.4124[0m
[32m[2022-09-05 12:57:05,719] [    INFO][0m - loss: 0.64451733, learning_rate: 9.706214689265538e-06, global_step: 260, interval_runtime: 1.4839, interval_samples_per_second: 5.391, interval_steps_per_second: 6.739, epoch: 1.4689[0m
[32m[2022-09-05 12:57:07,206] [    INFO][0m - loss: 0.42514644, learning_rate: 9.69491525423729e-06, global_step: 270, interval_runtime: 1.4859, interval_samples_per_second: 5.384, interval_steps_per_second: 6.73, epoch: 1.5254[0m
[32m[2022-09-05 12:57:08,689] [    INFO][0m - loss: 0.48317847, learning_rate: 9.68361581920904e-06, global_step: 280, interval_runtime: 1.4833, interval_samples_per_second: 5.393, interval_steps_per_second: 6.742, epoch: 1.5819[0m
[32m[2022-09-05 12:57:10,172] [    INFO][0m - loss: 0.3547931, learning_rate: 9.672316384180791e-06, global_step: 290, interval_runtime: 1.4837, interval_samples_per_second: 5.392, interval_steps_per_second: 6.74, epoch: 1.6384[0m
[32m[2022-09-05 12:57:11,655] [    INFO][0m - loss: 0.66957483, learning_rate: 9.661016949152544e-06, global_step: 300, interval_runtime: 1.4823, interval_samples_per_second: 5.397, interval_steps_per_second: 6.746, epoch: 1.6949[0m
[32m[2022-09-05 12:57:11,655] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 12:57:11,656] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 12:57:11,656] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 12:57:11,656] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 12:57:11,656] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 12:57:23,338] [    INFO][0m - eval_loss: 0.4486635625362396, eval_accuracy: 0.2079207920792079, eval_runtime: 11.6815, eval_samples_per_second: 121.046, eval_steps_per_second: 15.152, epoch: 1.6949[0m
[32m[2022-09-05 12:57:23,390] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-300[0m
[32m[2022-09-05 12:57:23,390] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 12:57:26,853] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-300/tokenizer_config.json[0m
[32m[2022-09-05 12:57:26,853] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-300/special_tokens_map.json[0m
[32m[2022-09-05 12:57:35,409] [    INFO][0m - loss: 0.42030883, learning_rate: 9.649717514124294e-06, global_step: 310, interval_runtime: 22.8536, interval_samples_per_second: 0.35, interval_steps_per_second: 0.438, epoch: 1.7514[0m
[32m[2022-09-05 12:57:36,896] [    INFO][0m - loss: 0.46289377, learning_rate: 9.638418079096045e-06, global_step: 320, interval_runtime: 2.3881, interval_samples_per_second: 3.35, interval_steps_per_second: 4.187, epoch: 1.8079[0m
[32m[2022-09-05 12:57:38,382] [    INFO][0m - loss: 0.58602266, learning_rate: 9.627118644067797e-06, global_step: 330, interval_runtime: 1.4856, interval_samples_per_second: 5.385, interval_steps_per_second: 6.731, epoch: 1.8644[0m
[32m[2022-09-05 12:57:39,871] [    INFO][0m - loss: 0.33338151, learning_rate: 9.615819209039548e-06, global_step: 340, interval_runtime: 1.4887, interval_samples_per_second: 5.374, interval_steps_per_second: 6.717, epoch: 1.9209[0m
[32m[2022-09-05 12:57:41,632] [    INFO][0m - loss: 0.3277391, learning_rate: 9.6045197740113e-06, global_step: 350, interval_runtime: 1.4816, interval_samples_per_second: 5.4, interval_steps_per_second: 6.75, epoch: 1.9774[0m
[32m[2022-09-05 12:57:43,129] [    INFO][0m - loss: 0.45391703, learning_rate: 9.593220338983051e-06, global_step: 360, interval_runtime: 1.7769, interval_samples_per_second: 4.502, interval_steps_per_second: 5.628, epoch: 2.0339[0m
[32m[2022-09-05 12:57:44,618] [    INFO][0m - loss: 0.41583481, learning_rate: 9.581920903954803e-06, global_step: 370, interval_runtime: 1.4885, interval_samples_per_second: 5.374, interval_steps_per_second: 6.718, epoch: 2.0904[0m
[32m[2022-09-05 12:57:46,105] [    INFO][0m - loss: 0.57189078, learning_rate: 9.570621468926554e-06, global_step: 380, interval_runtime: 1.4877, interval_samples_per_second: 5.378, interval_steps_per_second: 6.722, epoch: 2.1469[0m
[32m[2022-09-05 12:57:47,594] [    INFO][0m - loss: 0.55934029, learning_rate: 9.559322033898306e-06, global_step: 390, interval_runtime: 1.4877, interval_samples_per_second: 5.378, interval_steps_per_second: 6.722, epoch: 2.2034[0m
[32m[2022-09-05 12:57:49,086] [    INFO][0m - loss: 0.47819695, learning_rate: 9.548022598870057e-06, global_step: 400, interval_runtime: 1.4931, interval_samples_per_second: 5.358, interval_steps_per_second: 6.697, epoch: 2.2599[0m
[32m[2022-09-05 12:57:49,087] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 12:57:49,087] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 12:57:49,087] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 12:57:49,087] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 12:57:49,087] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 12:58:00,843] [    INFO][0m - eval_loss: 0.46861332654953003, eval_accuracy: 0.16831683168316833, eval_runtime: 11.7557, eval_samples_per_second: 120.282, eval_steps_per_second: 15.057, epoch: 2.2599[0m
[32m[2022-09-05 12:58:00,891] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-400[0m
[32m[2022-09-05 12:58:00,891] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 12:58:04,002] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-400/tokenizer_config.json[0m
[32m[2022-09-05 12:58:04,002] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-400/special_tokens_map.json[0m
[32m[2022-09-05 12:58:11,964] [    INFO][0m - loss: 0.56874819, learning_rate: 9.53672316384181e-06, global_step: 410, interval_runtime: 22.8782, interval_samples_per_second: 0.35, interval_steps_per_second: 0.437, epoch: 2.3164[0m
[32m[2022-09-05 12:58:13,449] [    INFO][0m - loss: 0.36608992, learning_rate: 9.52542372881356e-06, global_step: 420, interval_runtime: 1.4846, interval_samples_per_second: 5.389, interval_steps_per_second: 6.736, epoch: 2.3729[0m
[32m[2022-09-05 12:58:14,934] [    INFO][0m - loss: 0.4415164, learning_rate: 9.514124293785312e-06, global_step: 430, interval_runtime: 1.4846, interval_samples_per_second: 5.389, interval_steps_per_second: 6.736, epoch: 2.4294[0m
[32m[2022-09-05 12:58:16,425] [    INFO][0m - loss: 0.54498224, learning_rate: 9.502824858757063e-06, global_step: 440, interval_runtime: 1.4911, interval_samples_per_second: 5.365, interval_steps_per_second: 6.706, epoch: 2.4859[0m
[32m[2022-09-05 12:58:17,916] [    INFO][0m - loss: 0.45046329, learning_rate: 9.491525423728815e-06, global_step: 450, interval_runtime: 1.4912, interval_samples_per_second: 5.365, interval_steps_per_second: 6.706, epoch: 2.5424[0m
[32m[2022-09-05 12:58:19,407] [    INFO][0m - loss: 0.59357677, learning_rate: 9.480225988700566e-06, global_step: 460, interval_runtime: 1.4903, interval_samples_per_second: 5.368, interval_steps_per_second: 6.71, epoch: 2.5989[0m
[32m[2022-09-05 12:58:20,895] [    INFO][0m - loss: 0.54080644, learning_rate: 9.468926553672318e-06, global_step: 470, interval_runtime: 1.488, interval_samples_per_second: 5.376, interval_steps_per_second: 6.72, epoch: 2.6554[0m
[32m[2022-09-05 12:58:22,384] [    INFO][0m - loss: 0.44119053, learning_rate: 9.457627118644069e-06, global_step: 480, interval_runtime: 1.4897, interval_samples_per_second: 5.37, interval_steps_per_second: 6.713, epoch: 2.7119[0m
[32m[2022-09-05 12:58:23,877] [    INFO][0m - loss: 0.43429413, learning_rate: 9.44632768361582e-06, global_step: 490, interval_runtime: 1.4934, interval_samples_per_second: 5.357, interval_steps_per_second: 6.696, epoch: 2.7684[0m
[32m[2022-09-05 12:58:25,368] [    INFO][0m - loss: 0.35553875, learning_rate: 9.435028248587572e-06, global_step: 500, interval_runtime: 1.4908, interval_samples_per_second: 5.366, interval_steps_per_second: 6.708, epoch: 2.8249[0m
[32m[2022-09-05 12:58:25,369] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 12:58:25,369] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 12:58:25,369] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 12:58:25,369] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 12:58:25,369] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 12:58:37,112] [    INFO][0m - eval_loss: 0.4214252233505249, eval_accuracy: 0.2524752475247525, eval_runtime: 11.7426, eval_samples_per_second: 120.416, eval_steps_per_second: 15.073, epoch: 2.8249[0m
[32m[2022-09-05 12:58:37,164] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-500[0m
[32m[2022-09-05 12:58:37,164] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 12:58:40,266] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-500/tokenizer_config.json[0m
[32m[2022-09-05 12:58:40,267] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-500/special_tokens_map.json[0m
[32m[2022-09-05 12:58:48,776] [    INFO][0m - loss: 0.36602144, learning_rate: 9.423728813559322e-06, global_step: 510, interval_runtime: 23.4069, interval_samples_per_second: 0.342, interval_steps_per_second: 0.427, epoch: 2.8814[0m
[32m[2022-09-05 12:58:50,267] [    INFO][0m - loss: 0.39394977, learning_rate: 9.412429378531073e-06, global_step: 520, interval_runtime: 1.4913, interval_samples_per_second: 5.365, interval_steps_per_second: 6.706, epoch: 2.9379[0m
[32m[2022-09-05 12:58:51,755] [    INFO][0m - loss: 0.34483185, learning_rate: 9.401129943502825e-06, global_step: 530, interval_runtime: 1.488, interval_samples_per_second: 5.376, interval_steps_per_second: 6.72, epoch: 2.9944[0m
[32m[2022-09-05 12:58:53,263] [    INFO][0m - loss: 0.31274939, learning_rate: 9.389830508474576e-06, global_step: 540, interval_runtime: 1.5082, interval_samples_per_second: 5.304, interval_steps_per_second: 6.631, epoch: 3.0508[0m
[32m[2022-09-05 12:58:54,756] [    INFO][0m - loss: 0.47880592, learning_rate: 9.378531073446328e-06, global_step: 550, interval_runtime: 1.4931, interval_samples_per_second: 5.358, interval_steps_per_second: 6.698, epoch: 3.1073[0m
[32m[2022-09-05 12:58:56,258] [    INFO][0m - loss: 0.5468606, learning_rate: 9.367231638418079e-06, global_step: 560, interval_runtime: 1.5023, interval_samples_per_second: 5.325, interval_steps_per_second: 6.656, epoch: 3.1638[0m
[32m[2022-09-05 12:58:57,753] [    INFO][0m - loss: 0.48388872, learning_rate: 9.355932203389831e-06, global_step: 570, interval_runtime: 1.4952, interval_samples_per_second: 5.35, interval_steps_per_second: 6.688, epoch: 3.2203[0m
[32m[2022-09-05 12:58:59,259] [    INFO][0m - loss: 0.41933227, learning_rate: 9.344632768361582e-06, global_step: 580, interval_runtime: 1.5051, interval_samples_per_second: 5.315, interval_steps_per_second: 6.644, epoch: 3.2768[0m
[32m[2022-09-05 12:59:00,753] [    INFO][0m - loss: 0.50341983, learning_rate: 9.333333333333334e-06, global_step: 590, interval_runtime: 1.4945, interval_samples_per_second: 5.353, interval_steps_per_second: 6.691, epoch: 3.3333[0m
[32m[2022-09-05 12:59:02,243] [    INFO][0m - loss: 0.50493259, learning_rate: 9.322033898305085e-06, global_step: 600, interval_runtime: 1.4901, interval_samples_per_second: 5.369, interval_steps_per_second: 6.711, epoch: 3.3898[0m
[32m[2022-09-05 12:59:02,244] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 12:59:02,244] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 12:59:02,244] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 12:59:02,244] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 12:59:02,244] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 12:59:14,119] [    INFO][0m - eval_loss: 0.4238237142562866, eval_accuracy: 0.24752475247524752, eval_runtime: 11.8744, eval_samples_per_second: 119.08, eval_steps_per_second: 14.906, epoch: 3.3898[0m
[32m[2022-09-05 12:59:14,176] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-600[0m
[32m[2022-09-05 12:59:14,176] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 12:59:17,369] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-600/tokenizer_config.json[0m
[32m[2022-09-05 12:59:17,369] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-600/special_tokens_map.json[0m
[32m[2022-09-05 12:59:24,425] [    INFO][0m - loss: 0.41252398, learning_rate: 9.310734463276837e-06, global_step: 610, interval_runtime: 22.1816, interval_samples_per_second: 0.361, interval_steps_per_second: 0.451, epoch: 3.4463[0m
[32m[2022-09-05 12:59:25,911] [    INFO][0m - loss: 0.46473155, learning_rate: 9.299435028248588e-06, global_step: 620, interval_runtime: 1.486, interval_samples_per_second: 5.384, interval_steps_per_second: 6.73, epoch: 3.5028[0m
[32m[2022-09-05 12:59:27,404] [    INFO][0m - loss: 0.43219914, learning_rate: 9.28813559322034e-06, global_step: 630, interval_runtime: 1.4935, interval_samples_per_second: 5.357, interval_steps_per_second: 6.696, epoch: 3.5593[0m
[32m[2022-09-05 12:59:28,893] [    INFO][0m - loss: 0.43960791, learning_rate: 9.276836158192091e-06, global_step: 640, interval_runtime: 1.489, interval_samples_per_second: 5.373, interval_steps_per_second: 6.716, epoch: 3.6158[0m
[32m[2022-09-05 12:59:30,381] [    INFO][0m - loss: 0.41919236, learning_rate: 9.265536723163843e-06, global_step: 650, interval_runtime: 1.4875, interval_samples_per_second: 5.378, interval_steps_per_second: 6.723, epoch: 3.6723[0m
[32m[2022-09-05 12:59:31,868] [    INFO][0m - loss: 0.4394053, learning_rate: 9.254237288135594e-06, global_step: 660, interval_runtime: 1.4867, interval_samples_per_second: 5.381, interval_steps_per_second: 6.726, epoch: 3.7288[0m
[32m[2022-09-05 12:59:33,358] [    INFO][0m - loss: 0.34648788, learning_rate: 9.242937853107346e-06, global_step: 670, interval_runtime: 1.4902, interval_samples_per_second: 5.368, interval_steps_per_second: 6.711, epoch: 3.7853[0m
[32m[2022-09-05 12:59:34,845] [    INFO][0m - loss: 0.39793203, learning_rate: 9.231638418079097e-06, global_step: 680, interval_runtime: 1.4876, interval_samples_per_second: 5.378, interval_steps_per_second: 6.722, epoch: 3.8418[0m
[32m[2022-09-05 12:59:36,340] [    INFO][0m - loss: 0.47851515, learning_rate: 9.220338983050847e-06, global_step: 690, interval_runtime: 1.4945, interval_samples_per_second: 5.353, interval_steps_per_second: 6.691, epoch: 3.8983[0m
[32m[2022-09-05 12:59:37,833] [    INFO][0m - loss: 0.46696486, learning_rate: 9.2090395480226e-06, global_step: 700, interval_runtime: 1.4931, interval_samples_per_second: 5.358, interval_steps_per_second: 6.697, epoch: 3.9548[0m
[32m[2022-09-05 12:59:37,834] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 12:59:37,834] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 12:59:37,834] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 12:59:37,834] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 12:59:37,834] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 12:59:49,550] [    INFO][0m - eval_loss: 0.41354408860206604, eval_accuracy: 0.2376237623762376, eval_runtime: 11.7153, eval_samples_per_second: 120.697, eval_steps_per_second: 15.109, epoch: 3.9548[0m
[32m[2022-09-05 12:59:49,602] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-700[0m
[32m[2022-09-05 12:59:49,602] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 12:59:53,051] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-700/tokenizer_config.json[0m
[32m[2022-09-05 12:59:53,051] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-700/special_tokens_map.json[0m
[32m[2022-09-05 13:00:00,685] [    INFO][0m - loss: 0.50613093, learning_rate: 9.19774011299435e-06, global_step: 710, interval_runtime: 22.8518, interval_samples_per_second: 0.35, interval_steps_per_second: 0.438, epoch: 4.0113[0m
[32m[2022-09-05 13:00:02,176] [    INFO][0m - loss: 0.39070568, learning_rate: 9.186440677966101e-06, global_step: 720, interval_runtime: 1.491, interval_samples_per_second: 5.365, interval_steps_per_second: 6.707, epoch: 4.0678[0m
[32m[2022-09-05 13:00:03,666] [    INFO][0m - loss: 0.48194704, learning_rate: 9.175141242937853e-06, global_step: 730, interval_runtime: 1.4907, interval_samples_per_second: 5.367, interval_steps_per_second: 6.708, epoch: 4.1243[0m
[32m[2022-09-05 13:00:05,154] [    INFO][0m - loss: 0.40714188, learning_rate: 9.163841807909604e-06, global_step: 740, interval_runtime: 1.488, interval_samples_per_second: 5.376, interval_steps_per_second: 6.721, epoch: 4.1808[0m
[32m[2022-09-05 13:00:06,646] [    INFO][0m - loss: 0.37611537, learning_rate: 9.152542372881356e-06, global_step: 750, interval_runtime: 1.4917, interval_samples_per_second: 5.363, interval_steps_per_second: 6.704, epoch: 4.2373[0m
[32m[2022-09-05 13:00:08,136] [    INFO][0m - loss: 0.49497418, learning_rate: 9.141242937853107e-06, global_step: 760, interval_runtime: 1.4901, interval_samples_per_second: 5.369, interval_steps_per_second: 6.711, epoch: 4.2938[0m
[32m[2022-09-05 13:00:09,627] [    INFO][0m - loss: 0.39766462, learning_rate: 9.12994350282486e-06, global_step: 770, interval_runtime: 1.4913, interval_samples_per_second: 5.365, interval_steps_per_second: 6.706, epoch: 4.3503[0m
[32m[2022-09-05 13:00:11,118] [    INFO][0m - loss: 0.51971645, learning_rate: 9.11864406779661e-06, global_step: 780, interval_runtime: 1.4902, interval_samples_per_second: 5.369, interval_steps_per_second: 6.711, epoch: 4.4068[0m
[32m[2022-09-05 13:00:12,606] [    INFO][0m - loss: 0.5048521, learning_rate: 9.107344632768362e-06, global_step: 790, interval_runtime: 1.488, interval_samples_per_second: 5.376, interval_steps_per_second: 6.721, epoch: 4.4633[0m
[32m[2022-09-05 13:00:14,098] [    INFO][0m - loss: 0.40274763, learning_rate: 9.096045197740113e-06, global_step: 800, interval_runtime: 1.4923, interval_samples_per_second: 5.361, interval_steps_per_second: 6.701, epoch: 4.5198[0m
[32m[2022-09-05 13:00:14,098] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:00:14,099] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:00:14,099] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:00:14,099] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:00:14,099] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:00:26,029] [    INFO][0m - eval_loss: 0.42325732111930847, eval_accuracy: 0.16336633663366337, eval_runtime: 11.9302, eval_samples_per_second: 118.523, eval_steps_per_second: 14.836, epoch: 4.5198[0m
[32m[2022-09-05 13:00:26,080] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-800[0m
[32m[2022-09-05 13:00:26,081] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:00:29,203] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-800/tokenizer_config.json[0m
[32m[2022-09-05 13:00:29,204] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-800/special_tokens_map.json[0m
[32m[2022-09-05 13:00:38,689] [    INFO][0m - loss: 0.3871397, learning_rate: 9.084745762711865e-06, global_step: 810, interval_runtime: 24.5911, interval_samples_per_second: 0.325, interval_steps_per_second: 0.407, epoch: 4.5763[0m
[32m[2022-09-05 13:00:40,185] [    INFO][0m - loss: 0.40169892, learning_rate: 9.073446327683618e-06, global_step: 820, interval_runtime: 1.4953, interval_samples_per_second: 5.35, interval_steps_per_second: 6.688, epoch: 4.6328[0m
[32m[2022-09-05 13:00:41,679] [    INFO][0m - loss: 0.45886388, learning_rate: 9.062146892655368e-06, global_step: 830, interval_runtime: 1.495, interval_samples_per_second: 5.351, interval_steps_per_second: 6.689, epoch: 4.6893[0m
[32m[2022-09-05 13:00:43,173] [    INFO][0m - loss: 0.50937343, learning_rate: 9.05084745762712e-06, global_step: 840, interval_runtime: 1.4934, interval_samples_per_second: 5.357, interval_steps_per_second: 6.696, epoch: 4.7458[0m
[32m[2022-09-05 13:00:44,668] [    INFO][0m - loss: 0.50472059, learning_rate: 9.039548022598871e-06, global_step: 850, interval_runtime: 1.4958, interval_samples_per_second: 5.348, interval_steps_per_second: 6.685, epoch: 4.8023[0m
[32m[2022-09-05 13:00:46,165] [    INFO][0m - loss: 0.48853521, learning_rate: 9.028248587570622e-06, global_step: 860, interval_runtime: 1.4964, interval_samples_per_second: 5.346, interval_steps_per_second: 6.683, epoch: 4.8588[0m
[32m[2022-09-05 13:00:47,747] [    INFO][0m - loss: 0.36346428, learning_rate: 9.016949152542374e-06, global_step: 870, interval_runtime: 1.4898, interval_samples_per_second: 5.37, interval_steps_per_second: 6.712, epoch: 4.9153[0m
[32m[2022-09-05 13:00:49,238] [    INFO][0m - loss: 0.51264172, learning_rate: 9.005649717514125e-06, global_step: 880, interval_runtime: 1.5834, interval_samples_per_second: 5.052, interval_steps_per_second: 6.315, epoch: 4.9718[0m
[32m[2022-09-05 13:00:50,736] [    INFO][0m - loss: 0.34280171, learning_rate: 8.994350282485876e-06, global_step: 890, interval_runtime: 1.4979, interval_samples_per_second: 5.341, interval_steps_per_second: 6.676, epoch: 5.0282[0m
[32m[2022-09-05 13:00:52,228] [    INFO][0m - loss: 0.45696392, learning_rate: 8.983050847457628e-06, global_step: 900, interval_runtime: 1.4914, interval_samples_per_second: 5.364, interval_steps_per_second: 6.705, epoch: 5.0847[0m
[32m[2022-09-05 13:00:52,228] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:00:52,228] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:00:52,228] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:00:52,228] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:00:52,228] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:01:04,012] [    INFO][0m - eval_loss: 0.48171281814575195, eval_accuracy: 0.2722772277227723, eval_runtime: 11.7832, eval_samples_per_second: 120.002, eval_steps_per_second: 15.021, epoch: 5.0847[0m
[32m[2022-09-05 13:01:04,070] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-900[0m
[32m[2022-09-05 13:01:04,070] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:01:07,246] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-900/tokenizer_config.json[0m
[32m[2022-09-05 13:01:07,246] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-900/special_tokens_map.json[0m
[32m[2022-09-05 13:01:17,038] [    INFO][0m - loss: 0.49473224, learning_rate: 8.971751412429379e-06, global_step: 910, interval_runtime: 24.8099, interval_samples_per_second: 0.322, interval_steps_per_second: 0.403, epoch: 5.1412[0m
[32m[2022-09-05 13:01:18,524] [    INFO][0m - loss: 0.54644504, learning_rate: 8.960451977401131e-06, global_step: 920, interval_runtime: 1.4865, interval_samples_per_second: 5.382, interval_steps_per_second: 6.727, epoch: 5.1977[0m
[32m[2022-09-05 13:01:20,009] [    INFO][0m - loss: 0.45264549, learning_rate: 8.949152542372881e-06, global_step: 930, interval_runtime: 1.4848, interval_samples_per_second: 5.388, interval_steps_per_second: 6.735, epoch: 5.2542[0m
[32m[2022-09-05 13:01:21,497] [    INFO][0m - loss: 0.26629341, learning_rate: 8.937853107344634e-06, global_step: 940, interval_runtime: 1.4883, interval_samples_per_second: 5.375, interval_steps_per_second: 6.719, epoch: 5.3107[0m
[32m[2022-09-05 13:01:22,988] [    INFO][0m - loss: 0.65550647, learning_rate: 8.926553672316384e-06, global_step: 950, interval_runtime: 1.4913, interval_samples_per_second: 5.365, interval_steps_per_second: 6.706, epoch: 5.3672[0m
[32m[2022-09-05 13:01:24,482] [    INFO][0m - loss: 0.45235748, learning_rate: 8.915254237288137e-06, global_step: 960, interval_runtime: 1.493, interval_samples_per_second: 5.358, interval_steps_per_second: 6.698, epoch: 5.4237[0m
[32m[2022-09-05 13:01:25,973] [    INFO][0m - loss: 0.41305404, learning_rate: 8.903954802259887e-06, global_step: 970, interval_runtime: 1.492, interval_samples_per_second: 5.362, interval_steps_per_second: 6.702, epoch: 5.4802[0m
[32m[2022-09-05 13:01:27,464] [    INFO][0m - loss: 0.45222588, learning_rate: 8.89265536723164e-06, global_step: 980, interval_runtime: 1.4907, interval_samples_per_second: 5.366, interval_steps_per_second: 6.708, epoch: 5.5367[0m
[32m[2022-09-05 13:01:28,955] [    INFO][0m - loss: 0.49180908, learning_rate: 8.88135593220339e-06, global_step: 990, interval_runtime: 1.4904, interval_samples_per_second: 5.368, interval_steps_per_second: 6.71, epoch: 5.5932[0m
[32m[2022-09-05 13:01:30,449] [    INFO][0m - loss: 0.40648694, learning_rate: 8.870056497175143e-06, global_step: 1000, interval_runtime: 1.4938, interval_samples_per_second: 5.356, interval_steps_per_second: 6.694, epoch: 5.6497[0m
[32m[2022-09-05 13:01:30,449] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:01:30,449] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:01:30,449] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:01:30,450] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:01:30,450] [    INFO][0m -   Total prediction steps = 177[0m
====================
[5 4 5 4 0 4 3 6 3 1 0 1 0 3 5 4 6 0 5 1 5 0 4 6 2 5 5 0 3 5 6 5 4 2 3 1 4
 4 0 3 0 6 0 5 2 5 1 0 2 6 4 0 4 2 6 3 6 3 5 6 2 5 2 1 6 0 6 6 3 3 3 6 0 0
 5 0 0 1 2 6 1 5 0 6 5 4 2 6 6 3 4 3 6 3 1 6 5 5 2 1 2 1 0 4 3 3 1 3 6 3 2
 0 5 4 4 3 5 2 1 2 6 2 2 4 5 1 5 3 4 3 0 0 0 5 2 4 0 6 6 3 3 3 0 6 3 3 5 2
 0 6 3 5 5 0 4 2 1 0 0 4 5 1 0 5 4 3 0 1 0 0 4 6 2 5 5 4 5 4 6 4 3 3 4 4 0
 4 4 0 4 0 1 1 4 4 2 2 0 3 4 3 2 6]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[3 0 4 2 6 1 3 5 6 5 3 6 4 4 4 6 1 0 4 5 0 3 1 5 5 5 2 3 6 3 0 4 4 2 0 1 0
 6 5 6 0 2 1 5 2 2 3 5 2 5 4 0 4 6 6 0 2 4 2 6 4 1 5 2 4 0 1 1 5 3 3 0 0 0
 4 3 2 1 5 2 1 0 4 4 0 6 2 6 0 3 2 0 5 1 2 1 5 2 3 4 6 5 4 1 3 5 1 0 0 3 2
 2 6 4 2 2 6 2 6 2 2 5 1 6 6 5 5 1 3 2 0 4 0 3 3 0 3 6 2 1 2 1 3 5 3 0 5 1
 5 6 2 5 5 2 2 6 2 2 3 6 2 2 1 1 3 5 5 1 4 2 3 6 1 1 1 3 3 3 5 5 3 3 2 3 0
 5 4 5 4 6 1 2 1 6 1 2 4 3 2 0 2 0]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[0 5 5 2 6 3 3 4 6 2 1 1 2 5 0 4 0 5 4 5 0 0 2 5 2 2 5 3 2 0 2 4 4 0 3 4 4
 3 1 1 0 2 1 5 2 2 2 1 2 3 4 0 1 5 6 3 3 1 5 5 2 2 6 6 4 6 0 6 0 2 6 6 0 4
 1 5 2 0 1 3 1 5 4 6 2 5 2 6 4 3 2 1 3 5 2 1 5 3 3 4 4 6 3 2 3 4 5 0 5 3 0
 4 1 2 4 3 4 4 1 2 4 5 5 4 3 1 0 3 3 3 2 4 0 5 5 0 2 5 2 4 2 4 3 6 5 5 5 6
 0 3 2 0 1 6 1 1 6 0 3 4 4 1 4 1 3 6 0 1 2 2 4 4 2 5 3 2 5 4 5 3 5 1 2 2 5
 5 5 5 1 6 1 6 1 4 2 2 4 3 0 0 2 1]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[0 5 5 2 6 0 3 5 3 6 1 3 2 2 0 4 5 5 4 3 5 3 4 5 2 2 4 2 2 6 2 5 4 5 5 6 4
 1 0 6 0 0 1 2 2 2 3 0 2 6 4 0 1 5 6 5 1 1 5 0 2 1 5 2 4 0 1 5 0 5 3 6 0 3
 5 6 1 0 1 2 1 5 4 3 2 6 6 6 6 3 2 1 3 1 3 6 4 6 4 6 5 0 4 5 3 0 1 0 0 3 0
 4 1 2 4 1 0 4 1 2 4 6 0 5 1 6 5 1 3 3 5 4 0 5 5 0 0 5 4 4 3 1 1 6 3 4 5 1
 0 0 1 5 0 2 0 2 1 0 3 4 4 1 2 2 3 0 6 1 2 2 4 3 2 5 3 1 5 3 0 5 5 1 2 2 0
 4 4 5 4 6 1 2 1 6 2 2 4 5 3 3 2 1]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[0 5 4 3 6 2 3 1 5 5 0 3 2 2 0 6 0 0 5 3 5 3 4 5 1 2 0 2 2 3 2 5 4 3 5 1 6
 1 1 6 0 0 3 5 2 2 3 2 2 6 4 0 1 2 6 1 1 1 5 0 6 3 5 2 2 3 6 1 4 3 3 4 0 6
 5 5 1 3 1 4 1 0 1 6 4 6 6 6 0 3 2 0 5 1 3 6 4 6 3 4 4 5 4 5 6 0 1 5 0 0 0
 5 4 2 4 2 4 4 1 2 5 1 0 5 5 2 5 1 5 3 5 5 0 5 2 2 0 6 5 3 5 5 5 1 5 4 5 2
 6 0 0 5 0 2 0 0 2 6 3 5 4 1 2 1 3 0 0 1 2 4 2 0 0 5 0 1 5 3 0 5 1 3 4 2 0
 4 4 5 1 6 1 1 1 6 4 2 6 5 2 0 2 1]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[0 5 4 3 2 4 3 5 3 5 1 5 2 2 1 3 6 0 2 3 2 3 2 5 1 2 0 2 2 4 2 4 4 5 0 1 0
 1 1 6 0 0 3 5 3 2 1 0 2 6 4 0 0 0 6 0 1 2 5 0 6 3 4 2 2 4 5 1 5 3 1 4 0 6
 1 5 1 3 1 6 1 6 6 6 4 4 2 6 6 3 2 1 5 5 3 6 4 4 4 4 4 5 4 2 6 2 1 5 0 0 1
 5 4 2 4 3 4 5 0 2 5 5 0 5 5 2 5 1 2 0 0 5 1 5 2 0 4 1 2 3 6 4 0 5 5 5 5 0
 2 0 0 5 0 6 4 6 6 6 3 5 4 1 2 1 0 1 0 1 2 0 4 6 0 2 0 2 1 3 1 5 3 3 4 2 0
 4 5 5 1 6 1 5 1 6 2 2 0 6 2 5 2 1]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[0 4 2 3 0 2 3 3 4 5 1 5 2 2 1 3 6 0 1 5 2 3 6 2 1 2 2 2 2 4 2 4 4 6 5 1 0
 1 3 2 0 3 4 3 5 6 3 1 2 3 4 0 4 0 6 0 1 6 4 0 6 6 2 3 2 5 4 1 5 2 2 6 0 3
 0 5 5 1 2 6 2 4 6 4 4 4 0 6 1 3 2 1 5 3 3 6 4 3 5 4 4 5 3 6 5 2 1 0 0 2 5
 5 1 2 6 6 4 3 1 2 5 5 0 5 5 2 5 6 5 0 0 4 1 0 2 0 5 2 1 3 5 6 1 1 5 5 5 0
 2 0 0 0 0 6 4 6 6 6 3 5 4 1 0 1 3 4 0 1 2 0 2 4 0 2 0 2 4 3 1 5 3 3 4 2 0
 4 6 5 1 6 1 4 4 3 1 4 0 6 4 5 0 1]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[3 4 2 3 6 5 3 3 4 2 1 0 2 2 3 4 0 4 2 6 6 3 5 5 1 2 4 4 5 5 2 3 4 1 5 1 0
 1 6 6 0 6 4 0 5 2 3 0 2 3 4 0 4 0 3 3 1 4 6 0 6 5 0 4 3 5 2 1 5 2 2 1 0 0
 4 4 2 1 6 6 1 4 1 1 4 1 0 6 1 3 2 1 5 3 3 6 4 6 2 2 5 2 2 3 6 0 1 0 0 6 0
 5 2 2 6 2 4 3 1 4 3 1 0 5 3 1 5 6 0 0 0 4 6 0 3 0 0 2 5 3 6 0 6 1 5 4 5 2
 2 0 1 5 0 6 4 2 0 0 3 3 0 6 4 1 4 0 0 1 2 0 2 6 0 2 2 1 4 3 1 6 3 5 2 2 3
 4 6 5 0 0 1 2 4 3 2 2 0 3 1 5 0 4]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[5 2 3 3 6 2 3 2 2 2 1 0 2 2 4 4 0 2 2 6 2 6 4 5 1 6 2 2 2 6 4 3 4 3 3 4 1
 1 3 2 0 1 2 3 6 6 3 1 2 6 4 0 3 5 3 3 0 4 6 0 6 6 0 2 6 6 0 3 5 2 3 6 4 3
 4 5 2 1 6 6 1 4 1 1 4 4 6 6 4 3 2 1 5 4 4 6 4 6 4 3 5 4 4 2 6 0 6 4 6 3 0
 5 2 2 6 0 4 4 0 2 3 1 4 6 1 1 0 1 2 0 0 4 3 5 3 0 2 2 5 3 6 4 6 4 5 4 5 2
 5 2 3 5 0 3 6 1 6 5 5 3 3 6 4 5 4 4 0 6 0 0 3 3 0 2 0 2 4 3 0 5 3 5 2 6 0
 4 5 0 1 1 1 2 1 0 1 1 6 6 4 1 2 1]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[3 2 3 2 6 2 3 4 2 2 0 0 2 0 1 4 0 2 2 6 2 2 4 5 1 6 3 2 2 6 6 3 4 5 3 4 1
 1 4 6 0 0 2 3 5 2 2 1 2 6 4 5 2 5 3 3 0 4 6 5 6 5 0 3 6 6 0 5 5 2 2 6 0 3
 0 5 0 6 6 6 1 5 1 1 4 5 6 6 0 3 0 1 5 4 3 4 4 6 4 4 5 4 4 2 5 4 5 0 3 4 5
 1 4 5 6 0 4 4 0 4 3 1 5 5 0 1 5 1 2 0 5 5 6 5 5 0 0 5 5 3 6 4 6 6 5 4 0 2
 2 0 3 4 0 3 4 1 6 0 5 3 3 6 0 0 4 4 0 1 0 0 0 6 0 2 0 2 4 3 6 6 3 2 1 2 0
 4 5 5 1 1 1 1 1 0 2 1 6 6 1 1 2 3]
[32m[2022-09-05 13:01:42,258] [    INFO][0m - eval_loss: 0.41380006074905396, eval_accuracy: 0.32673267326732675, eval_runtime: 11.8082, eval_samples_per_second: 119.747, eval_steps_per_second: 14.99, epoch: 5.6497[0m
[32m[2022-09-05 13:01:42,310] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-1000[0m
[32m[2022-09-05 13:01:42,310] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:01:45,682] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-1000/tokenizer_config.json[0m
[32m[2022-09-05 13:01:45,682] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-1000/special_tokens_map.json[0m
[32m[2022-09-05 13:01:54,938] [    INFO][0m - loss: 0.44051714, learning_rate: 8.858757062146893e-06, global_step: 1010, interval_runtime: 24.4899, interval_samples_per_second: 0.327, interval_steps_per_second: 0.408, epoch: 5.7062[0m
[32m[2022-09-05 13:01:56,430] [    INFO][0m - loss: 0.39841561, learning_rate: 8.847457627118646e-06, global_step: 1020, interval_runtime: 1.491, interval_samples_per_second: 5.365, interval_steps_per_second: 6.707, epoch: 5.7627[0m
[32m[2022-09-05 13:01:57,919] [    INFO][0m - loss: 0.41090021, learning_rate: 8.836158192090396e-06, global_step: 1030, interval_runtime: 1.4896, interval_samples_per_second: 5.371, interval_steps_per_second: 6.713, epoch: 5.8192[0m
[32m[2022-09-05 13:01:59,410] [    INFO][0m - loss: 0.29517407, learning_rate: 8.824858757062149e-06, global_step: 1040, interval_runtime: 1.4907, interval_samples_per_second: 5.367, interval_steps_per_second: 6.708, epoch: 5.8757[0m
[32m[2022-09-05 13:02:00,899] [    INFO][0m - loss: 0.48149419, learning_rate: 8.8135593220339e-06, global_step: 1050, interval_runtime: 1.4894, interval_samples_per_second: 5.371, interval_steps_per_second: 6.714, epoch: 5.9322[0m
[32m[2022-09-05 13:02:02,383] [    INFO][0m - loss: 0.51727371, learning_rate: 8.80225988700565e-06, global_step: 1060, interval_runtime: 1.484, interval_samples_per_second: 5.391, interval_steps_per_second: 6.739, epoch: 5.9887[0m
[32m[2022-09-05 13:02:03,889] [    INFO][0m - loss: 0.51762409, learning_rate: 8.790960451977402e-06, global_step: 1070, interval_runtime: 1.5057, interval_samples_per_second: 5.313, interval_steps_per_second: 6.641, epoch: 6.0452[0m
[32m[2022-09-05 13:02:05,382] [    INFO][0m - loss: 0.41950712, learning_rate: 8.779661016949153e-06, global_step: 1080, interval_runtime: 1.4925, interval_samples_per_second: 5.36, interval_steps_per_second: 6.7, epoch: 6.1017[0m
[32m[2022-09-05 13:02:06,874] [    INFO][0m - loss: 0.52364297, learning_rate: 8.768361581920905e-06, global_step: 1090, interval_runtime: 1.4931, interval_samples_per_second: 5.358, interval_steps_per_second: 6.697, epoch: 6.1582[0m
[32m[2022-09-05 13:02:08,367] [    INFO][0m - loss: 0.51908941, learning_rate: 8.757062146892656e-06, global_step: 1100, interval_runtime: 1.4924, interval_samples_per_second: 5.361, interval_steps_per_second: 6.701, epoch: 6.2147[0m
[32m[2022-09-05 13:02:08,367] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:02:08,367] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:02:08,367] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:02:08,368] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:02:08,368] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:02:20,228] [    INFO][0m - eval_loss: 0.41180217266082764, eval_accuracy: 0.29207920792079206, eval_runtime: 11.8602, eval_samples_per_second: 119.223, eval_steps_per_second: 14.924, epoch: 6.2147[0m
[32m[2022-09-05 13:02:20,280] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-1100[0m
[32m[2022-09-05 13:02:20,280] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:02:23,749] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-1100/tokenizer_config.json[0m
[32m[2022-09-05 13:02:23,749] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-1100/special_tokens_map.json[0m
[32m[2022-09-05 13:02:31,234] [    INFO][0m - loss: 0.37752175, learning_rate: 8.745762711864407e-06, global_step: 1110, interval_runtime: 22.867, interval_samples_per_second: 0.35, interval_steps_per_second: 0.437, epoch: 6.2712[0m
[32m[2022-09-05 13:02:32,721] [    INFO][0m - loss: 0.40172772, learning_rate: 8.734463276836159e-06, global_step: 1120, interval_runtime: 1.4877, interval_samples_per_second: 5.377, interval_steps_per_second: 6.722, epoch: 6.3277[0m
[32m[2022-09-05 13:02:34,214] [    INFO][0m - loss: 0.53254938, learning_rate: 8.72316384180791e-06, global_step: 1130, interval_runtime: 1.4925, interval_samples_per_second: 5.36, interval_steps_per_second: 6.7, epoch: 6.3842[0m
[32m[2022-09-05 13:02:35,708] [    INFO][0m - loss: 0.49968762, learning_rate: 8.711864406779662e-06, global_step: 1140, interval_runtime: 1.4943, interval_samples_per_second: 5.354, interval_steps_per_second: 6.692, epoch: 6.4407[0m
[32m[2022-09-05 13:02:37,200] [    INFO][0m - loss: 0.38204222, learning_rate: 8.700564971751413e-06, global_step: 1150, interval_runtime: 1.4912, interval_samples_per_second: 5.365, interval_steps_per_second: 6.706, epoch: 6.4972[0m
[32m[2022-09-05 13:02:38,691] [    INFO][0m - loss: 0.36220939, learning_rate: 8.689265536723165e-06, global_step: 1160, interval_runtime: 1.4913, interval_samples_per_second: 5.364, interval_steps_per_second: 6.706, epoch: 6.5537[0m
[32m[2022-09-05 13:02:40,186] [    INFO][0m - loss: 0.39022346, learning_rate: 8.677966101694915e-06, global_step: 1170, interval_runtime: 1.495, interval_samples_per_second: 5.351, interval_steps_per_second: 6.689, epoch: 6.6102[0m
[32m[2022-09-05 13:02:41,678] [    INFO][0m - loss: 0.34363866, learning_rate: 8.666666666666668e-06, global_step: 1180, interval_runtime: 1.492, interval_samples_per_second: 5.362, interval_steps_per_second: 6.702, epoch: 6.6667[0m
[32m[2022-09-05 13:02:43,183] [    INFO][0m - loss: 0.42484627, learning_rate: 8.655367231638418e-06, global_step: 1190, interval_runtime: 1.5052, interval_samples_per_second: 5.315, interval_steps_per_second: 6.644, epoch: 6.7232[0m
[32m[2022-09-05 13:02:44,678] [    INFO][0m - loss: 0.54092941, learning_rate: 8.64406779661017e-06, global_step: 1200, interval_runtime: 1.495, interval_samples_per_second: 5.351, interval_steps_per_second: 6.689, epoch: 6.7797[0m
[32m[2022-09-05 13:02:44,679] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:02:44,679] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:02:44,679] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:02:44,679] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:02:44,679] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:02:56,636] [    INFO][0m - eval_loss: 0.4139038324356079, eval_accuracy: 0.4158415841584158, eval_runtime: 11.957, eval_samples_per_second: 118.257, eval_steps_per_second: 14.803, epoch: 6.7797[0m
[32m[2022-09-05 13:02:56,694] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-1200[0m
[32m[2022-09-05 13:02:56,694] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:03:00,945] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-1200/tokenizer_config.json[0m
[32m[2022-09-05 13:03:00,946] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-1200/special_tokens_map.json[0m
[32m[2022-09-05 13:03:09,667] [    INFO][0m - loss: 0.33589129, learning_rate: 8.632768361581921e-06, global_step: 1210, interval_runtime: 24.989, interval_samples_per_second: 0.32, interval_steps_per_second: 0.4, epoch: 6.8362[0m
[32m[2022-09-05 13:03:11,159] [    INFO][0m - loss: 0.56413975, learning_rate: 8.621468926553674e-06, global_step: 1220, interval_runtime: 1.4913, interval_samples_per_second: 5.364, interval_steps_per_second: 6.705, epoch: 6.8927[0m
[32m[2022-09-05 13:03:12,650] [    INFO][0m - loss: 0.38707385, learning_rate: 8.610169491525424e-06, global_step: 1230, interval_runtime: 1.4913, interval_samples_per_second: 5.365, interval_steps_per_second: 6.706, epoch: 6.9492[0m
[32m[2022-09-05 13:03:14,179] [    INFO][0m - loss: 0.33857, learning_rate: 8.598870056497177e-06, global_step: 1240, interval_runtime: 1.5292, interval_samples_per_second: 5.231, interval_steps_per_second: 6.539, epoch: 7.0056[0m
[32m[2022-09-05 13:03:15,671] [    INFO][0m - loss: 0.49347186, learning_rate: 8.587570621468927e-06, global_step: 1250, interval_runtime: 1.4919, interval_samples_per_second: 5.362, interval_steps_per_second: 6.703, epoch: 7.0621[0m
[32m[2022-09-05 13:03:17,165] [    INFO][0m - loss: 0.44776192, learning_rate: 8.57627118644068e-06, global_step: 1260, interval_runtime: 1.4937, interval_samples_per_second: 5.356, interval_steps_per_second: 6.695, epoch: 7.1186[0m
[32m[2022-09-05 13:03:18,658] [    INFO][0m - loss: 0.50037756, learning_rate: 8.56497175141243e-06, global_step: 1270, interval_runtime: 1.4939, interval_samples_per_second: 5.355, interval_steps_per_second: 6.694, epoch: 7.1751[0m
[32m[2022-09-05 13:03:20,154] [    INFO][0m - loss: 0.39204102, learning_rate: 8.553672316384181e-06, global_step: 1280, interval_runtime: 1.4957, interval_samples_per_second: 5.348, interval_steps_per_second: 6.686, epoch: 7.2316[0m
[32m[2022-09-05 13:03:21,652] [    INFO][0m - loss: 0.36890147, learning_rate: 8.542372881355933e-06, global_step: 1290, interval_runtime: 1.4972, interval_samples_per_second: 5.343, interval_steps_per_second: 6.679, epoch: 7.2881[0m
[32m[2022-09-05 13:03:23,151] [    INFO][0m - loss: 0.45767679, learning_rate: 8.531073446327684e-06, global_step: 1300, interval_runtime: 1.4991, interval_samples_per_second: 5.336, interval_steps_per_second: 6.671, epoch: 7.3446[0m
[32m[2022-09-05 13:03:23,151] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:03:23,151] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:03:23,151] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:03:23,151] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:03:23,152] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:03:35,258] [    INFO][0m - eval_loss: 0.4472386837005615, eval_accuracy: 0.3564356435643564, eval_runtime: 12.1064, eval_samples_per_second: 116.797, eval_steps_per_second: 14.62, epoch: 7.3446[0m
[32m[2022-09-05 13:03:35,312] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-1300[0m
[32m[2022-09-05 13:03:35,312] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:03:38,888] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-1300/tokenizer_config.json[0m
[32m[2022-09-05 13:03:38,888] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-1300/special_tokens_map.json[0m
[32m[2022-09-05 13:03:49,391] [    INFO][0m - loss: 0.48675108, learning_rate: 8.519774011299435e-06, global_step: 1310, interval_runtime: 26.2398, interval_samples_per_second: 0.305, interval_steps_per_second: 0.381, epoch: 7.4011[0m
[32m[2022-09-05 13:03:50,884] [    INFO][0m - loss: 0.38824415, learning_rate: 8.508474576271187e-06, global_step: 1320, interval_runtime: 1.4929, interval_samples_per_second: 5.359, interval_steps_per_second: 6.698, epoch: 7.4576[0m
[32m[2022-09-05 13:03:52,377] [    INFO][0m - loss: 0.50139542, learning_rate: 8.497175141242938e-06, global_step: 1330, interval_runtime: 1.4937, interval_samples_per_second: 5.356, interval_steps_per_second: 6.695, epoch: 7.5141[0m
[32m[2022-09-05 13:03:53,869] [    INFO][0m - loss: 0.4580256, learning_rate: 8.48587570621469e-06, global_step: 1340, interval_runtime: 1.4918, interval_samples_per_second: 5.363, interval_steps_per_second: 6.703, epoch: 7.5706[0m
[32m[2022-09-05 13:03:55,361] [    INFO][0m - loss: 0.44365048, learning_rate: 8.47457627118644e-06, global_step: 1350, interval_runtime: 1.4922, interval_samples_per_second: 5.361, interval_steps_per_second: 6.702, epoch: 7.6271[0m
[32m[2022-09-05 13:03:56,853] [    INFO][0m - loss: 0.27174425, learning_rate: 8.463276836158193e-06, global_step: 1360, interval_runtime: 1.4917, interval_samples_per_second: 5.363, interval_steps_per_second: 6.704, epoch: 7.6836[0m
[32m[2022-09-05 13:03:59,871] [    INFO][0m - loss: 0.37287316, learning_rate: 8.451977401129944e-06, global_step: 1370, interval_runtime: 1.4895, interval_samples_per_second: 5.371, interval_steps_per_second: 6.714, epoch: 7.7401[0m
[32m[2022-09-05 13:04:01,358] [    INFO][0m - loss: 0.43850517, learning_rate: 8.440677966101696e-06, global_step: 1380, interval_runtime: 3.0161, interval_samples_per_second: 2.652, interval_steps_per_second: 3.316, epoch: 7.7966[0m
[32m[2022-09-05 13:04:02,848] [    INFO][0m - loss: 0.45832596, learning_rate: 8.429378531073447e-06, global_step: 1390, interval_runtime: 1.4897, interval_samples_per_second: 5.37, interval_steps_per_second: 6.713, epoch: 7.8531[0m
[32m[2022-09-05 13:04:04,339] [    INFO][0m - loss: 0.4836812, learning_rate: 8.418079096045199e-06, global_step: 1400, interval_runtime: 1.4907, interval_samples_per_second: 5.367, interval_steps_per_second: 6.708, epoch: 7.9096[0m
[32m[2022-09-05 13:04:04,339] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:04:04,339] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:04:04,340] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:04:04,340] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:04:04,340] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:04:16,039] [    INFO][0m - eval_loss: 0.4086480736732483, eval_accuracy: 0.43564356435643564, eval_runtime: 11.6985, eval_samples_per_second: 120.871, eval_steps_per_second: 15.13, epoch: 7.9096[0m
[32m[2022-09-05 13:04:16,090] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-1400[0m
[32m[2022-09-05 13:04:16,091] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:04:18,042] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-1400/tokenizer_config.json[0m
[32m[2022-09-05 13:04:18,042] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-1400/special_tokens_map.json[0m
[32m[2022-09-05 13:04:22,778] [    INFO][0m - loss: 0.34132707, learning_rate: 8.40677966101695e-06, global_step: 1410, interval_runtime: 18.4389, interval_samples_per_second: 0.434, interval_steps_per_second: 0.542, epoch: 7.9661[0m
[32m[2022-09-05 13:04:24,286] [    INFO][0m - loss: 0.59651847, learning_rate: 8.395480225988702e-06, global_step: 1420, interval_runtime: 1.5078, interval_samples_per_second: 5.306, interval_steps_per_second: 6.632, epoch: 8.0226[0m
[32m[2022-09-05 13:04:25,779] [    INFO][0m - loss: 0.41310802, learning_rate: 8.384180790960452e-06, global_step: 1430, interval_runtime: 1.4928, interval_samples_per_second: 5.359, interval_steps_per_second: 6.699, epoch: 8.0791[0m
[32m[2022-09-05 13:04:27,267] [    INFO][0m - loss: 0.39228821, learning_rate: 8.372881355932205e-06, global_step: 1440, interval_runtime: 1.4881, interval_samples_per_second: 5.376, interval_steps_per_second: 6.72, epoch: 8.1356[0m
[32m[2022-09-05 13:04:28,761] [    INFO][0m - loss: 0.48289123, learning_rate: 8.361581920903955e-06, global_step: 1450, interval_runtime: 1.4942, interval_samples_per_second: 5.354, interval_steps_per_second: 6.692, epoch: 8.1921[0m
[32m[2022-09-05 13:04:30,251] [    INFO][0m - loss: 0.55623856, learning_rate: 8.350282485875708e-06, global_step: 1460, interval_runtime: 1.4899, interval_samples_per_second: 5.37, interval_steps_per_second: 6.712, epoch: 8.2486[0m
[32m[2022-09-05 13:04:31,742] [    INFO][0m - loss: 0.445439, learning_rate: 8.338983050847458e-06, global_step: 1470, interval_runtime: 1.4908, interval_samples_per_second: 5.366, interval_steps_per_second: 6.708, epoch: 8.3051[0m
[32m[2022-09-05 13:04:33,235] [    INFO][0m - loss: 0.30573499, learning_rate: 8.327683615819209e-06, global_step: 1480, interval_runtime: 1.4935, interval_samples_per_second: 5.356, interval_steps_per_second: 6.696, epoch: 8.3616[0m
[32m[2022-09-05 13:04:34,729] [    INFO][0m - loss: 0.40201063, learning_rate: 8.316384180790961e-06, global_step: 1490, interval_runtime: 1.4945, interval_samples_per_second: 5.353, interval_steps_per_second: 6.691, epoch: 8.4181[0m
[32m[2022-09-05 13:04:36,223] [    INFO][0m - loss: 0.45790343, learning_rate: 8.305084745762712e-06, global_step: 1500, interval_runtime: 1.4935, interval_samples_per_second: 5.357, interval_steps_per_second: 6.696, epoch: 8.4746[0m
[32m[2022-09-05 13:04:36,224] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:04:36,224] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:04:36,224] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:04:36,224] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:04:36,224] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:04:48,353] [    INFO][0m - eval_loss: 0.42330607771873474, eval_accuracy: 0.46534653465346537, eval_runtime: 12.1279, eval_samples_per_second: 116.591, eval_steps_per_second: 14.594, epoch: 8.4746[0m
[32m[2022-09-05 13:04:49,334] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-1500[0m
[32m[2022-09-05 13:04:49,334] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:04:51,359] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-1500/tokenizer_config.json[0m
[32m[2022-09-05 13:04:51,359] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-1500/special_tokens_map.json[0m
[32m[2022-09-05 13:04:55,770] [    INFO][0m - loss: 0.48747516, learning_rate: 8.293785310734463e-06, global_step: 1510, interval_runtime: 19.5467, interval_samples_per_second: 0.409, interval_steps_per_second: 0.512, epoch: 8.5311[0m
[32m[2022-09-05 13:04:57,264] [    INFO][0m - loss: 0.36970747, learning_rate: 8.282485875706215e-06, global_step: 1520, interval_runtime: 1.4938, interval_samples_per_second: 5.355, interval_steps_per_second: 6.694, epoch: 8.5876[0m
[32m[2022-09-05 13:05:02,891] [    INFO][0m - loss: 0.3649024, learning_rate: 8.271186440677966e-06, global_step: 1530, interval_runtime: 1.4936, interval_samples_per_second: 5.356, interval_steps_per_second: 6.695, epoch: 8.6441[0m
[32m[2022-09-05 13:05:04,385] [    INFO][0m - loss: 0.49625769, learning_rate: 8.259887005649718e-06, global_step: 1540, interval_runtime: 5.6281, interval_samples_per_second: 1.421, interval_steps_per_second: 1.777, epoch: 8.7006[0m
[32m[2022-09-05 13:05:05,876] [    INFO][0m - loss: 0.39347634, learning_rate: 8.248587570621469e-06, global_step: 1550, interval_runtime: 1.4908, interval_samples_per_second: 5.366, interval_steps_per_second: 6.708, epoch: 8.7571[0m
[32m[2022-09-05 13:05:07,369] [    INFO][0m - loss: 0.30635123, learning_rate: 8.237288135593221e-06, global_step: 1560, interval_runtime: 1.4929, interval_samples_per_second: 5.359, interval_steps_per_second: 6.698, epoch: 8.8136[0m
[32m[2022-09-05 13:05:08,864] [    INFO][0m - loss: 0.4568429, learning_rate: 8.225988700564972e-06, global_step: 1570, interval_runtime: 1.4945, interval_samples_per_second: 5.353, interval_steps_per_second: 6.691, epoch: 8.8701[0m
[32m[2022-09-05 13:05:10,358] [    INFO][0m - loss: 0.45508003, learning_rate: 8.214689265536724e-06, global_step: 1580, interval_runtime: 1.4949, interval_samples_per_second: 5.351, interval_steps_per_second: 6.689, epoch: 8.9266[0m
[32m[2022-09-05 13:05:11,846] [    INFO][0m - loss: 0.35760596, learning_rate: 8.203389830508475e-06, global_step: 1590, interval_runtime: 1.4873, interval_samples_per_second: 5.379, interval_steps_per_second: 6.724, epoch: 8.9831[0m
[32m[2022-09-05 13:05:13,349] [    INFO][0m - loss: 0.47968445, learning_rate: 8.192090395480227e-06, global_step: 1600, interval_runtime: 1.5028, interval_samples_per_second: 5.323, interval_steps_per_second: 6.654, epoch: 9.0395[0m
[32m[2022-09-05 13:05:13,349] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:05:13,349] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:05:13,349] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:05:13,349] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:05:13,349] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:05:25,304] [    INFO][0m - eval_loss: 0.3887209892272949, eval_accuracy: 0.5693069306930693, eval_runtime: 11.9547, eval_samples_per_second: 118.28, eval_steps_per_second: 14.806, epoch: 9.0395[0m
[32m[2022-09-05 13:05:25,353] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-1600[0m
[32m[2022-09-05 13:05:25,353] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:05:27,162] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-1600/tokenizer_config.json[0m
[32m[2022-09-05 13:05:27,162] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-1600/special_tokens_map.json[0m
[32m[2022-09-05 13:05:31,841] [    INFO][0m - loss: 0.37887526, learning_rate: 8.18079096045198e-06, global_step: 1610, interval_runtime: 18.4926, interval_samples_per_second: 0.433, interval_steps_per_second: 0.541, epoch: 9.096[0m
[32m[2022-09-05 13:05:33,331] [    INFO][0m - loss: 0.35991325, learning_rate: 8.16949152542373e-06, global_step: 1620, interval_runtime: 1.4898, interval_samples_per_second: 5.37, interval_steps_per_second: 6.712, epoch: 9.1525[0m
[32m[2022-09-05 13:05:34,820] [    INFO][0m - loss: 0.4324244, learning_rate: 8.158192090395482e-06, global_step: 1630, interval_runtime: 1.4889, interval_samples_per_second: 5.373, interval_steps_per_second: 6.716, epoch: 9.209[0m
[32m[2022-09-05 13:05:36,308] [    INFO][0m - loss: 0.31353705, learning_rate: 8.146892655367233e-06, global_step: 1640, interval_runtime: 1.4886, interval_samples_per_second: 5.374, interval_steps_per_second: 6.718, epoch: 9.2655[0m
[32m[2022-09-05 13:05:37,802] [    INFO][0m - loss: 0.53103504, learning_rate: 8.135593220338983e-06, global_step: 1650, interval_runtime: 1.4937, interval_samples_per_second: 5.356, interval_steps_per_second: 6.695, epoch: 9.322[0m
[32m[2022-09-05 13:05:39,297] [    INFO][0m - loss: 0.34915895, learning_rate: 8.124293785310736e-06, global_step: 1660, interval_runtime: 1.4949, interval_samples_per_second: 5.352, interval_steps_per_second: 6.689, epoch: 9.3785[0m
[32m[2022-09-05 13:05:40,792] [    INFO][0m - loss: 0.30949264, learning_rate: 8.112994350282486e-06, global_step: 1670, interval_runtime: 1.4951, interval_samples_per_second: 5.351, interval_steps_per_second: 6.688, epoch: 9.435[0m
[32m[2022-09-05 13:05:42,283] [    INFO][0m - loss: 0.47868438, learning_rate: 8.101694915254237e-06, global_step: 1680, interval_runtime: 1.4904, interval_samples_per_second: 5.368, interval_steps_per_second: 6.71, epoch: 9.4915[0m
[32m[2022-09-05 13:05:43,775] [    INFO][0m - loss: 0.44208789, learning_rate: 8.09039548022599e-06, global_step: 1690, interval_runtime: 1.4925, interval_samples_per_second: 5.36, interval_steps_per_second: 6.7, epoch: 9.548[0m
[32m[2022-09-05 13:05:45,267] [    INFO][0m - loss: 0.42662659, learning_rate: 8.07909604519774e-06, global_step: 1700, interval_runtime: 1.4918, interval_samples_per_second: 5.363, interval_steps_per_second: 6.703, epoch: 9.6045[0m
[32m[2022-09-05 13:05:45,267] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:05:45,268] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:05:45,268] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:05:45,268] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:05:45,268] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:05:57,052] [    INFO][0m - eval_loss: 0.3543669879436493, eval_accuracy: 0.594059405940594, eval_runtime: 11.7836, eval_samples_per_second: 119.998, eval_steps_per_second: 15.021, epoch: 9.6045[0m
[32m[2022-09-05 13:05:57,104] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-1700[0m
[32m[2022-09-05 13:05:57,105] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:05:58,938] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-1700/tokenizer_config.json[0m
[32m[2022-09-05 13:06:01,403] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-1700/special_tokens_map.json[0m
[32m[2022-09-05 13:06:07,089] [    INFO][0m - loss: 0.42737913, learning_rate: 8.067796610169492e-06, global_step: 1710, interval_runtime: 21.8224, interval_samples_per_second: 0.367, interval_steps_per_second: 0.458, epoch: 9.661[0m
[32m[2022-09-05 13:06:08,582] [    INFO][0m - loss: 0.37722752, learning_rate: 8.056497175141243e-06, global_step: 1720, interval_runtime: 1.4931, interval_samples_per_second: 5.358, interval_steps_per_second: 6.698, epoch: 9.7175[0m
[32m[2022-09-05 13:06:10,079] [    INFO][0m - loss: 0.41755877, learning_rate: 8.045197740112995e-06, global_step: 1730, interval_runtime: 1.4967, interval_samples_per_second: 5.345, interval_steps_per_second: 6.681, epoch: 9.774[0m
[32m[2022-09-05 13:06:11,572] [    INFO][0m - loss: 0.24906952, learning_rate: 8.033898305084746e-06, global_step: 1740, interval_runtime: 1.493, interval_samples_per_second: 5.358, interval_steps_per_second: 6.698, epoch: 9.8305[0m
[32m[2022-09-05 13:06:13,062] [    INFO][0m - loss: 0.56157026, learning_rate: 8.022598870056498e-06, global_step: 1750, interval_runtime: 1.4898, interval_samples_per_second: 5.37, interval_steps_per_second: 6.712, epoch: 9.887[0m
[32m[2022-09-05 13:06:14,555] [    INFO][0m - loss: 0.5078547, learning_rate: 8.011299435028249e-06, global_step: 1760, interval_runtime: 1.4931, interval_samples_per_second: 5.358, interval_steps_per_second: 6.697, epoch: 9.9435[0m
[32m[2022-09-05 13:06:16,011] [    INFO][0m - loss: 0.36189053, learning_rate: 8.000000000000001e-06, global_step: 1770, interval_runtime: 1.4556, interval_samples_per_second: 5.496, interval_steps_per_second: 6.87, epoch: 10.0[0m
[32m[2022-09-05 13:06:17,565] [    INFO][0m - loss: 0.41805396, learning_rate: 7.988700564971752e-06, global_step: 1780, interval_runtime: 1.5541, interval_samples_per_second: 5.148, interval_steps_per_second: 6.435, epoch: 10.0565[0m
[32m[2022-09-05 13:06:19,061] [    INFO][0m - loss: 0.40653915, learning_rate: 7.977401129943504e-06, global_step: 1790, interval_runtime: 1.4964, interval_samples_per_second: 5.346, interval_steps_per_second: 6.683, epoch: 10.113[0m
[32m[2022-09-05 13:06:20,561] [    INFO][0m - loss: 0.23295071, learning_rate: 7.966101694915255e-06, global_step: 1800, interval_runtime: 1.4999, interval_samples_per_second: 5.334, interval_steps_per_second: 6.667, epoch: 10.1695[0m
[32m[2022-09-05 13:06:20,562] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:06:20,562] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:06:20,562] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:06:20,562] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:06:20,562] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:06:32,608] [    INFO][0m - eval_loss: 0.3319486081600189, eval_accuracy: 0.5891089108910891, eval_runtime: 12.0456, eval_samples_per_second: 117.388, eval_steps_per_second: 14.694, epoch: 10.1695[0m
[32m[2022-09-05 13:06:32,650] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-1800[0m
[32m[2022-09-05 13:06:32,650] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:06:34,320] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-1800/tokenizer_config.json[0m
[32m[2022-09-05 13:06:34,320] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-1800/special_tokens_map.json[0m
[32m[2022-09-05 13:06:38,583] [    INFO][0m - loss: 0.29329686, learning_rate: 7.954802259887007e-06, global_step: 1810, interval_runtime: 18.0216, interval_samples_per_second: 0.444, interval_steps_per_second: 0.555, epoch: 10.226[0m
[32m[2022-09-05 13:06:40,080] [    INFO][0m - loss: 0.44896588, learning_rate: 7.943502824858758e-06, global_step: 1820, interval_runtime: 1.4968, interval_samples_per_second: 5.345, interval_steps_per_second: 6.681, epoch: 10.2825[0m
[32m[2022-09-05 13:06:41,575] [    INFO][0m - loss: 0.57186251, learning_rate: 7.93220338983051e-06, global_step: 1830, interval_runtime: 1.4949, interval_samples_per_second: 5.352, interval_steps_per_second: 6.689, epoch: 10.339[0m
[32m[2022-09-05 13:06:43,077] [    INFO][0m - loss: 0.46958103, learning_rate: 7.920903954802261e-06, global_step: 1840, interval_runtime: 1.5019, interval_samples_per_second: 5.327, interval_steps_per_second: 6.658, epoch: 10.3955[0m
[32m[2022-09-05 13:06:44,576] [    INFO][0m - loss: 0.40766521, learning_rate: 7.909604519774012e-06, global_step: 1850, interval_runtime: 1.4991, interval_samples_per_second: 5.337, interval_steps_per_second: 6.671, epoch: 10.452[0m
[32m[2022-09-05 13:06:46,069] [    INFO][0m - loss: 0.37110553, learning_rate: 7.898305084745764e-06, global_step: 1860, interval_runtime: 1.4932, interval_samples_per_second: 5.358, interval_steps_per_second: 6.697, epoch: 10.5085[0m
[32m[2022-09-05 13:06:47,571] [    INFO][0m - loss: 0.38614428, learning_rate: 7.887005649717515e-06, global_step: 1870, interval_runtime: 1.5025, interval_samples_per_second: 5.324, interval_steps_per_second: 6.655, epoch: 10.565[0m
[32m[2022-09-05 13:06:49,069] [    INFO][0m - loss: 0.36681607, learning_rate: 7.875706214689265e-06, global_step: 1880, interval_runtime: 1.4977, interval_samples_per_second: 5.341, interval_steps_per_second: 6.677, epoch: 10.6215[0m
[32m[2022-09-05 13:06:50,564] [    INFO][0m - loss: 0.37153635, learning_rate: 7.864406779661017e-06, global_step: 1890, interval_runtime: 1.4948, interval_samples_per_second: 5.352, interval_steps_per_second: 6.69, epoch: 10.678[0m
[32m[2022-09-05 13:06:52,058] [    INFO][0m - loss: 0.2236388, learning_rate: 7.853107344632768e-06, global_step: 1900, interval_runtime: 1.4941, interval_samples_per_second: 5.354, interval_steps_per_second: 6.693, epoch: 10.7345[0m
[32m[2022-09-05 13:06:52,058] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:06:52,058] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:06:52,059] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:06:52,059] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:06:52,059] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:07:03,879] [    INFO][0m - eval_loss: 0.352571964263916, eval_accuracy: 0.5841584158415841, eval_runtime: 11.8196, eval_samples_per_second: 119.632, eval_steps_per_second: 14.975, epoch: 10.7345[0m
[32m[2022-09-05 13:07:03,936] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-1900[0m
[32m[2022-09-05 13:07:03,936] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:07:05,686] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-1900/tokenizer_config.json[0m
[32m[2022-09-05 13:07:05,686] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-1900/special_tokens_map.json[0m
[32m[2022-09-05 13:07:09,875] [    INFO][0m - loss: 0.2590735, learning_rate: 7.84180790960452e-06, global_step: 1910, interval_runtime: 17.8171, interval_samples_per_second: 0.449, interval_steps_per_second: 0.561, epoch: 10.791[0m
[32m[2022-09-05 13:07:11,366] [    INFO][0m - loss: 0.30743897, learning_rate: 7.830508474576271e-06, global_step: 1920, interval_runtime: 1.4907, interval_samples_per_second: 5.367, interval_steps_per_second: 6.708, epoch: 10.8475[0m
[32m[2022-09-05 13:07:12,856] [    INFO][0m - loss: 0.4354825, learning_rate: 7.819209039548023e-06, global_step: 1930, interval_runtime: 1.4905, interval_samples_per_second: 5.367, interval_steps_per_second: 6.709, epoch: 10.904[0m
[32m[2022-09-05 13:07:14,354] [    INFO][0m - loss: 0.31690795, learning_rate: 7.807909604519774e-06, global_step: 1940, interval_runtime: 1.4981, interval_samples_per_second: 5.34, interval_steps_per_second: 6.675, epoch: 10.9605[0m
[32m[2022-09-05 13:07:15,921] [    INFO][0m - loss: 0.22834973, learning_rate: 7.796610169491526e-06, global_step: 1950, interval_runtime: 1.5665, interval_samples_per_second: 5.107, interval_steps_per_second: 6.384, epoch: 11.0169[0m
[32m[2022-09-05 13:07:17,417] [    INFO][0m - loss: 0.33443851, learning_rate: 7.785310734463277e-06, global_step: 1960, interval_runtime: 1.4959, interval_samples_per_second: 5.348, interval_steps_per_second: 6.685, epoch: 11.0734[0m
[32m[2022-09-05 13:07:18,914] [    INFO][0m - loss: 0.14805861, learning_rate: 7.77401129943503e-06, global_step: 1970, interval_runtime: 1.4975, interval_samples_per_second: 5.342, interval_steps_per_second: 6.678, epoch: 11.1299[0m
[32m[2022-09-05 13:07:20,416] [    INFO][0m - loss: 0.18458743, learning_rate: 7.76271186440678e-06, global_step: 1980, interval_runtime: 1.5016, interval_samples_per_second: 5.328, interval_steps_per_second: 6.66, epoch: 11.1864[0m
[32m[2022-09-05 13:07:21,919] [    INFO][0m - loss: 0.24494519, learning_rate: 7.751412429378532e-06, global_step: 1990, interval_runtime: 1.503, interval_samples_per_second: 5.323, interval_steps_per_second: 6.654, epoch: 11.2429[0m
[32m[2022-09-05 13:07:23,414] [    INFO][0m - loss: 0.22174659, learning_rate: 7.740112994350283e-06, global_step: 2000, interval_runtime: 1.4956, interval_samples_per_second: 5.349, interval_steps_per_second: 6.686, epoch: 11.2994[0m
[32m[2022-09-05 13:07:23,415] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:07:23,415] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:07:23,415] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:07:23,415] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:07:23,415] [    INFO][0m -   Total prediction steps = 177[0m
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[5 4 3 2 6 2 3 4 2 2 4 0 2 1 3 3 0 2 2 1 2 2 4 5 6 6 2 2 2 6 4 3 4 5 3 4 1
 1 3 6 0 0 2 2 6 2 2 1 2 6 4 0 2 5 3 4 0 2 6 5 6 6 0 3 6 6 6 5 6 2 1 6 6 3
 0 4 3 6 6 6 3 5 1 5 4 4 6 6 2 3 2 1 5 4 3 5 4 6 4 4 5 4 4 2 5 0 4 0 3 3 0
 5 4 2 6 0 4 4 0 2 4 1 0 5 0 1 5 1 2 1 5 4 6 5 5 0 0 2 0 3 6 0 6 6 5 4 4 2
 2 0 3 4 0 3 4 5 6 0 5 3 5 6 0 5 4 4 0 1 0 0 0 4 0 5 0 2 4 3 0 6 2 2 1 1 0
 4 5 5 1 0 6 1 1 6 2 1 6 6 1 6 0 3]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[3 2 0 2 2 2 3 4 2 2 2 2 2 2 1 0 0 2 2 3 2 6 4 5 1 6 2 2 2 4 4 3 4 3 3 4 1
 4 3 6 0 0 2 3 6 2 3 3 2 6 4 5 2 0 3 0 0 6 6 5 6 6 3 2 6 6 0 5 6 6 2 4 6 3
 0 5 0 6 6 6 2 5 5 1 4 1 6 5 5 3 0 6 5 4 4 4 4 6 4 4 4 4 4 6 3 0 4 0 3 3 4
 5 4 5 4 0 4 4 0 2 2 0 5 5 1 0 5 1 5 1 5 4 6 5 5 0 0 2 5 5 6 4 5 4 5 4 4 0
 5 0 0 0 0 3 0 5 6 0 5 3 3 6 0 0 0 4 0 1 0 0 0 2 0 4 0 2 4 3 3 6 3 3 5 1 0
 4 5 5 1 1 3 1 1 0 0 1 6 6 1 1 2 4]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[0 2 0 2 4 2 3 4 2 3 2 2 2 2 1 4 0 2 2 3 2 6 4 5 1 2 2 2 2 4 4 3 4 3 3 4 1
 1 3 2 0 0 2 2 6 2 3 3 2 6 4 0 5 5 3 3 0 4 6 1 6 6 5 3 6 6 6 3 0 6 3 4 6 3
 0 5 3 1 6 6 3 4 5 5 4 4 6 0 4 0 2 1 5 4 3 4 4 6 4 4 4 4 4 6 0 4 0 0 3 3 4
 5 4 5 4 0 4 4 4 2 4 1 5 5 1 2 5 1 2 2 5 4 6 5 2 0 0 2 0 5 6 4 5 5 5 4 4 0
 5 0 0 5 0 3 4 5 6 1 5 1 3 6 0 1 3 4 0 1 1 0 0 6 2 4 0 2 5 3 0 5 3 0 3 1 0
 4 5 5 3 1 3 1 1 6 0 1 6 6 1 1 2 4]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[3 2 0 3 4 2 2 2 2 3 2 2 2 2 2 1 6 2 2 3 2 6 4 5 6 2 2 1 2 4 4 3 4 3 3 5 3
 0 3 4 3 0 2 2 3 2 3 3 1 5 4 5 5 3 3 3 0 6 0 5 6 6 6 2 6 0 6 3 0 6 1 4 4 3
 0 6 3 1 1 6 2 5 5 5 4 6 6 0 5 6 2 4 5 4 3 4 4 4 4 4 4 4 4 6 3 2 4 0 2 1 4
 2 4 4 4 0 4 4 6 2 3 5 5 5 0 0 5 1 5 2 5 0 6 5 5 0 2 5 2 5 6 4 5 4 2 5 4 0
 5 2 0 0 0 3 0 5 6 1 0 1 0 6 0 1 3 0 0 1 0 0 1 6 0 4 0 2 5 1 0 5 3 0 1 6 0
 4 5 5 1 1 3 2 1 0 1 1 6 6 2 1 0 1]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[1 2 5 3 2 2 2 1 2 1 2 2 2 2 0 4 6 2 2 3 2 6 4 2 5 2 2 2 2 4 3 3 3 3 3 1 4
 5 1 4 5 0 3 2 1 3 3 3 1 5 4 5 3 5 3 3 4 6 4 5 6 6 6 2 6 6 3 2 1 6 6 4 0 3
 6 6 3 1 1 6 2 5 5 6 6 3 6 6 4 6 2 5 5 4 4 4 4 1 4 4 2 0 4 6 0 2 0 4 2 4 4
 1 4 4 4 0 4 4 4 4 3 0 5 5 5 5 5 1 5 2 5 5 6 5 5 1 2 5 0 5 6 5 5 5 5 4 5 0
 5 6 3 0 0 3 0 2 6 1 0 0 3 1 2 2 0 4 5 0 0 0 1 3 2 4 0 2 5 1 0 5 1 5 1 6 0
 2 1 5 0 1 3 1 1 0 1 1 6 6 0 6 0 1]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[3 2 5 3 4 2 2 2 2 3 2 2 2 5 0 0 1 2 2 3 2 0 4 2 5 2 2 5 2 4 3 3 3 3 3 5 0
 3 0 3 3 0 3 3 3 3 3 3 1 5 4 5 3 3 3 3 4 6 4 3 6 6 6 0 6 6 6 2 6 2 6 4 6 3
 0 6 3 6 1 6 2 6 1 6 6 6 6 4 4 6 4 5 5 4 4 4 4 1 4 4 2 0 4 6 2 5 4 4 4 4 4
 1 4 4 4 0 4 4 4 4 2 5 5 5 5 5 5 2 5 5 5 5 1 5 5 1 2 5 0 5 6 4 5 3 5 5 4 0
 5 2 3 0 0 0 0 5 6 2 0 0 0 1 0 0 0 6 5 0 0 0 1 3 2 0 0 2 5 1 4 5 1 0 1 1 0
 1 1 5 0 1 3 1 1 0 1 1 6 1 1 6 0 1]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[2 2 5 3 4 2 1 2 2 3 4 1 2 3 0 0 2 2 2 3 2 0 4 2 5 2 2 2 2 4 3 3 3 3 3 5 0
 3 0 3 3 3 0 3 3 3 3 3 1 5 5 5 3 1 3 3 4 6 4 6 6 6 3 0 2 6 6 2 6 6 6 4 6 3
 5 6 6 6 1 6 6 6 1 6 6 6 6 4 4 6 4 5 3 4 4 4 4 1 4 4 2 0 4 6 2 4 4 5 4 4 4
 1 4 4 4 4 4 5 4 4 2 5 5 5 5 5 1 2 5 5 5 5 5 5 5 1 2 5 0 5 5 0 5 3 5 5 4 0
 5 2 3 0 0 0 4 5 6 0 0 0 4 1 0 0 0 2 5 0 0 0 1 3 6 4 0 3 5 1 0 5 1 0 1 1 0
 1 1 1 0 1 3 1 1 0 1 1 6 1 1 6 1 1]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[3 5 5 3 4 2 2 2 2 3 4 1 2 3 2 0 2 2 2 0 2 0 2 2 2 2 2 2 2 4 3 3 2 3 3 1 0
 3 4 4 3 0 0 2 0 3 3 3 1 5 5 5 3 3 3 3 0 6 3 3 6 6 3 0 6 6 3 2 6 6 6 4 6 6
 5 6 3 6 0 6 6 0 1 6 6 0 6 4 4 6 4 5 1 4 4 4 4 1 4 4 4 0 4 6 2 5 4 4 4 4 4
 1 4 3 4 4 4 5 0 4 3 5 5 5 5 5 1 5 5 5 5 5 5 5 5 1 2 5 2 5 6 5 5 3 5 5 4 0
 6 2 0 0 0 0 1 5 6 0 0 0 4 0 0 0 0 1 5 0 0 0 1 3 6 4 1 2 5 1 0 2 1 0 1 1 0
 1 1 1 0 1 3 1 1 0 1 1 6 1 1 6 1 1]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[2 5 5 3 4 2 2 2 2 3 4 1 2 3 2 2 2 2 2 0 2 6 4 2 2 2 2 2 2 4 3 3 2 3 3 1 0
 3 4 4 3 0 0 2 3 3 3 3 1 5 5 5 3 3 3 3 0 6 3 3 6 6 3 0 6 6 3 2 1 6 6 4 6 3
 5 6 3 6 0 6 6 0 1 6 6 6 6 4 4 6 4 5 1 4 4 4 6 1 4 4 4 0 4 4 2 5 4 4 4 4 4
 1 4 3 4 4 4 5 0 4 3 5 6 5 5 5 1 2 5 5 5 5 5 5 5 1 2 5 2 5 6 5 5 3 5 5 4 0
 6 2 3 0 0 0 4 1 0 0 0 0 4 0 0 0 0 1 0 0 0 0 1 1 6 4 1 6 5 1 0 5 1 0 1 1 3
 1 1 4 0 1 3 1 1 0 1 1 6 1 1 6 1 1]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[32m[2022-09-05 13:07:35,221] [    INFO][0m - eval_loss: 0.8514623641967773, eval_accuracy: 0.5544554455445545, eval_runtime: 11.805, eval_samples_per_second: 119.78, eval_steps_per_second: 14.994, epoch: 11.2994[0m
[32m[2022-09-05 13:07:35,279] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-2000[0m
[32m[2022-09-05 13:07:35,279] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:07:36,856] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-2000/tokenizer_config.json[0m
[32m[2022-09-05 13:07:36,857] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-2000/special_tokens_map.json[0m
[32m[2022-09-05 13:07:41,152] [    INFO][0m - loss: 0.39897308, learning_rate: 7.728813559322035e-06, global_step: 2010, interval_runtime: 17.7376, interval_samples_per_second: 0.451, interval_steps_per_second: 0.564, epoch: 11.3559[0m
[32m[2022-09-05 13:07:42,643] [    INFO][0m - loss: 0.17687045, learning_rate: 7.717514124293786e-06, global_step: 2020, interval_runtime: 1.4913, interval_samples_per_second: 5.365, interval_steps_per_second: 6.706, epoch: 11.4124[0m
[32m[2022-09-05 13:07:44,136] [    INFO][0m - loss: 0.45891423, learning_rate: 7.706214689265538e-06, global_step: 2030, interval_runtime: 1.4928, interval_samples_per_second: 5.359, interval_steps_per_second: 6.699, epoch: 11.4689[0m
[32m[2022-09-05 13:07:45,631] [    INFO][0m - loss: 0.15598261, learning_rate: 7.694915254237289e-06, global_step: 2040, interval_runtime: 1.4952, interval_samples_per_second: 5.35, interval_steps_per_second: 6.688, epoch: 11.5254[0m
[32m[2022-09-05 13:07:47,131] [    INFO][0m - loss: 0.28427114, learning_rate: 7.68361581920904e-06, global_step: 2050, interval_runtime: 1.4993, interval_samples_per_second: 5.336, interval_steps_per_second: 6.67, epoch: 11.5819[0m
[32m[2022-09-05 13:07:48,626] [    INFO][0m - loss: 0.16381615, learning_rate: 7.672316384180792e-06, global_step: 2060, interval_runtime: 1.4957, interval_samples_per_second: 5.349, interval_steps_per_second: 6.686, epoch: 11.6384[0m
[32m[2022-09-05 13:07:50,124] [    INFO][0m - loss: 0.61462412, learning_rate: 7.661016949152543e-06, global_step: 2070, interval_runtime: 1.498, interval_samples_per_second: 5.341, interval_steps_per_second: 6.676, epoch: 11.6949[0m
[32m[2022-09-05 13:07:51,622] [    INFO][0m - loss: 0.36296151, learning_rate: 7.649717514124295e-06, global_step: 2080, interval_runtime: 1.4975, interval_samples_per_second: 5.342, interval_steps_per_second: 6.678, epoch: 11.7514[0m
[32m[2022-09-05 13:07:53,118] [    INFO][0m - loss: 0.22110622, learning_rate: 7.638418079096046e-06, global_step: 2090, interval_runtime: 1.4966, interval_samples_per_second: 5.345, interval_steps_per_second: 6.682, epoch: 11.8079[0m
[32m[2022-09-05 13:07:54,616] [    INFO][0m - loss: 0.30332563, learning_rate: 7.627118644067797e-06, global_step: 2100, interval_runtime: 1.4971, interval_samples_per_second: 5.344, interval_steps_per_second: 6.679, epoch: 11.8644[0m
[32m[2022-09-05 13:07:54,616] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:07:54,616] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:07:54,616] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:07:54,616] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:07:54,616] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:08:06,424] [    INFO][0m - eval_loss: 0.7609745860099792, eval_accuracy: 0.5594059405940595, eval_runtime: 11.8071, eval_samples_per_second: 119.758, eval_steps_per_second: 14.991, epoch: 11.8644[0m
[32m[2022-09-05 13:08:06,482] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-2100[0m
[32m[2022-09-05 13:08:06,482] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:08:08,208] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-2100/tokenizer_config.json[0m
[32m[2022-09-05 13:08:08,209] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-2100/special_tokens_map.json[0m
[32m[2022-09-05 13:08:11,043] [    INFO][0m - 
Training completed. 
[0m
[32m[2022-09-05 13:08:11,043] [    INFO][0m - Loading best model from ./checkpoints_chid/checkpoint-1700 (score: 0.594059405940594).[0m
[32m[2022-09-05 13:08:13,887] [    INFO][0m - train_runtime: 750.9111, train_samples_per_second: 94.152, train_steps_per_second: 11.786, train_loss: 0.4543156947408404, epoch: 11.8644[0m
[32m[2022-09-05 13:08:13,889] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/[0m
[32m[2022-09-05 13:08:13,889] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:08:17,231] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/tokenizer_config.json[0m
[32m[2022-09-05 13:08:17,231] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/special_tokens_map.json[0m
[32m[2022-09-05 13:08:17,233] [    INFO][0m - ***** train metrics *****[0m
[32m[2022-09-05 13:08:17,233] [    INFO][0m -   epoch                    =    11.8644[0m
[32m[2022-09-05 13:08:17,233] [    INFO][0m -   train_loss               =     0.4543[0m
[32m[2022-09-05 13:08:17,233] [    INFO][0m -   train_runtime            = 0:12:30.91[0m
[32m[2022-09-05 13:08:17,233] [    INFO][0m -   train_samples_per_second =     94.152[0m
[32m[2022-09-05 13:08:17,233] [    INFO][0m -   train_steps_per_second   =     11.786[0m
[32m[2022-09-05 13:08:17,253] [    INFO][0m - ***** Running Prediction *****[0m
[32m[2022-09-05 13:08:17,253] [    INFO][0m -   Num examples = 14014[0m
[32m[2022-09-05 13:08:17,253] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:08:17,253] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:08:17,253] [    INFO][0m -   Total prediction steps = 1752[0m
[32m[2022-09-05 13:12:57,942] [    INFO][0m - ***** test metrics *****[0m
[32m[2022-09-05 13:12:57,943] [    INFO][0m -   test_accuracy           =     0.5644[0m
[32m[2022-09-05 13:12:57,943] [    INFO][0m -   test_loss               =     0.3544[0m
[32m[2022-09-05 13:12:57,943] [    INFO][0m -   test_runtime            = 0:04:40.68[0m
[32m[2022-09-05 13:12:57,943] [    INFO][0m -   test_samples_per_second =     49.927[0m
[32m[2022-09-05 13:12:57,943] [    INFO][0m -   test_steps_per_second   =      6.242[0m
[33m[2022-09-05 13:13:16,458] [ WARNING][0m - evaluation_strategy reset to IntervalStrategy.STEPS for do_eval is True. you can also set evaluation_strategy='epoch'.[0m
[32m[2022-09-05 13:13:16,459] [    INFO][0m - The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).[0m
[32m[2022-09-05 13:13:16,459] [    INFO][0m - ============================================================[0m
[32m[2022-09-05 13:13:16,459] [    INFO][0m -      Model Configuration Arguments      [0m
[32m[2022-09-05 13:13:16,459] [    INFO][0m - paddle commit id              :65f388690048d0965ec7d3b43fb6ee9d8c6dee7c[0m
[32m[2022-09-05 13:13:16,459] [    INFO][0m - do_save                       :True[0m
[32m[2022-09-05 13:13:16,459] [    INFO][0m - do_test                       :True[0m
[32m[2022-09-05 13:13:16,459] [    INFO][0m - early_stop_patience           :4[0m
[32m[2022-09-05 13:13:16,459] [    INFO][0m - export_type                   :paddle[0m
[32m[2022-09-05 13:13:16,459] [    INFO][0m - model_name_or_path            :ernie-3.0-base-zh[0m
[32m[2022-09-05 13:13:16,460] [    INFO][0m - [0m
[32m[2022-09-05 13:13:16,460] [    INFO][0m - ============================================================[0m
[32m[2022-09-05 13:13:16,460] [    INFO][0m -       Data Configuration Arguments      [0m
[32m[2022-09-05 13:13:16,460] [    INFO][0m - paddle commit id              :65f388690048d0965ec7d3b43fb6ee9d8c6dee7c[0m
[32m[2022-09-05 13:13:16,460] [    INFO][0m - encoder_hidden_size           :200[0m
[32m[2022-09-05 13:13:16,460] [    INFO][0m - prompt                        :[0m
[32m[2022-09-05 13:13:16,460] [    INFO][0m - soft_encoder                  :lstm[0m
[32m[2022-09-05 13:13:16,460] [    INFO][0m - split_id                      :few_all[0m
[32m[2022-09-05 13:13:16,460] [    INFO][0m - task_name                     :chid[0m
[32m[2022-09-05 13:13:16,460] [    INFO][0m - [0m
[32m[2022-09-05 13:13:16,461] [    INFO][0m - Already cached /ssd2/wanghuijuan03/.paddlenlp/models/ernie-3.0-base-zh/ernie_3.0_base_zh.pdparams[0m
[32m[2022-09-05 13:13:18,073] [    INFO][0m - Already cached /ssd2/wanghuijuan03/.paddlenlp/models/ernie-3.0-base-zh/ernie_3.0_base_zh_vocab.txt[0m
[32m[2022-09-05 13:13:18,095] [    INFO][0m - tokenizer config file saved in /ssd2/wanghuijuan03/.paddlenlp/models/ernie-3.0-base-zh/tokenizer_config.json[0m
[32m[2022-09-05 13:13:18,095] [    INFO][0m - Special tokens file saved in /ssd2/wanghuijuan03/.paddlenlp/models/ernie-3.0-base-zh/special_tokens_map.json[0m
[32m[2022-09-05 13:13:18,096] [    INFO][0m - Using template: [{'add_prefix_space': '', 'text': 'text_a'}, {'add_prefix_space': '', 'hard': 'Êñá‰∏≠ÊàêËØ≠ÊòØÂê¶Ê≠£Á°ÆÔºü'}, {'add_prefix_space': '', 'mask': None}][0m
2022-09-05 13:13:18,099 INFO [download.py:119] unique_endpoints {''}
[32m[2022-09-05 13:13:18,188] [    INFO][0m - ============================================================[0m
[32m[2022-09-05 13:13:18,188] [    INFO][0m -     Training Configuration Arguments    [0m
[32m[2022-09-05 13:13:18,188] [    INFO][0m - paddle commit id              :65f388690048d0965ec7d3b43fb6ee9d8c6dee7c[0m
[32m[2022-09-05 13:13:18,189] [    INFO][0m - _no_sync_in_gradient_accumulation:True[0m
[32m[2022-09-05 13:13:18,189] [    INFO][0m - adam_beta1                    :0.9[0m
[32m[2022-09-05 13:13:18,189] [    INFO][0m - adam_beta2                    :0.999[0m
[32m[2022-09-05 13:13:18,189] [    INFO][0m - adam_epsilon                  :1e-08[0m
[32m[2022-09-05 13:13:18,189] [    INFO][0m - alpha_rdrop                   :5.0[0m
[32m[2022-09-05 13:13:18,189] [    INFO][0m - alpha_rgl                     :0.5[0m
[32m[2022-09-05 13:13:18,189] [    INFO][0m - current_device                :gpu:0[0m
[32m[2022-09-05 13:13:18,189] [    INFO][0m - dataloader_drop_last          :False[0m
[32m[2022-09-05 13:13:18,189] [    INFO][0m - dataloader_num_workers        :0[0m
[32m[2022-09-05 13:13:18,189] [    INFO][0m - device                        :gpu[0m
[32m[2022-09-05 13:13:18,189] [    INFO][0m - disable_tqdm                  :True[0m
[32m[2022-09-05 13:13:18,190] [    INFO][0m - do_eval                       :True[0m
[32m[2022-09-05 13:13:18,190] [    INFO][0m - do_export                     :False[0m
[32m[2022-09-05 13:13:18,190] [    INFO][0m - do_predict                    :False[0m
[32m[2022-09-05 13:13:18,190] [    INFO][0m - do_train                      :True[0m
[32m[2022-09-05 13:13:18,190] [    INFO][0m - eval_batch_size               :8[0m
[32m[2022-09-05 13:13:18,190] [    INFO][0m - eval_steps                    :100[0m
[32m[2022-09-05 13:13:18,190] [    INFO][0m - evaluation_strategy           :IntervalStrategy.STEPS[0m
[32m[2022-09-05 13:13:18,190] [    INFO][0m - first_max_length              :None[0m
[32m[2022-09-05 13:13:18,190] [    INFO][0m - fp16                          :False[0m
[32m[2022-09-05 13:13:18,190] [    INFO][0m - fp16_opt_level                :O1[0m
[32m[2022-09-05 13:13:18,190] [    INFO][0m - freeze_dropout                :False[0m
[32m[2022-09-05 13:13:18,190] [    INFO][0m - freeze_plm                    :False[0m
[32m[2022-09-05 13:13:18,190] [    INFO][0m - gradient_accumulation_steps   :1[0m
[32m[2022-09-05 13:13:18,191] [    INFO][0m - greater_is_better             :True[0m
[32m[2022-09-05 13:13:18,191] [    INFO][0m - ignore_data_skip              :False[0m
[32m[2022-09-05 13:13:18,191] [    INFO][0m - label_names                   :None[0m
[32m[2022-09-05 13:13:18,191] [    INFO][0m - learning_rate                 :1e-05[0m
[32m[2022-09-05 13:13:18,191] [    INFO][0m - load_best_model_at_end        :True[0m
[32m[2022-09-05 13:13:18,191] [    INFO][0m - local_process_index           :0[0m
[32m[2022-09-05 13:13:18,191] [    INFO][0m - local_rank                    :-1[0m
[32m[2022-09-05 13:13:18,191] [    INFO][0m - log_level                     :-1[0m
[32m[2022-09-05 13:13:18,191] [    INFO][0m - log_level_replica             :-1[0m
[32m[2022-09-05 13:13:18,191] [    INFO][0m - log_on_each_node              :True[0m
[32m[2022-09-05 13:13:18,191] [    INFO][0m - logging_dir                   :./checkpoints_chid/runs/Sep05_13-13-16_instance-3bwob41y-01[0m
[32m[2022-09-05 13:13:18,191] [    INFO][0m - logging_first_step            :False[0m
[32m[2022-09-05 13:13:18,191] [    INFO][0m - logging_steps                 :10[0m
[32m[2022-09-05 13:13:18,191] [    INFO][0m - logging_strategy              :IntervalStrategy.STEPS[0m
[32m[2022-09-05 13:13:18,192] [    INFO][0m - lr_scheduler_type             :SchedulerType.LINEAR[0m
[32m[2022-09-05 13:13:18,192] [    INFO][0m - max_grad_norm                 :1.0[0m
[32m[2022-09-05 13:13:18,192] [    INFO][0m - max_seq_length                :256[0m
[32m[2022-09-05 13:13:18,192] [    INFO][0m - max_steps                     :-1[0m
[32m[2022-09-05 13:13:18,192] [    INFO][0m - metric_for_best_model         :accuracy[0m
[32m[2022-09-05 13:13:18,192] [    INFO][0m - minimum_eval_times            :None[0m
[32m[2022-09-05 13:13:18,192] [    INFO][0m - no_cuda                       :False[0m
[32m[2022-09-05 13:13:18,192] [    INFO][0m - num_train_epochs              :50.0[0m
[32m[2022-09-05 13:13:18,192] [    INFO][0m - optim                         :OptimizerNames.ADAMW[0m
[32m[2022-09-05 13:13:18,192] [    INFO][0m - other_max_length              :None[0m
[32m[2022-09-05 13:13:18,192] [    INFO][0m - output_dir                    :./checkpoints_chid/[0m
[32m[2022-09-05 13:13:18,192] [    INFO][0m - overwrite_output_dir          :False[0m
[32m[2022-09-05 13:13:18,192] [    INFO][0m - past_index                    :-1[0m
[32m[2022-09-05 13:13:18,193] [    INFO][0m - per_device_eval_batch_size    :8[0m
[32m[2022-09-05 13:13:18,193] [    INFO][0m - per_device_train_batch_size   :8[0m
[32m[2022-09-05 13:13:18,193] [    INFO][0m - ppt_adam_beta1                :0.9[0m
[32m[2022-09-05 13:13:18,193] [    INFO][0m - ppt_adam_beta2                :0.999[0m
[32m[2022-09-05 13:13:18,193] [    INFO][0m - ppt_adam_epsilon              :1e-08[0m
[32m[2022-09-05 13:13:18,193] [    INFO][0m - ppt_learning_rate             :1e-05[0m
[32m[2022-09-05 13:13:18,193] [    INFO][0m - ppt_weight_decay              :0.0[0m
[32m[2022-09-05 13:13:18,193] [    INFO][0m - prediction_loss_only          :False[0m
[32m[2022-09-05 13:13:18,193] [    INFO][0m - process_index                 :0[0m
[32m[2022-09-05 13:13:18,193] [    INFO][0m - remove_unused_columns         :True[0m
[32m[2022-09-05 13:13:18,193] [    INFO][0m - report_to                     :['visualdl'][0m
[32m[2022-09-05 13:13:18,193] [    INFO][0m - resume_from_checkpoint        :None[0m
[32m[2022-09-05 13:13:18,193] [    INFO][0m - run_name                      :./checkpoints_chid/[0m
[32m[2022-09-05 13:13:18,194] [    INFO][0m - save_on_each_node             :False[0m
[32m[2022-09-05 13:13:18,194] [    INFO][0m - save_steps                    :100[0m
[32m[2022-09-05 13:13:18,194] [    INFO][0m - save_strategy                 :IntervalStrategy.STEPS[0m
[32m[2022-09-05 13:13:18,194] [    INFO][0m - save_total_limit              :None[0m
[32m[2022-09-05 13:13:18,194] [    INFO][0m - scale_loss                    :32768[0m
[32m[2022-09-05 13:13:18,194] [    INFO][0m - seed                          :42[0m
[32m[2022-09-05 13:13:18,194] [    INFO][0m - should_log                    :True[0m
[32m[2022-09-05 13:13:18,194] [    INFO][0m - should_save                   :True[0m
[32m[2022-09-05 13:13:18,194] [    INFO][0m - task_type                     :multi-class[0m
[32m[2022-09-05 13:13:18,194] [    INFO][0m - train_batch_size              :8[0m
[32m[2022-09-05 13:13:18,194] [    INFO][0m - truncate_mode                 :tail[0m
[32m[2022-09-05 13:13:18,194] [    INFO][0m - use_rdrop                     :False[0m
[32m[2022-09-05 13:13:18,194] [    INFO][0m - use_rgl                       :False[0m
[32m[2022-09-05 13:13:18,195] [    INFO][0m - warmup_ratio                  :0.0[0m
[32m[2022-09-05 13:13:18,195] [    INFO][0m - warmup_steps                  :0[0m
[32m[2022-09-05 13:13:18,195] [    INFO][0m - weight_decay                  :0.0[0m
[32m[2022-09-05 13:13:18,195] [    INFO][0m - world_size                    :1[0m
[32m[2022-09-05 13:13:18,195] [    INFO][0m - [0m
[32m[2022-09-05 13:13:18,196] [    INFO][0m - ***** Running training *****[0m
[32m[2022-09-05 13:13:18,196] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:13:18,197] [    INFO][0m -   Num Epochs = 50[0m
[32m[2022-09-05 13:13:18,197] [    INFO][0m -   Instantaneous batch size per device = 8[0m
[32m[2022-09-05 13:13:18,197] [    INFO][0m -   Total train batch size (w. parallel, distributed & accumulation) = 8[0m
[32m[2022-09-05 13:13:18,197] [    INFO][0m -   Gradient Accumulation steps = 1[0m
[32m[2022-09-05 13:13:18,197] [    INFO][0m -   Total optimization steps = 8850.0[0m
[32m[2022-09-05 13:13:18,197] [    INFO][0m -   Total num train samples = 70700[0m
[32m[2022-09-05 13:13:19,746] [    INFO][0m - loss: 6.41117706, learning_rate: 9.988700564971753e-06, global_step: 10, interval_runtime: 1.5486, interval_samples_per_second: 5.166, interval_steps_per_second: 6.457, epoch: 0.0565[0m
[32m[2022-09-05 13:13:21,232] [    INFO][0m - loss: 0.83077965, learning_rate: 9.977401129943504e-06, global_step: 20, interval_runtime: 1.4853, interval_samples_per_second: 5.386, interval_steps_per_second: 6.733, epoch: 0.113[0m
[32m[2022-09-05 13:13:22,715] [    INFO][0m - loss: 0.73049583, learning_rate: 9.966101694915256e-06, global_step: 30, interval_runtime: 1.4832, interval_samples_per_second: 5.394, interval_steps_per_second: 6.742, epoch: 0.1695[0m
[32m[2022-09-05 13:13:24,194] [    INFO][0m - loss: 0.73157792, learning_rate: 9.954802259887007e-06, global_step: 40, interval_runtime: 1.4789, interval_samples_per_second: 5.409, interval_steps_per_second: 6.762, epoch: 0.226[0m
[32m[2022-09-05 13:13:25,675] [    INFO][0m - loss: 0.53051877, learning_rate: 9.943502824858759e-06, global_step: 50, interval_runtime: 1.4816, interval_samples_per_second: 5.4, interval_steps_per_second: 6.75, epoch: 0.2825[0m
[32m[2022-09-05 13:13:27,159] [    INFO][0m - loss: 0.40829582, learning_rate: 9.93220338983051e-06, global_step: 60, interval_runtime: 1.4836, interval_samples_per_second: 5.392, interval_steps_per_second: 6.741, epoch: 0.339[0m
[32m[2022-09-05 13:13:28,643] [    INFO][0m - loss: 0.8010046, learning_rate: 9.92090395480226e-06, global_step: 70, interval_runtime: 1.4841, interval_samples_per_second: 5.39, interval_steps_per_second: 6.738, epoch: 0.3955[0m
[32m[2022-09-05 13:13:30,126] [    INFO][0m - loss: 0.64876237, learning_rate: 9.909604519774013e-06, global_step: 80, interval_runtime: 1.4826, interval_samples_per_second: 5.396, interval_steps_per_second: 6.745, epoch: 0.452[0m
[32m[2022-09-05 13:13:31,610] [    INFO][0m - loss: 0.57373872, learning_rate: 9.898305084745763e-06, global_step: 90, interval_runtime: 1.4842, interval_samples_per_second: 5.39, interval_steps_per_second: 6.738, epoch: 0.5085[0m
[32m[2022-09-05 13:13:33,096] [    INFO][0m - loss: 0.46160889, learning_rate: 9.887005649717516e-06, global_step: 100, interval_runtime: 1.4864, interval_samples_per_second: 5.382, interval_steps_per_second: 6.728, epoch: 0.565[0m
[32m[2022-09-05 13:13:33,097] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:13:33,097] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:13:33,097] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:13:33,097] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:13:33,097] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:13:44,044] [    INFO][0m - eval_loss: 0.4349440634250641, eval_accuracy: 0.1782178217821782, eval_runtime: 10.9468, eval_samples_per_second: 129.171, eval_steps_per_second: 16.169, epoch: 0.565[0m
[32m[2022-09-05 13:13:44,073] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-100[0m
[32m[2022-09-05 13:13:44,073] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:13:47,232] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-100/tokenizer_config.json[0m
[32m[2022-09-05 13:13:47,232] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-100/special_tokens_map.json[0m
[32m[2022-09-05 13:13:53,910] [    INFO][0m - loss: 0.5012485, learning_rate: 9.875706214689266e-06, global_step: 110, interval_runtime: 20.8144, interval_samples_per_second: 0.384, interval_steps_per_second: 0.48, epoch: 0.6215[0m
[32m[2022-09-05 13:13:55,396] [    INFO][0m - loss: 0.41731315, learning_rate: 9.864406779661017e-06, global_step: 120, interval_runtime: 1.4852, interval_samples_per_second: 5.386, interval_steps_per_second: 6.733, epoch: 0.678[0m
[32m[2022-09-05 13:13:56,877] [    INFO][0m - loss: 0.49975686, learning_rate: 9.85310734463277e-06, global_step: 130, interval_runtime: 1.4808, interval_samples_per_second: 5.402, interval_steps_per_second: 6.753, epoch: 0.7345[0m
[32m[2022-09-05 13:13:58,360] [    INFO][0m - loss: 0.57546616, learning_rate: 9.84180790960452e-06, global_step: 140, interval_runtime: 1.4834, interval_samples_per_second: 5.393, interval_steps_per_second: 6.741, epoch: 0.791[0m
[32m[2022-09-05 13:13:59,845] [    INFO][0m - loss: 0.5483263, learning_rate: 9.830508474576272e-06, global_step: 150, interval_runtime: 1.4852, interval_samples_per_second: 5.387, interval_steps_per_second: 6.733, epoch: 0.8475[0m
[32m[2022-09-05 13:14:01,330] [    INFO][0m - loss: 0.58812952, learning_rate: 9.819209039548023e-06, global_step: 160, interval_runtime: 1.4854, interval_samples_per_second: 5.386, interval_steps_per_second: 6.732, epoch: 0.904[0m
[32m[2022-09-05 13:14:02,818] [    INFO][0m - loss: 0.47958641, learning_rate: 9.807909604519775e-06, global_step: 170, interval_runtime: 1.4872, interval_samples_per_second: 5.379, interval_steps_per_second: 6.724, epoch: 0.9605[0m
[32m[2022-09-05 13:14:04,319] [    INFO][0m - loss: 0.41309743, learning_rate: 9.796610169491526e-06, global_step: 180, interval_runtime: 1.501, interval_samples_per_second: 5.33, interval_steps_per_second: 6.662, epoch: 1.0169[0m
[32m[2022-09-05 13:14:05,807] [    INFO][0m - loss: 0.59461226, learning_rate: 9.785310734463278e-06, global_step: 190, interval_runtime: 1.4879, interval_samples_per_second: 5.377, interval_steps_per_second: 6.721, epoch: 1.0734[0m
[32m[2022-09-05 13:14:07,295] [    INFO][0m - loss: 0.46333652, learning_rate: 9.774011299435029e-06, global_step: 200, interval_runtime: 1.4888, interval_samples_per_second: 5.373, interval_steps_per_second: 6.717, epoch: 1.1299[0m
[32m[2022-09-05 13:14:07,296] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:14:07,296] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:14:07,296] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:14:07,296] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:14:07,296] [    INFO][0m -   Total prediction steps = 177[0m
[2 0 5 3 4 2 2 2 2 0 4 1 2 0 2 2 2 2 2 0 2 6 4 2 2 2 2 2 2 4 3 3 2 3 3 5 0
 3 4 4 3 0 0 3 3 3 3 3 1 4 5 5 3 3 3 3 1 6 3 2 6 6 3 0 2 6 3 2 1 6 6 4 6 6
 5 6 6 6 4 6 2 6 1 6 6 6 6 4 4 5 4 5 1 2 4 4 6 3 4 4 4 0 4 6 4 5 0 4 2 4 4
 1 4 3 4 4 4 5 0 4 2 5 6 5 5 5 1 1 5 5 5 5 3 5 5 1 2 5 2 5 4 0 5 3 5 5 4 0
 0 2 3 0 0 0 4 5 0 2 0 0 4 1 0 0 0 3 0 0 0 0 1 3 6 0 0 3 5 1 0 2 1 0 1 1 3
 2 1 4 0 1 3 1 1 5 1 1 6 1 1 6 1 1]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[3 4 0 3 3 2 2 2 2 3 4 1 2 0 2 2 2 2 2 0 2 6 2 2 2 2 2 3 2 4 3 3 2 3 3 5 0
 3 4 3 3 0 5 3 1 3 3 3 1 1 5 5 3 3 3 3 1 6 3 2 6 6 6 0 6 6 3 2 1 6 6 4 6 3
 5 6 3 6 1 4 6 6 1 6 6 6 6 4 4 5 4 5 5 4 4 4 6 3 4 4 4 0 4 1 2 5 0 4 2 4 4
 1 4 3 5 4 4 5 0 4 3 5 6 5 5 5 1 2 5 5 5 5 3 5 5 1 2 5 2 5 4 5 5 3 5 5 4 0
 2 2 0 0 0 0 4 5 6 0 0 0 4 0 0 0 0 1 5 0 0 0 1 1 6 4 0 3 0 1 0 2 1 3 1 1 3
 1 1 4 1 1 3 1 1 5 1 1 6 1 1 6 1 1]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[4 1 1 ... 1 1 2]
[1 1 1 ... 1 1 1]
0
= 0 ===================
[('Èîô', 12012)]
----------
[('Ê≠£', 12012)]
----------
[('ËØØ', 10144), ('Á°Æ', 1868)]
----------
[('Á°Æ', 10144), ('ËØØ', 1868)]
----------
[('ÂáÜ', 4715), ('Èáç', 3902), ('Áªù', 562), ('Â§±', 406), ('ÈÉ®', 337), ('Âèç', 235), ('ÊÅ∞', 234), ('Ë≠¶', 173), ('ÂØπ', 162), ('‰∏ç', 156), ('Âøò', 126), ('Ê†á', 116), ('ÂÅè', 101), ('Âêà', 70), ('ÊÄù', 68), ('Ë∞®', 58), ('‰∏Ä', 36), ('ÁóÖ', 30), ('ÁõÆ', 30), ('Áúü', 29), ('‰π±', 25), ('Ê≠™', 22), ('ÂÖ®', 20), ('Êëò', 19), ('Âéü', 16), ('Â•Ω', 15), ('Áã¨', 15), ('Âºï', 12), ('ÂºÇ', 12), ('Áõ∏', 12), ('Âàó', 11), ('‰∫∫', 10), ('ÂÆå', 10), ('ËÆ°', 9), ('Á≤æ', 9), ('Á©∫', 8), ('ÈÅì', 8), ('Èùû', 8), ('ÂÅá', 8), ('Èù¢', 7), ('Âá∫', 6), ('Êîæ', 6), ('ÈóÆ', 5), ('Áõ¥', 5), ('ÂÖ•', 5), ('Êö¥', 5), ('Á∫µ', 5), ('Èïø', 5), ('Â§ß', 5), ('Ëøá', 5), ('Ê∑±', 5), ('‰Ωú', 5), ('‰∏ã', 5), ('Êó†', 4), ('Ê≠â', 4), ('ÂÄí', 4), ('‰∏ä', 4), ('Â∑ß', 4), ('Áªè', 4), ('ÂÜ§', 4), ('Áâπ', 4), ('ÁÇπ', 4), ('Ê≥ï', 4), ('ÁêÜ', 4), ('Êúâ', 4), ('Êàê', 3), ('ÂÅ•', 3), ('‰∫§', 3), ('ÁªÑ', 3), ('Ëã±', 3), ('ÁôΩ', 3), ('Ê∞î', 3), ('ÂÆû', 3), ('ÁßÅ', 3), ('ÁÆÄ', 3), ('ÊÅ∂', 2), ('Êú∫', 2), ('ÈÄâ', 2), ('ÂÖâ', 2), ('ÁΩ™', 2), ('‰π¶', 2), ('Á¶Å', 2), ('ËØö', 2), ('Êòé', 2), ('ÊÑö', 2), ('Áßë', 2), ('Âèë', 2), ('ËΩ¨', 1), ('Ê∞¥', 1), ('Â∑¶', 1), ('Ë°•', 1), ('‰ª£', 1), ('ÂÖ¨', 1), ('Ê®™', 1), ('Ëµ∑', 1), ('Êõ¥', 1), ('‰∏ª', 1), ('Â∏∏', 1), ('Âú∞', 1), ('ËÆæ', 1), ('ËäÇ', 1), ('‰Ωì', 1), ('‰∏≠', 1), ('Â§©', 1), ('Èªò', 1), ('Áóõ', 1), ('Èáé', 1), ('ÊïÖ', 1), ('Ê¥ª', 1), ('Â∞è', 1), ('Áßã', 1), ('Ëé´', 1), ('‰∏â', 1), ('ÂèØ', 1), ('È´ò', 1), ('Êâì', 1), ('Ë¥¥', 1), ('ËÉΩ', 1), ('Âßî', 1), ('ÂâØ', 1), ('ÂÆö', 1), ('ÁΩÆ', 1), ('Ê≠ª', 1), ('Ë∂ä', 1), ('Â§ç', 1), ('Âõû', 1), ('Â¶Ñ', 1), ('ÂºÄ', 1)]
----------
= 1 ===================
[('ËØØ', 12010), ('Á°Æ', 2)]
----------
[('Á°Æ', 12010), ('ËØØ', 2)]
----------
[('Èîô', 12009), ('Ê≠£', 3)]
----------
[('Ê≠£', 11980), ('ÁõÆ', 19), ('‰π±', 4), ('Èù¢', 4), ('Èîô', 3), ('Ê≥ï', 1), ('ÁÇπ', 1)]
----------
[('‰π±', 6254), ('È¢ò', 2299), ('ÁõÆ', 990), ('Âç¥', 285), ('ÁÇπ', 279), ('Ê≥ï', 278), ('Êïà', 241), ('Êçü', 94), ('ÂΩì', 76), ('ÁóÖ', 76), ('Èù¢', 68), ('Â≠¶', 56), ('ÁΩÆ', 43), ('Ëø´', 34), ('‰∏ã', 33), ('Âêà', 33), ('Âàá', 32), ('Ê≠£', 29), ('Âà´', 27), ('ÂøÉ', 27), ('ÁêÜ', 27), ('Ê∞î', 25), ('Â§±', 25), ('Èáç', 24), ('Ëá¥', 24), ('‰∫∫', 22), ('ËÆ°', 19), ('Âá∫', 18), ('ÊúØ', 16), ('Ë∞®', 15), ('Êï¥', 14), ('Â§ñ', 14), ('Â§ç', 14), ('Ê•ö', 12), ('Ëâ≤', 12), ('Âøò', 12), ('ËÆ∞', 11), ('Ê∞¥', 11), ('ÊÄù', 11), ('‰Ωì', 11), ('Èöæ', 11), ('Â∏∏', 10), ('ÂÆû', 9), ('Ê¥ª', 9), ('‰∏ª', 9), ('ÂÆ∂', 9), ('ÂÖ≥', 8), ('Ê≠ª', 8), ('Êûú', 8), ('ÊÄ™', 7), ('ÂºÄ', 7), ('Â£Æ', 7), ('Êñ∞', 7), ('ÈÅì', 7), ('‰πâ', 7), ('ÊÉÖ', 7), ('ËΩ¨', 7), ('Ë¥Ø', 7), ('Âëä', 6), ('Ê†º', 6), ('Êñ≠', 6), ('Áªù', 6), ('Êîæ', 6), ('Ëæπ', 6), ('ÁªÜ', 6), ('Êú¨', 6), ('Á´ã', 6), ('ÂÖ®', 5), ('Âøó', 5), ('ÂºÇ', 5), ('Èïø', 5), ('Ê∑±', 5), ('ÂÆö', 5), ('Âèë', 5), ('ËØÑ', 5), ('Êâã', 4), ('Á®Ω', 4), ('ÈÉ®', 4), ('Âç∞', 4), ('ÊÖé', 4), ('ËÆÆ', 4), ('Âè£', 4), ('‰º†', 4), ('Êä•', 4), ('Ëß£', 3), ('Ê°à', 3), ('Ê†∑', 3), ('Ë∑Ø', 3), ('Ë®Ä', 3), ('Áü≥', 3), ('Ëóè', 3), ('Èáè', 3), ('Êûê', 3), ('‰º™', 3), ('Âèç', 3), ('Áã¨', 3), ('‰ª£', 3), ('ÂõΩ', 3), ('Â∫¶', 3), ('‰πê', 3), ('Â≠ó', 3), ('ÊÄÅ', 2), ('Ê¨°', 2), ('Áªü', 2), ('Âä®', 2), ('ËÉΩ', 2), ('Êñπ', 2), ('Êºè', 2), ('Áªè', 2), ('Êúà', 2), ('‰∏ä', 2), ('ÊÑü', 2), ('Âºï', 2), ('Êâì', 2), ('‰Ωú', 2), ('Â§¥', 2), ('Êô∫', 2), ('Âáª', 2), ('ÊùÇ', 2), ('Êï∞', 2), ('ÊÅØ', 2), ('Èô§', 2), ('ÂÜô', 2), ('ÊÅ∂', 2), ('Âõæ', 2), ('Âè≤', 2), ('Áï•', 1), ('Ë°®', 1), ('Èáä', 1), ('Áßã', 1), ('Â•Ω', 1), ('Èó¥', 1), ('Ëøá', 1), ('Êù•', 1), ('Êóß', 1), ('Á∫¢', 1), ('ÊÄª', 1), ('ÊÉ≥', 1), ('‰∏≠', 1), ('Ëçê', 1), ('Â§ö', 1), ('ÂøΩ', 1), ('Ëôé', 1), ('ËÆæ', 1), ('Âú∞', 1), ('Áâ©', 1), ('Â±Ä', 1), ('ËØï', 1), ('Ê≠™', 1), ('È™ó', 1), ('Âêë', 1), ('ÂÄº', 1), ('Á©∫', 1), ('ÁÅ´', 1), ('Ë∞É', 1), ('ÊÅ∞', 1), ('ÂºÉ', 1), ('Â∏ù', 1), ('Áæé', 1), ('Â¢û', 1), ('Á´†', 1), ('Êòé', 1), ('È¢Ü', 1), ('Âäõ', 1), ('ÂêÉ', 1), ('ÂáÄ', 1), ('Êéâ', 1), ('ÂàÜ', 1), ('È´ò', 1), ('Â•≥', 1), ('Âèò', 1), ('ËΩ¶', 1)]
----------
1
= 0 ===================
[('Èîô', 2002)]
----------
[('Ê≠£', 2002)]
----------
[('Á°Æ', 1059), ('ËØØ', 943)]
----------
[('ËØØ', 1059), ('Á°Æ', 943)]
----------
[('ÂáÜ', 1199), ('Èáç', 646), ('Áªù', 41), ('ÊÅ∞', 31), ('‰∏ç', 11), ('Âèç', 9), ('Ê†á', 8), ('ÂØπ', 6), ('Â§±', 5), ('ÂÅè', 4), ('ÊÄù', 4), ('Âêà', 4), ('Ë≠¶', 4), ('ÈÉ®', 3), ('Áúü', 3), ('ÁõÆ', 2), ('Ê≠™', 2), ('Âøò', 2), ('Ë∞®', 2), ('Èù¢', 1), ('Âá∫', 1), ('Á´ã', 1), ('ÊÑö', 1), ('Áªè', 1), ('ËÆ°', 1), ('ÂÆå', 1), ('ËÄÅ', 1), ('Áé∞', 1), ('Êòé', 1), ('Ëøá', 1), ('Â§ß', 1), ('‰∏Ä', 1), ('Áã¨', 1), ('ÁêÜ', 1), ('ÂÆ∂', 1)]
----------
= 1 ===================
[('ËØØ', 1996), ('Á°Æ', 6)]
----------
[('Á°Æ', 1996), ('ËØØ', 6)]
----------
[('Èîô', 2002)]
----------
[('Ê≠£', 1995), ('ÁõÆ', 4), ('Ê•ö', 2), ('Èù¢', 1)]
----------
[('‰π±', 1019), ('È¢ò', 771), ('ÁõÆ', 38), ('Êïà', 21), ('ÁÇπ', 21), ('Âç¥', 20), ('Ê≥ï', 17), ('ÂΩì', 10), ('Ê≠£', 7), ('Êçü', 5), ('ÁóÖ', 5), ('Âêà', 5), ('Èù¢', 5), ('Èáç', 4), ('Ëá¥', 3), ('ÂøÉ', 3), ('Â≠¶', 3), ('‰∫∫', 3), ('Ëâ≤', 3), ('Â§ç', 2), ('Â∏∏', 2), ('Âàá', 2), ('Ëø´', 2), ('ÁΩÆ', 2), ('Âà´', 2), ('‰∏ã', 2), ('Ë∑Ø', 1), ('ÂÖ®', 1), ('ÂÆû', 1), ('‰πâ', 1), ('Á´ã', 1), ('Â∫¶', 1), ('Áªè', 1), ('Èó¥', 1), ('Ê•ö', 1), ('‰Ωì', 1), ('Êï¥', 1), ('Â∞Ω', 1), ('Êîæ', 1), ('Ë°®', 1), ('Êñπ', 1), ('Ê¥ª', 1), ('ËØÑ', 1), ('ËΩ¨', 1), ('Áªù', 1), ('ÈÅì', 1), ('Âøò', 1), ('ÁêÜ', 1), ('Ê∞¥', 1), ('Èöæ', 1), ('ÂÆ∂', 1)]
----------
====================
[1 4 4 2 2 5 4 0 1 5 3 5 0 5 0 0 6 0 1 6 3 5 2 5 5 6 4 2 3 1 0 4 3 4 1 3 3
 4 6 6 3 0 1 1 6 3 0 5 1 1 6 3 6 0 0 5 4 2 3 6 6 4 5 3 3 3 5 2 4 2 5 6 4 4
 3 5 5 4 0 6 0 4 5 2 6 5 0 3 0 0 6 5 4 2 6 1 6 4 5 4 3 1 0 2 0 1 5 5 4 5 4
 1 6 0 6 6 6 5 4 5 5 3 4 6 3 3 3 5 5 3 0 3 4 0 6 2 1 1 2 5 3 6 4 0 5 5 1 6
 3 3 6 4 4 6 1 5 0 6 0 2 4 4 5 1 6 1 1 2 5 0 2 3 5 4 5 3 1 2 1 0 5 3 2 2 6
 2 3 5 1 6 1 6 3 6 4 1 3 5 5 5 5 2]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[32m[2022-09-05 13:14:18,285] [    INFO][0m - eval_loss: 0.4265170693397522, eval_accuracy: 0.1188118811881188, eval_runtime: 10.9879, eval_samples_per_second: 128.687, eval_steps_per_second: 16.109, epoch: 1.1299[0m
[32m[2022-09-05 13:14:18,312] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-200[0m
[32m[2022-09-05 13:14:18,313] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:14:21,460] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-200/tokenizer_config.json[0m
[32m[2022-09-05 13:14:21,460] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-200/special_tokens_map.json[0m
[32m[2022-09-05 13:14:28,071] [    INFO][0m - loss: 0.36678185, learning_rate: 9.762711864406781e-06, global_step: 210, interval_runtime: 20.7756, interval_samples_per_second: 0.385, interval_steps_per_second: 0.481, epoch: 1.1864[0m
[32m[2022-09-05 13:14:29,556] [    INFO][0m - loss: 0.64764314, learning_rate: 9.751412429378532e-06, global_step: 220, interval_runtime: 1.4848, interval_samples_per_second: 5.388, interval_steps_per_second: 6.735, epoch: 1.2429[0m
[32m[2022-09-05 13:14:31,040] [    INFO][0m - loss: 0.48738947, learning_rate: 9.740112994350284e-06, global_step: 230, interval_runtime: 1.4847, interval_samples_per_second: 5.388, interval_steps_per_second: 6.736, epoch: 1.2994[0m
[32m[2022-09-05 13:14:32,524] [    INFO][0m - loss: 0.57676396, learning_rate: 9.728813559322035e-06, global_step: 240, interval_runtime: 1.4834, interval_samples_per_second: 5.393, interval_steps_per_second: 6.741, epoch: 1.3559[0m
[32m[2022-09-05 13:14:34,010] [    INFO][0m - loss: 0.34710898, learning_rate: 9.717514124293787e-06, global_step: 250, interval_runtime: 1.4864, interval_samples_per_second: 5.382, interval_steps_per_second: 6.728, epoch: 1.4124[0m
[32m[2022-09-05 13:14:35,495] [    INFO][0m - loss: 0.60717826, learning_rate: 9.706214689265538e-06, global_step: 260, interval_runtime: 1.4848, interval_samples_per_second: 5.388, interval_steps_per_second: 6.735, epoch: 1.4689[0m
[32m[2022-09-05 13:14:36,978] [    INFO][0m - loss: 0.41618423, learning_rate: 9.69491525423729e-06, global_step: 270, interval_runtime: 1.4832, interval_samples_per_second: 5.394, interval_steps_per_second: 6.742, epoch: 1.5254[0m
[32m[2022-09-05 13:14:38,464] [    INFO][0m - loss: 0.56953301, learning_rate: 9.68361581920904e-06, global_step: 280, interval_runtime: 1.4857, interval_samples_per_second: 5.385, interval_steps_per_second: 6.731, epoch: 1.5819[0m
[32m[2022-09-05 13:14:39,948] [    INFO][0m - loss: 0.34187458, learning_rate: 9.672316384180791e-06, global_step: 290, interval_runtime: 1.4837, interval_samples_per_second: 5.392, interval_steps_per_second: 6.74, epoch: 1.6384[0m
[32m[2022-09-05 13:14:41,431] [    INFO][0m - loss: 0.56593266, learning_rate: 9.661016949152544e-06, global_step: 300, interval_runtime: 1.4834, interval_samples_per_second: 5.393, interval_steps_per_second: 6.741, epoch: 1.6949[0m
[32m[2022-09-05 13:14:41,432] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:14:41,432] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:14:41,432] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:14:41,432] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:14:41,432] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:14:52,408] [    INFO][0m - eval_loss: 0.4249281883239746, eval_accuracy: 0.18316831683168316, eval_runtime: 10.976, eval_samples_per_second: 128.826, eval_steps_per_second: 16.126, epoch: 1.6949[0m
[32m[2022-09-05 13:14:52,434] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-300[0m
[32m[2022-09-05 13:14:52,435] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:14:55,378] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-300/tokenizer_config.json[0m
[32m[2022-09-05 13:14:55,379] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-300/special_tokens_map.json[0m
[32m[2022-09-05 13:15:02,249] [    INFO][0m - loss: 0.38006668, learning_rate: 9.649717514124294e-06, global_step: 310, interval_runtime: 20.8178, interval_samples_per_second: 0.384, interval_steps_per_second: 0.48, epoch: 1.7514[0m
[32m[2022-09-05 13:15:03,739] [    INFO][0m - loss: 0.45210023, learning_rate: 9.638418079096045e-06, global_step: 320, interval_runtime: 1.4899, interval_samples_per_second: 5.37, interval_steps_per_second: 6.712, epoch: 1.8079[0m
[32m[2022-09-05 13:15:05,227] [    INFO][0m - loss: 0.66810856, learning_rate: 9.627118644067797e-06, global_step: 330, interval_runtime: 1.488, interval_samples_per_second: 5.376, interval_steps_per_second: 6.721, epoch: 1.8644[0m
[32m[2022-09-05 13:15:06,712] [    INFO][0m - loss: 0.37691543, learning_rate: 9.615819209039548e-06, global_step: 340, interval_runtime: 1.4852, interval_samples_per_second: 5.386, interval_steps_per_second: 6.733, epoch: 1.9209[0m
[32m[2022-09-05 13:15:08,198] [    INFO][0m - loss: 0.3587656, learning_rate: 9.6045197740113e-06, global_step: 350, interval_runtime: 1.4864, interval_samples_per_second: 5.382, interval_steps_per_second: 6.728, epoch: 1.9774[0m
[32m[2022-09-05 13:15:09,694] [    INFO][0m - loss: 0.44147639, learning_rate: 9.593220338983051e-06, global_step: 360, interval_runtime: 1.4957, interval_samples_per_second: 5.349, interval_steps_per_second: 6.686, epoch: 2.0339[0m
[32m[2022-09-05 13:15:11,185] [    INFO][0m - loss: 0.41870308, learning_rate: 9.581920903954803e-06, global_step: 370, interval_runtime: 1.4907, interval_samples_per_second: 5.366, interval_steps_per_second: 6.708, epoch: 2.0904[0m
[32m[2022-09-05 13:15:12,671] [    INFO][0m - loss: 0.57272568, learning_rate: 9.570621468926554e-06, global_step: 380, interval_runtime: 1.4859, interval_samples_per_second: 5.384, interval_steps_per_second: 6.73, epoch: 2.1469[0m
[32m[2022-09-05 13:15:14,162] [    INFO][0m - loss: 0.52758994, learning_rate: 9.559322033898306e-06, global_step: 390, interval_runtime: 1.4912, interval_samples_per_second: 5.365, interval_steps_per_second: 6.706, epoch: 2.2034[0m
[32m[2022-09-05 13:15:15,653] [    INFO][0m - loss: 0.48994694, learning_rate: 9.548022598870057e-06, global_step: 400, interval_runtime: 1.4905, interval_samples_per_second: 5.367, interval_steps_per_second: 6.709, epoch: 2.2599[0m
[32m[2022-09-05 13:15:15,653] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:15:15,653] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:15:15,654] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:15:15,654] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:15:15,654] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:15:26,828] [    INFO][0m - eval_loss: 0.5027413368225098, eval_accuracy: 0.2524752475247525, eval_runtime: 11.1735, eval_samples_per_second: 126.549, eval_steps_per_second: 15.841, epoch: 2.2599[0m
[32m[2022-09-05 13:15:26,854] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-400[0m
[32m[2022-09-05 13:15:26,854] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:15:30,447] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-400/tokenizer_config.json[0m
[32m[2022-09-05 13:15:30,448] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-400/special_tokens_map.json[0m
[32m[2022-09-05 13:15:38,147] [    INFO][0m - loss: 0.57985597, learning_rate: 9.53672316384181e-06, global_step: 410, interval_runtime: 22.4943, interval_samples_per_second: 0.356, interval_steps_per_second: 0.445, epoch: 2.3164[0m
[32m[2022-09-05 13:15:39,632] [    INFO][0m - loss: 0.41202431, learning_rate: 9.52542372881356e-06, global_step: 420, interval_runtime: 1.485, interval_samples_per_second: 5.387, interval_steps_per_second: 6.734, epoch: 2.3729[0m
[32m[2022-09-05 13:15:41,120] [    INFO][0m - loss: 0.46442504, learning_rate: 9.514124293785312e-06, global_step: 430, interval_runtime: 1.4875, interval_samples_per_second: 5.378, interval_steps_per_second: 6.723, epoch: 2.4294[0m
[32m[2022-09-05 13:15:42,608] [    INFO][0m - loss: 0.51931167, learning_rate: 9.502824858757063e-06, global_step: 440, interval_runtime: 1.4889, interval_samples_per_second: 5.373, interval_steps_per_second: 6.716, epoch: 2.4859[0m
[32m[2022-09-05 13:15:44,094] [    INFO][0m - loss: 0.45278893, learning_rate: 9.491525423728815e-06, global_step: 450, interval_runtime: 1.4858, interval_samples_per_second: 5.384, interval_steps_per_second: 6.73, epoch: 2.5424[0m
[32m[2022-09-05 13:15:45,579] [    INFO][0m - loss: 0.62797422, learning_rate: 9.480225988700566e-06, global_step: 460, interval_runtime: 1.4848, interval_samples_per_second: 5.388, interval_steps_per_second: 6.735, epoch: 2.5989[0m
[32m[2022-09-05 13:15:47,063] [    INFO][0m - loss: 0.54226909, learning_rate: 9.468926553672318e-06, global_step: 470, interval_runtime: 1.4843, interval_samples_per_second: 5.39, interval_steps_per_second: 6.737, epoch: 2.6554[0m
[32m[2022-09-05 13:15:48,548] [    INFO][0m - loss: 0.39598625, learning_rate: 9.457627118644069e-06, global_step: 480, interval_runtime: 1.4847, interval_samples_per_second: 5.388, interval_steps_per_second: 6.735, epoch: 2.7119[0m
[32m[2022-09-05 13:15:50,034] [    INFO][0m - loss: 0.40127635, learning_rate: 9.44632768361582e-06, global_step: 490, interval_runtime: 1.4863, interval_samples_per_second: 5.383, interval_steps_per_second: 6.728, epoch: 2.7684[0m
[32m[2022-09-05 13:15:51,521] [    INFO][0m - loss: 0.36445436, learning_rate: 9.435028248587572e-06, global_step: 500, interval_runtime: 1.4867, interval_samples_per_second: 5.381, interval_steps_per_second: 6.726, epoch: 2.8249[0m
[32m[2022-09-05 13:15:51,521] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:15:51,521] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:15:51,521] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:15:51,521] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:15:51,522] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:16:02,562] [    INFO][0m - eval_loss: 0.4149746298789978, eval_accuracy: 0.19306930693069307, eval_runtime: 11.0401, eval_samples_per_second: 128.079, eval_steps_per_second: 16.033, epoch: 2.8249[0m
[32m[2022-09-05 13:16:02,589] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-500[0m
[32m[2022-09-05 13:16:02,589] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:16:05,989] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-500/tokenizer_config.json[0m
[32m[2022-09-05 13:16:05,989] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-500/special_tokens_map.json[0m
[32m[2022-09-05 13:16:12,900] [    INFO][0m - loss: 0.38306522, learning_rate: 9.423728813559322e-06, global_step: 510, interval_runtime: 21.3792, interval_samples_per_second: 0.374, interval_steps_per_second: 0.468, epoch: 2.8814[0m
[32m[2022-09-05 13:16:14,385] [    INFO][0m - loss: 0.39736595, learning_rate: 9.412429378531073e-06, global_step: 520, interval_runtime: 1.4852, interval_samples_per_second: 5.386, interval_steps_per_second: 6.733, epoch: 2.9379[0m
[32m[2022-09-05 13:16:15,869] [    INFO][0m - loss: 0.34370835, learning_rate: 9.401129943502825e-06, global_step: 530, interval_runtime: 1.4833, interval_samples_per_second: 5.393, interval_steps_per_second: 6.742, epoch: 2.9944[0m
[32m[2022-09-05 13:16:17,369] [    INFO][0m - loss: 0.36009269, learning_rate: 9.389830508474576e-06, global_step: 540, interval_runtime: 1.4999, interval_samples_per_second: 5.334, interval_steps_per_second: 6.667, epoch: 3.0508[0m
[32m[2022-09-05 13:16:18,861] [    INFO][0m - loss: 0.44169073, learning_rate: 9.378531073446328e-06, global_step: 550, interval_runtime: 1.4929, interval_samples_per_second: 5.359, interval_steps_per_second: 6.698, epoch: 3.1073[0m
[32m[2022-09-05 13:16:20,349] [    INFO][0m - loss: 0.46008549, learning_rate: 9.367231638418079e-06, global_step: 560, interval_runtime: 1.4875, interval_samples_per_second: 5.378, interval_steps_per_second: 6.723, epoch: 3.1638[0m
[32m[2022-09-05 13:16:21,840] [    INFO][0m - loss: 0.4953783, learning_rate: 9.355932203389831e-06, global_step: 570, interval_runtime: 1.4907, interval_samples_per_second: 5.367, interval_steps_per_second: 6.708, epoch: 3.2203[0m
[32m[2022-09-05 13:16:23,333] [    INFO][0m - loss: 0.4406147, learning_rate: 9.344632768361582e-06, global_step: 580, interval_runtime: 1.4934, interval_samples_per_second: 5.357, interval_steps_per_second: 6.696, epoch: 3.2768[0m
[32m[2022-09-05 13:16:24,820] [    INFO][0m - loss: 0.48636675, learning_rate: 9.333333333333334e-06, global_step: 590, interval_runtime: 1.4875, interval_samples_per_second: 5.378, interval_steps_per_second: 6.723, epoch: 3.3333[0m
[32m[2022-09-05 13:16:26,307] [    INFO][0m - loss: 0.46019864, learning_rate: 9.322033898305085e-06, global_step: 600, interval_runtime: 1.4861, interval_samples_per_second: 5.383, interval_steps_per_second: 6.729, epoch: 3.3898[0m
[32m[2022-09-05 13:16:26,307] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:16:26,308] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:16:26,308] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:16:26,308] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:16:26,308] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:16:37,467] [    INFO][0m - eval_loss: 0.4336521029472351, eval_accuracy: 0.1782178217821782, eval_runtime: 11.1592, eval_samples_per_second: 126.712, eval_steps_per_second: 15.861, epoch: 3.3898[0m
[32m[2022-09-05 13:16:37,494] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-600[0m
[32m[2022-09-05 13:16:37,494] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:16:40,683] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-600/tokenizer_config.json[0m
[32m[2022-09-05 13:16:40,684] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-600/special_tokens_map.json[0m
[32m[2022-09-05 13:16:47,393] [    INFO][0m - loss: 0.38552403, learning_rate: 9.310734463276837e-06, global_step: 610, interval_runtime: 21.0861, interval_samples_per_second: 0.379, interval_steps_per_second: 0.474, epoch: 3.4463[0m
[32m[2022-09-05 13:16:48,875] [    INFO][0m - loss: 0.46066523, learning_rate: 9.299435028248588e-06, global_step: 620, interval_runtime: 1.4822, interval_samples_per_second: 5.397, interval_steps_per_second: 6.747, epoch: 3.5028[0m
[32m[2022-09-05 13:16:50,362] [    INFO][0m - loss: 0.39934821, learning_rate: 9.28813559322034e-06, global_step: 630, interval_runtime: 1.4875, interval_samples_per_second: 5.378, interval_steps_per_second: 6.723, epoch: 3.5593[0m
[32m[2022-09-05 13:16:51,850] [    INFO][0m - loss: 0.41800895, learning_rate: 9.276836158192091e-06, global_step: 640, interval_runtime: 1.4875, interval_samples_per_second: 5.378, interval_steps_per_second: 6.723, epoch: 3.6158[0m
[32m[2022-09-05 13:16:53,338] [    INFO][0m - loss: 0.40309887, learning_rate: 9.265536723163843e-06, global_step: 650, interval_runtime: 1.4884, interval_samples_per_second: 5.375, interval_steps_per_second: 6.719, epoch: 3.6723[0m
[32m[2022-09-05 13:16:54,826] [    INFO][0m - loss: 0.41485906, learning_rate: 9.254237288135594e-06, global_step: 660, interval_runtime: 1.4878, interval_samples_per_second: 5.377, interval_steps_per_second: 6.721, epoch: 3.7288[0m
[32m[2022-09-05 13:16:56,313] [    INFO][0m - loss: 0.3526917, learning_rate: 9.242937853107346e-06, global_step: 670, interval_runtime: 1.4871, interval_samples_per_second: 5.38, interval_steps_per_second: 6.724, epoch: 3.7853[0m
[32m[2022-09-05 13:16:57,799] [    INFO][0m - loss: 0.41843033, learning_rate: 9.231638418079097e-06, global_step: 680, interval_runtime: 1.4861, interval_samples_per_second: 5.383, interval_steps_per_second: 6.729, epoch: 3.8418[0m
[32m[2022-09-05 13:16:59,285] [    INFO][0m - loss: 0.55130725, learning_rate: 9.220338983050847e-06, global_step: 690, interval_runtime: 1.4855, interval_samples_per_second: 5.385, interval_steps_per_second: 6.732, epoch: 3.8983[0m
[32m[2022-09-05 13:17:00,774] [    INFO][0m - loss: 0.52133226, learning_rate: 9.2090395480226e-06, global_step: 700, interval_runtime: 1.489, interval_samples_per_second: 5.373, interval_steps_per_second: 6.716, epoch: 3.9548[0m
[32m[2022-09-05 13:17:00,774] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:17:00,774] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:17:00,774] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:17:00,774] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:17:00,775] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:17:11,874] [    INFO][0m - eval_loss: 0.41299235820770264, eval_accuracy: 0.10891089108910891, eval_runtime: 11.0986, eval_samples_per_second: 127.404, eval_steps_per_second: 15.948, epoch: 3.9548[0m
[32m[2022-09-05 13:17:11,902] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-700[0m
[32m[2022-09-05 13:17:11,902] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:17:15,004] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-700/tokenizer_config.json[0m
[32m[2022-09-05 13:17:15,005] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-700/special_tokens_map.json[0m
[32m[2022-09-05 13:17:21,614] [    INFO][0m - loss: 0.49785252, learning_rate: 9.19774011299435e-06, global_step: 710, interval_runtime: 20.84, interval_samples_per_second: 0.384, interval_steps_per_second: 0.48, epoch: 4.0113[0m
[32m[2022-09-05 13:17:23,107] [    INFO][0m - loss: 0.3906213, learning_rate: 9.186440677966101e-06, global_step: 720, interval_runtime: 1.4931, interval_samples_per_second: 5.358, interval_steps_per_second: 6.698, epoch: 4.0678[0m
[32m[2022-09-05 13:17:24,593] [    INFO][0m - loss: 0.47415638, learning_rate: 9.175141242937853e-06, global_step: 730, interval_runtime: 1.4864, interval_samples_per_second: 5.382, interval_steps_per_second: 6.728, epoch: 4.1243[0m
[32m[2022-09-05 13:17:26,080] [    INFO][0m - loss: 0.40501676, learning_rate: 9.163841807909604e-06, global_step: 740, interval_runtime: 1.4865, interval_samples_per_second: 5.382, interval_steps_per_second: 6.727, epoch: 4.1808[0m
[32m[2022-09-05 13:17:27,573] [    INFO][0m - loss: 0.39508932, learning_rate: 9.152542372881356e-06, global_step: 750, interval_runtime: 1.4928, interval_samples_per_second: 5.359, interval_steps_per_second: 6.699, epoch: 4.2373[0m
[32m[2022-09-05 13:17:29,066] [    INFO][0m - loss: 0.52731214, learning_rate: 9.141242937853107e-06, global_step: 760, interval_runtime: 1.4931, interval_samples_per_second: 5.358, interval_steps_per_second: 6.698, epoch: 4.2938[0m
[32m[2022-09-05 13:17:30,556] [    INFO][0m - loss: 0.43265018, learning_rate: 9.12994350282486e-06, global_step: 770, interval_runtime: 1.49, interval_samples_per_second: 5.369, interval_steps_per_second: 6.712, epoch: 4.3503[0m
[32m[2022-09-05 13:17:32,048] [    INFO][0m - loss: 0.53735542, learning_rate: 9.11864406779661e-06, global_step: 780, interval_runtime: 1.4921, interval_samples_per_second: 5.362, interval_steps_per_second: 6.702, epoch: 4.4068[0m
[32m[2022-09-05 13:17:33,538] [    INFO][0m - loss: 0.48319979, learning_rate: 9.107344632768362e-06, global_step: 790, interval_runtime: 1.4904, interval_samples_per_second: 5.368, interval_steps_per_second: 6.71, epoch: 4.4633[0m
[32m[2022-09-05 13:17:35,027] [    INFO][0m - loss: 0.4045764, learning_rate: 9.096045197740113e-06, global_step: 800, interval_runtime: 1.4885, interval_samples_per_second: 5.374, interval_steps_per_second: 6.718, epoch: 4.5198[0m
[32m[2022-09-05 13:17:35,028] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:17:35,028] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:17:35,028] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:17:35,028] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:17:35,028] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:17:46,098] [    INFO][0m - eval_loss: 0.4155786335468292, eval_accuracy: 0.10396039603960396, eval_runtime: 11.0692, eval_samples_per_second: 127.742, eval_steps_per_second: 15.99, epoch: 4.5198[0m
[32m[2022-09-05 13:17:46,127] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-800[0m
[32m[2022-09-05 13:17:46,127] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:17:49,269] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-800/tokenizer_config.json[0m
[32m[2022-09-05 13:17:49,270] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-800/special_tokens_map.json[0m
[32m[2022-09-05 13:17:54,350] [    INFO][0m - 
Training completed. 
[0m
[32m[2022-09-05 13:17:54,351] [    INFO][0m - Loading best model from ./checkpoints_chid/checkpoint-400 (score: 0.2524752475247525).[0m
[32m[2022-09-05 13:17:55,371] [    INFO][0m - train_runtime: 277.1738, train_samples_per_second: 255.075, train_steps_per_second: 31.929, train_loss: 0.5590456312894821, epoch: 4.5198[0m
[32m[2022-09-05 13:17:55,412] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/[0m
[32m[2022-09-05 13:17:55,412] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:17:58,518] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/tokenizer_config.json[0m
[32m[2022-09-05 13:17:58,519] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/special_tokens_map.json[0m
[32m[2022-09-05 13:17:58,520] [    INFO][0m - ***** train metrics *****[0m
[32m[2022-09-05 13:17:58,520] [    INFO][0m -   epoch                    =     4.5198[0m
[32m[2022-09-05 13:17:58,520] [    INFO][0m -   train_loss               =      0.559[0m
[32m[2022-09-05 13:17:58,521] [    INFO][0m -   train_runtime            = 0:04:37.17[0m
[32m[2022-09-05 13:17:58,521] [    INFO][0m -   train_samples_per_second =    255.075[0m
[32m[2022-09-05 13:17:58,521] [    INFO][0m -   train_steps_per_second   =     31.929[0m
[32m[2022-09-05 13:17:58,527] [    INFO][0m - ***** Running Prediction *****[0m
[32m[2022-09-05 13:17:58,527] [    INFO][0m -   Num examples = 14014[0m
[32m[2022-09-05 13:17:58,527] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:17:58,527] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:17:58,527] [    INFO][0m -   Total prediction steps = 1752[0m
[32m[2022-09-05 13:19:48,877] [    INFO][0m - ***** test metrics *****[0m
[32m[2022-09-05 13:19:48,878] [    INFO][0m -   test_accuracy           =     0.2517[0m
[32m[2022-09-05 13:19:48,878] [    INFO][0m -   test_loss               =     0.5038[0m
[32m[2022-09-05 13:19:48,878] [    INFO][0m -   test_runtime            = 0:01:50.35[0m
[32m[2022-09-05 13:19:48,878] [    INFO][0m -   test_samples_per_second =    126.996[0m
[32m[2022-09-05 13:19:48,878] [    INFO][0m -   test_steps_per_second   =     15.877[0m
[33m[2022-09-05 13:20:05,150] [ WARNING][0m - evaluation_strategy reset to IntervalStrategy.STEPS for do_eval is True. you can also set evaluation_strategy='epoch'.[0m
[32m[2022-09-05 13:20:05,151] [    INFO][0m - The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).[0m
[32m[2022-09-05 13:20:05,151] [    INFO][0m - ============================================================[0m
[32m[2022-09-05 13:20:05,151] [    INFO][0m -      Model Configuration Arguments      [0m
[32m[2022-09-05 13:20:05,151] [    INFO][0m - paddle commit id              :65f388690048d0965ec7d3b43fb6ee9d8c6dee7c[0m
[32m[2022-09-05 13:20:05,151] [    INFO][0m - do_save                       :True[0m
[32m[2022-09-05 13:20:05,151] [    INFO][0m - do_test                       :True[0m
[32m[2022-09-05 13:20:05,151] [    INFO][0m - early_stop_patience           :4[0m
[32m[2022-09-05 13:20:05,151] [    INFO][0m - export_type                   :paddle[0m
[32m[2022-09-05 13:20:05,151] [    INFO][0m - model_name_or_path            :ernie-3.0-base-zh[0m
[32m[2022-09-05 13:20:05,151] [    INFO][0m - [0m
[32m[2022-09-05 13:20:05,152] [    INFO][0m - ============================================================[0m
[32m[2022-09-05 13:20:05,152] [    INFO][0m -       Data Configuration Arguments      [0m
[32m[2022-09-05 13:20:05,152] [    INFO][0m - paddle commit id              :65f388690048d0965ec7d3b43fb6ee9d8c6dee7c[0m
[32m[2022-09-05 13:20:05,152] [    INFO][0m - encoder_hidden_size           :200[0m
[32m[2022-09-05 13:20:05,152] [    INFO][0m - prompt                        :[0m
[32m[2022-09-05 13:20:05,152] [    INFO][0m - soft_encoder                  :lstm[0m
[32m[2022-09-05 13:20:05,152] [    INFO][0m - split_id                      :few_all[0m
[32m[2022-09-05 13:20:05,152] [    INFO][0m - task_name                     :chid[0m
[32m[2022-09-05 13:20:05,152] [    INFO][0m - [0m
[32m[2022-09-05 13:20:05,153] [    INFO][0m - Already cached /ssd2/wanghuijuan03/.paddlenlp/models/ernie-3.0-base-zh/ernie_3.0_base_zh.pdparams[0m
[32m[2022-09-05 13:20:06,557] [    INFO][0m - Already cached /ssd2/wanghuijuan03/.paddlenlp/models/ernie-3.0-base-zh/ernie_3.0_base_zh_vocab.txt[0m
[32m[2022-09-05 13:20:06,578] [    INFO][0m - tokenizer config file saved in /ssd2/wanghuijuan03/.paddlenlp/models/ernie-3.0-base-zh/tokenizer_config.json[0m
[32m[2022-09-05 13:20:06,578] [    INFO][0m - Special tokens file saved in /ssd2/wanghuijuan03/.paddlenlp/models/ernie-3.0-base-zh/special_tokens_map.json[0m
[32m[2022-09-05 13:20:06,579] [    INFO][0m - Using template: [{'add_prefix_space': '', 'text': 'text_a'}, {'add_prefix_space': '', 'hard': 'ÊàêËØ≠'}, {'add_prefix_space': '', 'text': 'text_b'}, {'add_prefix_space': '', 'hard': '‰ΩøÁî®ÊòØÂê¶Ê≠£Á°ÆÔºü'}, {'add_prefix_space': '', 'mask': None}][0m
2022-09-05 13:20:06,581 INFO [download.py:119] unique_endpoints {''}
[32m[2022-09-05 13:20:06,671] [    INFO][0m - ============================================================[0m
[32m[2022-09-05 13:20:06,671] [    INFO][0m -     Training Configuration Arguments    [0m
[32m[2022-09-05 13:20:06,671] [    INFO][0m - paddle commit id              :65f388690048d0965ec7d3b43fb6ee9d8c6dee7c[0m
[32m[2022-09-05 13:20:06,671] [    INFO][0m - _no_sync_in_gradient_accumulation:True[0m
[32m[2022-09-05 13:20:06,671] [    INFO][0m - adam_beta1                    :0.9[0m
[32m[2022-09-05 13:20:06,672] [    INFO][0m - adam_beta2                    :0.999[0m
[32m[2022-09-05 13:20:06,672] [    INFO][0m - adam_epsilon                  :1e-08[0m
[32m[2022-09-05 13:20:06,672] [    INFO][0m - alpha_rdrop                   :5.0[0m
[32m[2022-09-05 13:20:06,672] [    INFO][0m - alpha_rgl                     :0.5[0m
[32m[2022-09-05 13:20:06,672] [    INFO][0m - current_device                :gpu:0[0m
[32m[2022-09-05 13:20:06,672] [    INFO][0m - dataloader_drop_last          :False[0m
[32m[2022-09-05 13:20:06,672] [    INFO][0m - dataloader_num_workers        :0[0m
[32m[2022-09-05 13:20:06,672] [    INFO][0m - device                        :gpu[0m
[32m[2022-09-05 13:20:06,672] [    INFO][0m - disable_tqdm                  :True[0m
[32m[2022-09-05 13:20:06,672] [    INFO][0m - do_eval                       :True[0m
[32m[2022-09-05 13:20:06,672] [    INFO][0m - do_export                     :False[0m
[32m[2022-09-05 13:20:06,672] [    INFO][0m - do_predict                    :False[0m
[32m[2022-09-05 13:20:06,672] [    INFO][0m - do_train                      :True[0m
[32m[2022-09-05 13:20:06,673] [    INFO][0m - eval_batch_size               :8[0m
[32m[2022-09-05 13:20:06,673] [    INFO][0m - eval_steps                    :100[0m
[32m[2022-09-05 13:20:06,673] [    INFO][0m - evaluation_strategy           :IntervalStrategy.STEPS[0m
[32m[2022-09-05 13:20:06,673] [    INFO][0m - first_max_length              :None[0m
[32m[2022-09-05 13:20:06,673] [    INFO][0m - fp16                          :False[0m
[32m[2022-09-05 13:20:06,673] [    INFO][0m - fp16_opt_level                :O1[0m
[32m[2022-09-05 13:20:06,673] [    INFO][0m - freeze_dropout                :False[0m
[32m[2022-09-05 13:20:06,673] [    INFO][0m - freeze_plm                    :False[0m
[32m[2022-09-05 13:20:06,673] [    INFO][0m - gradient_accumulation_steps   :1[0m
[32m[2022-09-05 13:20:06,673] [    INFO][0m - greater_is_better             :True[0m
[32m[2022-09-05 13:20:06,673] [    INFO][0m - ignore_data_skip              :False[0m
[32m[2022-09-05 13:20:06,673] [    INFO][0m - label_names                   :None[0m
[32m[2022-09-05 13:20:06,673] [    INFO][0m - learning_rate                 :1e-05[0m
[32m[2022-09-05 13:20:06,674] [    INFO][0m - load_best_model_at_end        :True[0m
[32m[2022-09-05 13:20:06,674] [    INFO][0m - local_process_index           :0[0m
[32m[2022-09-05 13:20:06,674] [    INFO][0m - local_rank                    :-1[0m
[32m[2022-09-05 13:20:06,674] [    INFO][0m - log_level                     :-1[0m
[32m[2022-09-05 13:20:06,674] [    INFO][0m - log_level_replica             :-1[0m
[32m[2022-09-05 13:20:06,674] [    INFO][0m - log_on_each_node              :True[0m
[32m[2022-09-05 13:20:06,674] [    INFO][0m - logging_dir                   :./checkpoints_chid/runs/Sep05_13-20-05_instance-3bwob41y-01[0m
[32m[2022-09-05 13:20:06,674] [    INFO][0m - logging_first_step            :False[0m
[32m[2022-09-05 13:20:06,674] [    INFO][0m - logging_steps                 :10[0m
[32m[2022-09-05 13:20:06,674] [    INFO][0m - logging_strategy              :IntervalStrategy.STEPS[0m
[32m[2022-09-05 13:20:06,674] [    INFO][0m - lr_scheduler_type             :SchedulerType.LINEAR[0m
[32m[2022-09-05 13:20:06,674] [    INFO][0m - max_grad_norm                 :1.0[0m
[32m[2022-09-05 13:20:06,674] [    INFO][0m - max_seq_length                :256[0m
[32m[2022-09-05 13:20:06,675] [    INFO][0m - max_steps                     :-1[0m
[32m[2022-09-05 13:20:06,675] [    INFO][0m - metric_for_best_model         :accuracy[0m
[32m[2022-09-05 13:20:06,675] [    INFO][0m - minimum_eval_times            :None[0m
[32m[2022-09-05 13:20:06,675] [    INFO][0m - no_cuda                       :False[0m
[32m[2022-09-05 13:20:06,675] [    INFO][0m - num_train_epochs              :50.0[0m
[32m[2022-09-05 13:20:06,675] [    INFO][0m - optim                         :OptimizerNames.ADAMW[0m
[32m[2022-09-05 13:20:06,675] [    INFO][0m - other_max_length              :None[0m
[32m[2022-09-05 13:20:06,675] [    INFO][0m - output_dir                    :./checkpoints_chid/[0m
[32m[2022-09-05 13:20:06,675] [    INFO][0m - overwrite_output_dir          :False[0m
[32m[2022-09-05 13:20:06,675] [    INFO][0m - past_index                    :-1[0m
[32m[2022-09-05 13:20:06,675] [    INFO][0m - per_device_eval_batch_size    :8[0m
[32m[2022-09-05 13:20:06,675] [    INFO][0m - per_device_train_batch_size   :8[0m
[32m[2022-09-05 13:20:06,675] [    INFO][0m - ppt_adam_beta1                :0.9[0m
[32m[2022-09-05 13:20:06,675] [    INFO][0m - ppt_adam_beta2                :0.999[0m
[32m[2022-09-05 13:20:06,676] [    INFO][0m - ppt_adam_epsilon              :1e-08[0m
[32m[2022-09-05 13:20:06,676] [    INFO][0m - ppt_learning_rate             :1e-05[0m
[32m[2022-09-05 13:20:06,676] [    INFO][0m - ppt_weight_decay              :0.0[0m
[32m[2022-09-05 13:20:06,676] [    INFO][0m - prediction_loss_only          :False[0m
[32m[2022-09-05 13:20:06,676] [    INFO][0m - process_index                 :0[0m
[32m[2022-09-05 13:20:06,676] [    INFO][0m - remove_unused_columns         :True[0m
[32m[2022-09-05 13:20:06,676] [    INFO][0m - report_to                     :['visualdl'][0m
[32m[2022-09-05 13:20:06,676] [    INFO][0m - resume_from_checkpoint        :None[0m
[32m[2022-09-05 13:20:06,676] [    INFO][0m - run_name                      :./checkpoints_chid/[0m
[32m[2022-09-05 13:20:06,676] [    INFO][0m - save_on_each_node             :False[0m
[32m[2022-09-05 13:20:06,676] [    INFO][0m - save_steps                    :100[0m
[32m[2022-09-05 13:20:06,676] [    INFO][0m - save_strategy                 :IntervalStrategy.STEPS[0m
[32m[2022-09-05 13:20:06,676] [    INFO][0m - save_total_limit              :None[0m
[32m[2022-09-05 13:20:06,677] [    INFO][0m - scale_loss                    :32768[0m
[32m[2022-09-05 13:20:06,677] [    INFO][0m - seed                          :42[0m
[32m[2022-09-05 13:20:06,677] [    INFO][0m - should_log                    :True[0m
[32m[2022-09-05 13:20:06,677] [    INFO][0m - should_save                   :True[0m
[32m[2022-09-05 13:20:06,677] [    INFO][0m - task_type                     :multi-class[0m
[32m[2022-09-05 13:20:06,677] [    INFO][0m - train_batch_size              :8[0m
[32m[2022-09-05 13:20:06,677] [    INFO][0m - truncate_mode                 :tail[0m
[32m[2022-09-05 13:20:06,677] [    INFO][0m - use_rdrop                     :False[0m
[32m[2022-09-05 13:20:06,677] [    INFO][0m - use_rgl                       :False[0m
[32m[2022-09-05 13:20:06,677] [    INFO][0m - warmup_ratio                  :0.0[0m
[32m[2022-09-05 13:20:06,677] [    INFO][0m - warmup_steps                  :0[0m
[32m[2022-09-05 13:20:06,677] [    INFO][0m - weight_decay                  :0.0[0m
[32m[2022-09-05 13:20:06,677] [    INFO][0m - world_size                    :1[0m
[32m[2022-09-05 13:20:06,677] [    INFO][0m - [0m
[32m[2022-09-05 13:20:06,679] [    INFO][0m - ***** Running training *****[0m
[32m[2022-09-05 13:20:06,679] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:20:06,679] [    INFO][0m -   Num Epochs = 50[0m
[32m[2022-09-05 13:20:06,679] [    INFO][0m -   Instantaneous batch size per device = 8[0m
[32m[2022-09-05 13:20:06,679] [    INFO][0m -   Total train batch size (w. parallel, distributed & accumulation) = 8[0m
[32m[2022-09-05 13:20:06,679] [    INFO][0m -   Gradient Accumulation steps = 1[0m
[32m[2022-09-05 13:20:06,679] [    INFO][0m -   Total optimization steps = 8850.0[0m
[32m[2022-09-05 13:20:06,680] [    INFO][0m -   Total num train samples = 70700[0m
[32m[2022-09-05 13:20:08,252] [    INFO][0m - loss: 6.72494965, learning_rate: 9.988700564971753e-06, global_step: 10, interval_runtime: 1.5713, interval_samples_per_second: 5.091, interval_steps_per_second: 6.364, epoch: 0.0565[0m
[32m[2022-09-05 13:20:09,738] [    INFO][0m - loss: 0.80830956, learning_rate: 9.977401129943504e-06, global_step: 20, interval_runtime: 1.4865, interval_samples_per_second: 5.382, interval_steps_per_second: 6.727, epoch: 0.113[0m
[32m[2022-09-05 13:20:11,276] [    INFO][0m - loss: 0.7266326, learning_rate: 9.966101694915256e-06, global_step: 30, interval_runtime: 1.4913, interval_samples_per_second: 5.365, interval_steps_per_second: 6.706, epoch: 0.1695[0m
[32m[2022-09-05 13:20:12,772] [    INFO][0m - loss: 0.79548583, learning_rate: 9.954802259887007e-06, global_step: 40, interval_runtime: 1.5424, interval_samples_per_second: 5.187, interval_steps_per_second: 6.484, epoch: 0.226[0m
[32m[2022-09-05 13:20:14,261] [    INFO][0m - loss: 0.73677673, learning_rate: 9.943502824858759e-06, global_step: 50, interval_runtime: 1.4892, interval_samples_per_second: 5.372, interval_steps_per_second: 6.715, epoch: 0.2825[0m
[32m[2022-09-05 13:20:15,838] [    INFO][0m - loss: 0.27165108, learning_rate: 9.93220338983051e-06, global_step: 60, interval_runtime: 1.4986, interval_samples_per_second: 5.338, interval_steps_per_second: 6.673, epoch: 0.339[0m
[32m[2022-09-05 13:20:17,326] [    INFO][0m - loss: 1.24697838, learning_rate: 9.92090395480226e-06, global_step: 70, interval_runtime: 1.5666, interval_samples_per_second: 5.107, interval_steps_per_second: 6.383, epoch: 0.3955[0m
[32m[2022-09-05 13:20:18,816] [    INFO][0m - loss: 0.64111333, learning_rate: 9.909604519774013e-06, global_step: 80, interval_runtime: 1.4897, interval_samples_per_second: 5.37, interval_steps_per_second: 6.713, epoch: 0.452[0m
[32m[2022-09-05 13:20:20,303] [    INFO][0m - loss: 0.58102679, learning_rate: 9.898305084745763e-06, global_step: 90, interval_runtime: 1.4868, interval_samples_per_second: 5.381, interval_steps_per_second: 6.726, epoch: 0.5085[0m
[32m[2022-09-05 13:20:21,792] [    INFO][0m - loss: 0.53267503, learning_rate: 9.887005649717516e-06, global_step: 100, interval_runtime: 1.4897, interval_samples_per_second: 5.37, interval_steps_per_second: 6.713, epoch: 0.565[0m
[32m[2022-09-05 13:20:21,793] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:20:21,793] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:20:21,793] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:20:21,793] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:20:21,793] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:20:33,083] [    INFO][0m - eval_loss: 0.42143237590789795, eval_accuracy: 0.10891089108910891, eval_runtime: 11.2895, eval_samples_per_second: 125.249, eval_steps_per_second: 15.678, epoch: 0.565[0m
[32m[2022-09-05 13:20:33,083] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-100[0m
[32m[2022-09-05 13:20:33,083] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:20:36,100] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-100/tokenizer_config.json[0m
[32m[2022-09-05 13:20:36,100] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-100/special_tokens_map.json[0m
[32m[2022-09-05 13:20:42,671] [    INFO][0m - loss: 0.44767013, learning_rate: 9.875706214689266e-06, global_step: 110, interval_runtime: 20.8781, interval_samples_per_second: 0.383, interval_steps_per_second: 0.479, epoch: 0.6215[0m
[32m[2022-09-05 13:20:44,157] [    INFO][0m - loss: 0.38869061, learning_rate: 9.864406779661017e-06, global_step: 120, interval_runtime: 1.4863, interval_samples_per_second: 5.382, interval_steps_per_second: 6.728, epoch: 0.678[0m
[32m[2022-09-05 13:20:45,647] [    INFO][0m - loss: 0.52196245, learning_rate: 9.85310734463277e-06, global_step: 130, interval_runtime: 1.4901, interval_samples_per_second: 5.369, interval_steps_per_second: 6.711, epoch: 0.7345[0m
[32m[2022-09-05 13:20:47,135] [    INFO][0m - loss: 0.5070509, learning_rate: 9.84180790960452e-06, global_step: 140, interval_runtime: 1.4881, interval_samples_per_second: 5.376, interval_steps_per_second: 6.72, epoch: 0.791[0m
[32m[2022-09-05 13:20:48,625] [    INFO][0m - loss: 0.55765715, learning_rate: 9.830508474576272e-06, global_step: 150, interval_runtime: 1.4898, interval_samples_per_second: 5.37, interval_steps_per_second: 6.712, epoch: 0.8475[0m
[32m[2022-09-05 13:20:50,115] [    INFO][0m - loss: 0.44940481, learning_rate: 9.819209039548023e-06, global_step: 160, interval_runtime: 1.4905, interval_samples_per_second: 5.367, interval_steps_per_second: 6.709, epoch: 0.904[0m
[32m[2022-09-05 13:20:51,601] [    INFO][0m - loss: 0.44963975, learning_rate: 9.807909604519775e-06, global_step: 170, interval_runtime: 1.4859, interval_samples_per_second: 5.384, interval_steps_per_second: 6.73, epoch: 0.9605[0m
[32m[2022-09-05 13:20:53,121] [    INFO][0m - loss: 0.44937444, learning_rate: 9.796610169491526e-06, global_step: 180, interval_runtime: 1.5194, interval_samples_per_second: 5.265, interval_steps_per_second: 6.581, epoch: 1.0169[0m
[32m[2022-09-05 13:20:54,626] [    INFO][0m - loss: 0.59647746, learning_rate: 9.785310734463278e-06, global_step: 190, interval_runtime: 1.5053, interval_samples_per_second: 5.315, interval_steps_per_second: 6.643, epoch: 1.0734[0m
[32m[2022-09-05 13:20:56,117] [    INFO][0m - loss: 0.48893604, learning_rate: 9.774011299435029e-06, global_step: 200, interval_runtime: 1.4913, interval_samples_per_second: 5.364, interval_steps_per_second: 6.705, epoch: 1.1299[0m
[32m[2022-09-05 13:20:56,118] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:20:56,118] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:20:56,118] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:20:56,118] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:20:56,118] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:21:07,302] [    INFO][0m - eval_loss: 0.4162274897098541, eval_accuracy: 0.17326732673267325, eval_runtime: 11.1831, eval_samples_per_second: 126.441, eval_steps_per_second: 15.827, epoch: 1.1299[0m
[32m[2022-09-05 13:21:07,302] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-200[0m
[32m[2022-09-05 13:21:07,302] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:21:10,515] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-200/tokenizer_config.json[0m
[32m[2022-09-05 13:21:10,515] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-200/special_tokens_map.json[0m
[32m[2022-09-05 13:21:16,936] [    INFO][0m - loss: 0.39414172, learning_rate: 9.762711864406781e-06, global_step: 210, interval_runtime: 20.8189, interval_samples_per_second: 0.384, interval_steps_per_second: 0.48, epoch: 1.1864[0m
[32m[2022-09-05 13:21:18,427] [    INFO][0m - loss: 0.65739117, learning_rate: 9.751412429378532e-06, global_step: 220, interval_runtime: 1.4913, interval_samples_per_second: 5.364, interval_steps_per_second: 6.705, epoch: 1.2429[0m
[32m[2022-09-05 13:21:19,924] [    INFO][0m - loss: 0.45080876, learning_rate: 9.740112994350284e-06, global_step: 230, interval_runtime: 1.497, interval_samples_per_second: 5.344, interval_steps_per_second: 6.68, epoch: 1.2994[0m
[32m[2022-09-05 13:21:21,417] [    INFO][0m - loss: 0.50575266, learning_rate: 9.728813559322035e-06, global_step: 240, interval_runtime: 1.493, interval_samples_per_second: 5.358, interval_steps_per_second: 6.698, epoch: 1.3559[0m
[32m[2022-09-05 13:21:22,911] [    INFO][0m - loss: 0.27151916, learning_rate: 9.717514124293787e-06, global_step: 250, interval_runtime: 1.4933, interval_samples_per_second: 5.357, interval_steps_per_second: 6.697, epoch: 1.4124[0m
[32m[2022-09-05 13:21:24,405] [    INFO][0m - loss: 0.65610175, learning_rate: 9.706214689265538e-06, global_step: 260, interval_runtime: 1.4945, interval_samples_per_second: 5.353, interval_steps_per_second: 6.691, epoch: 1.4689[0m
[32m[2022-09-05 13:21:25,897] [    INFO][0m - loss: 0.42017417, learning_rate: 9.69491525423729e-06, global_step: 270, interval_runtime: 1.4917, interval_samples_per_second: 5.363, interval_steps_per_second: 6.704, epoch: 1.5254[0m
[32m[2022-09-05 13:21:27,391] [    INFO][0m - loss: 0.5163126, learning_rate: 9.68361581920904e-06, global_step: 280, interval_runtime: 1.4938, interval_samples_per_second: 5.356, interval_steps_per_second: 6.695, epoch: 1.5819[0m
[32m[2022-09-05 13:21:28,887] [    INFO][0m - loss: 0.27588899, learning_rate: 9.672316384180791e-06, global_step: 290, interval_runtime: 1.4965, interval_samples_per_second: 5.346, interval_steps_per_second: 6.682, epoch: 1.6384[0m
[32m[2022-09-05 13:21:30,383] [    INFO][0m - loss: 0.67503352, learning_rate: 9.661016949152544e-06, global_step: 300, interval_runtime: 1.4957, interval_samples_per_second: 5.349, interval_steps_per_second: 6.686, epoch: 1.6949[0m
[32m[2022-09-05 13:21:30,383] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:21:30,384] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:21:30,384] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:21:30,384] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:21:30,384] [    INFO][0m -   Total prediction steps = 177[0m
[1 2 1 5 3 5 6 0 6 5 5 1 4 1 3 1 3 0 4 3 0 5 0 3 4 4 3 2 6 0 5 6 3 5 6 5 5
 4 5 0 3 6 1 2 1 0 0 0 2 4 2 4 6 3 5 5 3 4 2 6 5 2 3 6 0 0 1 0 0 3 4 1 1 6
 3 3 5 3 3 5 6 1 2 5 4 0 2 3 1 5 4 3 5 1 5 5 2 6 3 3 0 5 0 4 3 1 2 3 6 3 6
 4 0 0 0 0 1 5 2 4 2 4 1 6 6 5 6 6 0 3 6 1 1 3 6 5 4 2 4 5 0 0 3 3 6 1 5 6
 6 2 1 3 3 6 3 3 1 5 6 2 4 2 1 2 2 2 0 0 1 2 3 3 5 3 6 0 0 2 1 3 2 6 2 3 4
 4 2 5 1 6 1 4 1 6 5 3 2 1 6 3 3 6]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[1 0 0 5 2 2 5 3 2 2 0 5 5 0 0 2 6 5 2 3 0 5 0 3 1 6 3 5 6 0 0 4 3 5 1 5 5
 4 4 0 3 3 1 2 0 6 0 0 4 4 2 4 6 5 1 2 5 2 6 1 5 1 4 3 0 1 3 2 2 3 3 0 0 6
 5 6 6 3 3 0 1 1 2 5 4 3 2 3 3 5 3 2 5 1 5 5 4 3 4 4 3 1 1 4 6 5 3 0 6 3 6
 4 4 6 4 4 2 3 2 6 6 3 0 6 2 1 5 5 5 0 6 1 3 5 6 5 6 3 4 3 5 5 5 0 5 0 0 2
 6 5 2 1 2 2 3 2 6 6 6 4 4 0 0 5 2 1 6 0 0 1 4 3 0 4 4 0 0 5 3 5 5 2 1 2 6
 4 5 5 6 4 1 4 5 3 5 5 0 5 6 2 0 3]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[2 0 0 3 2 2 5 6 2 2 5 5 1 0 0 2 6 1 4 3 4 5 1 2 4 6 2 2 2 0 6 2 2 6 1 5 3
 2 4 6 3 0 4 2 5 2 0 0 1 1 2 4 2 5 1 2 5 2 6 5 6 6 4 2 2 6 0 2 2 6 3 1 6 6
 6 6 6 6 1 6 5 2 2 1 2 3 1 3 1 5 3 2 0 4 5 4 4 0 4 3 3 1 1 4 6 5 3 0 6 0 6
 3 2 2 4 0 5 3 0 6 5 0 2 6 6 5 1 5 6 5 6 3 3 4 5 5 6 6 1 3 4 0 5 0 5 0 0 3
 4 2 2 4 0 1 6 2 6 1 6 4 4 0 0 2 2 2 5 0 3 0 4 2 0 6 4 0 6 1 3 3 3 2 5 0 1
 4 5 5 0 1 1 1 5 0 5 1 1 0 2 2 2 3]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[2 0 2 5 2 2 4 0 6 2 0 2 2 0 5 2 3 5 4 3 0 3 6 6 5 6 5 2 6 4 2 3 2 1 6 5 4
 2 6 6 4 3 0 1 5 2 0 0 1 1 2 4 6 3 1 5 5 2 0 5 6 4 4 6 5 2 0 6 2 6 0 1 4 4
 6 5 6 6 1 6 1 4 3 0 5 3 1 3 1 1 3 5 5 2 1 1 4 2 1 4 6 2 3 2 2 1 2 2 6 1 6
 4 0 2 0 5 6 5 0 0 5 0 6 0 6 5 6 5 6 0 0 3 2 4 3 5 1 6 4 6 5 0 2 0 6 1 2 6
 1 2 2 4 2 1 0 1 1 0 1 2 0 4 0 2 2 1 1 3 3 0 3 2 0 0 3 4 1 2 3 3 1 2 1 2 6
 4 5 5 0 0 1 2 5 4 5 5 1 5 6 2 0 2]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[0 2 4 3 6 4 4 0 6 2 1 2 3 0 5 5 1 1 4 3 4 5 2 3 4 6 5 2 6 5 2 4 2 1 1 5 4
 6 6 4 4 0 0 1 5 2 0 2 1 6 4 4 6 3 1 1 5 0 6 5 6 6 4 6 5 1 0 5 6 6 3 3 3 3
 6 5 6 6 1 0 5 2 3 1 0 3 1 3 6 1 3 5 6 2 5 5 5 2 1 4 2 1 3 1 3 2 2 2 6 4 6
 4 0 2 0 4 6 5 0 0 5 5 6 6 1 5 1 5 6 0 3 6 2 5 3 1 1 2 3 5 6 0 3 0 6 1 0 3
 1 2 3 4 3 1 1 1 1 0 3 4 6 4 0 0 0 1 1 6 3 1 6 0 0 0 6 0 1 2 6 3 1 6 4 2 6
 4 5 5 6 4 1 4 2 4 5 6 1 5 6 4 0 6]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[5 6 1 4 4 5 4 0 2 1 5 5 5 1 0 5 2 0 3 3 4 5 1 6 1 5 0 2 6 2 0 4 5 0 6 1 5
 6 4 4 6 3 1 0 5 4 0 0 1 1 4 3 5 2 1 2 2 2 1 1 5 0 4 2 5 3 4 2 0 3 3 0 4 6
 6 6 1 3 6 6 1 4 1 4 3 6 2 0 1 5 1 6 4 2 5 0 5 5 0 3 0 1 6 1 5 1 2 2 6 2 1
 2 0 0 4 4 1 5 2 5 6 6 0 6 6 1 4 3 5 0 0 3 1 5 3 4 0 3 3 3 0 3 3 3 2 2 5 6
 1 2 2 5 3 5 1 3 1 5 6 2 2 4 3 2 6 2 2 0 5 4 2 6 2 6 4 0 0 2 3 3 4 4 5 5 0
 1 0 2 6 4 1 4 4 1 5 5 4 4 6 6 2 2]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[3 2 1 0 3 5 5 5 0 5 1 5 0 1 0 2 5 0 3 1 0 5 1 6 0 0 3 3 6 6 1 4 5 2 4 1 5
 4 4 0 1 6 1 5 5 0 0 0 5 1 2 0 5 6 0 5 2 2 1 3 5 0 6 2 5 3 0 2 1 0 5 0 3 6
 3 3 5 4 6 6 1 4 1 4 3 6 5 0 3 5 1 3 4 2 1 0 6 5 0 0 2 2 6 3 5 1 6 2 6 0 1
 3 0 4 6 4 2 5 2 5 6 1 2 6 6 1 1 3 5 1 6 3 1 0 1 2 6 2 5 3 2 6 3 3 4 2 5 6
 1 2 5 5 2 3 1 3 1 5 6 2 2 2 1 0 6 4 5 0 0 4 4 4 2 6 4 4 0 0 0 1 4 4 6 5 6
 3 0 2 4 6 1 4 1 1 3 3 4 4 6 2 2 0]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[6 1 6 ... 4 1 3]
[1 1 1 ... 1 1 1]
0
= 0 ===================
[('Âê¶', 12012)]
----------
[('ÊòØ', 12012)]
----------
[('‰∏ç', 12012)]
----------
[('‰∏∫', 9011), ('ÁöÑ', 3001)]
----------
[('ÁöÑ', 8991), ('‰∏∫', 3001), ('‰Ωï', 20)]
----------
1
= 0 ===================
[('Âê¶', 2002)]
----------
[('ÊòØ', 2002)]
----------
[('‰∏ç', 2002)]
----------
[('‰∏∫', 1495), ('ÁöÑ', 507)]
----------
[('ÁöÑ', 1492), ('‰∏∫', 507), ('‰Ωï', 3)]
----------
====================
[0 1 5 1 0 1 4 5 1 2 6 2 5 2 3 2 6 0 1 3 0 2 1 5 1 4 6 6 1 1 1 6 4 2 2 0 1
 1 3 5 3 0 1 5 5 0 1 0 2 4 6 2 3 6 0 2 1 2 2 0 4 1 4 3 0 0 6 3 2 3 4 5 0 1
 5 0 5 2 2 5 6 1 0 1 0 0 1 3 5 3 2 6 3 0 5 2 4 2 6 3 2 0 0 6 5 2 2 6 4 0 5
 3 3 3 6 4 5 0 1 2 3 4 1 1 5 6 2 1 1 6 5 3 6 4 6 6 1 6 4 5 1 1 0 0 2 5 0 4
 1 6 5 2 3 1 6 5 0 2 1 2 2 2 0 1 6 1 2 2 1 2 3 3 3 2 4 4 0 2 0 2 1 2 2 3 3
 4 4 3 4 6 3 0 0 1 5 0 5 5 6 4 5 5]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[6 5 4 2 2 0 5 0 4 3 5 5 4 3 0 1 6 3 3 3 6 1 1 5 0 0 3 6 6 5 1 3 6 3 3 0 4
 4 0 4 1 0 6 3 0 0 4 2 2 4 0 3 3 6 1 6 0 2 5 1 2 6 6 2 3 3 4 0 4 2 5 0 4 1
 6 6 4 2 1 6 6 5 2 0 4 2 2 2 3 3 2 2 2 5 5 1 5 4 5 4 2 3 4 2 5 5 2 4 2 2 5
 6 4 4 6 4 6 6 3 4 4 5 2 6 0 6 0 1 5 0 6 6 5 5 3 1 1 6 1 0 6 6 3 0 5 5 0 6
 4 2 2 4 4 6 3 6 6 1 5 2 3 3 0 0 1 1 0 0 1 0 1 3 3 4 0 3 0 3 0 3 0 2 5 2 3
 2 2 1 5 6 3 4 3 2 3 0 1 2 4 2 2 2]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[32m[2022-09-05 13:21:41,833] [    INFO][0m - eval_loss: 0.43162697553634644, eval_accuracy: 0.24752475247524752, eval_runtime: 11.4484, eval_samples_per_second: 123.511, eval_steps_per_second: 15.461, epoch: 1.6949[0m
[32m[2022-09-05 13:21:41,833] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-300[0m
[32m[2022-09-05 13:21:41,833] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:21:44,912] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-300/tokenizer_config.json[0m
[32m[2022-09-05 13:21:44,913] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-300/special_tokens_map.json[0m
[32m[2022-09-05 13:21:51,459] [    INFO][0m - loss: 0.41998177, learning_rate: 9.649717514124294e-06, global_step: 310, interval_runtime: 21.0759, interval_samples_per_second: 0.38, interval_steps_per_second: 0.474, epoch: 1.7514[0m
[32m[2022-09-05 13:21:52,952] [    INFO][0m - loss: 0.38087668, learning_rate: 9.638418079096045e-06, global_step: 320, interval_runtime: 1.4933, interval_samples_per_second: 5.357, interval_steps_per_second: 6.697, epoch: 1.8079[0m
[32m[2022-09-05 13:21:54,452] [    INFO][0m - loss: 0.6925631, learning_rate: 9.627118644067797e-06, global_step: 330, interval_runtime: 1.4994, interval_samples_per_second: 5.335, interval_steps_per_second: 6.669, epoch: 1.8644[0m
[32m[2022-09-05 13:21:55,946] [    INFO][0m - loss: 0.33683364, learning_rate: 9.615819209039548e-06, global_step: 340, interval_runtime: 1.494, interval_samples_per_second: 5.355, interval_steps_per_second: 6.693, epoch: 1.9209[0m
[32m[2022-09-05 13:21:57,438] [    INFO][0m - loss: 0.37718079, learning_rate: 9.6045197740113e-06, global_step: 350, interval_runtime: 1.4922, interval_samples_per_second: 5.361, interval_steps_per_second: 6.701, epoch: 1.9774[0m
[32m[2022-09-05 13:21:58,946] [    INFO][0m - loss: 0.42569532, learning_rate: 9.593220338983051e-06, global_step: 360, interval_runtime: 1.5082, interval_samples_per_second: 5.304, interval_steps_per_second: 6.63, epoch: 2.0339[0m
[32m[2022-09-05 13:22:00,446] [    INFO][0m - loss: 0.42945886, learning_rate: 9.581920903954803e-06, global_step: 370, interval_runtime: 1.4996, interval_samples_per_second: 5.335, interval_steps_per_second: 6.669, epoch: 2.0904[0m
[32m[2022-09-05 13:22:01,947] [    INFO][0m - loss: 0.64417143, learning_rate: 9.570621468926554e-06, global_step: 380, interval_runtime: 1.501, interval_samples_per_second: 5.33, interval_steps_per_second: 6.662, epoch: 2.1469[0m
[32m[2022-09-05 13:22:03,441] [    INFO][0m - loss: 0.53811669, learning_rate: 9.559322033898306e-06, global_step: 390, interval_runtime: 1.4944, interval_samples_per_second: 5.353, interval_steps_per_second: 6.691, epoch: 2.2034[0m
[32m[2022-09-05 13:22:04,943] [    INFO][0m - loss: 0.50720654, learning_rate: 9.548022598870057e-06, global_step: 400, interval_runtime: 1.5015, interval_samples_per_second: 5.328, interval_steps_per_second: 6.66, epoch: 2.2599[0m
[32m[2022-09-05 13:22:04,944] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:22:04,944] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:22:04,944] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:22:04,944] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:22:04,944] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:22:16,332] [    INFO][0m - eval_loss: 0.5527680516242981, eval_accuracy: 0.24752475247524752, eval_runtime: 11.3879, eval_samples_per_second: 124.167, eval_steps_per_second: 15.543, epoch: 2.2599[0m
[32m[2022-09-05 13:22:16,333] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-400[0m
[32m[2022-09-05 13:22:16,333] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:22:19,271] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-400/tokenizer_config.json[0m
[32m[2022-09-05 13:22:19,271] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-400/special_tokens_map.json[0m
[32m[2022-09-05 13:22:25,678] [    INFO][0m - loss: 0.66134996, learning_rate: 9.53672316384181e-06, global_step: 410, interval_runtime: 20.7351, interval_samples_per_second: 0.386, interval_steps_per_second: 0.482, epoch: 2.3164[0m
[32m[2022-09-05 13:22:27,166] [    INFO][0m - loss: 0.36861501, learning_rate: 9.52542372881356e-06, global_step: 420, interval_runtime: 1.4885, interval_samples_per_second: 5.375, interval_steps_per_second: 6.718, epoch: 2.3729[0m
[32m[2022-09-05 13:22:28,654] [    INFO][0m - loss: 0.49842839, learning_rate: 9.514124293785312e-06, global_step: 430, interval_runtime: 1.4878, interval_samples_per_second: 5.377, interval_steps_per_second: 6.721, epoch: 2.4294[0m
[32m[2022-09-05 13:22:30,147] [    INFO][0m - loss: 0.55108824, learning_rate: 9.502824858757063e-06, global_step: 440, interval_runtime: 1.4924, interval_samples_per_second: 5.36, interval_steps_per_second: 6.701, epoch: 2.4859[0m
[32m[2022-09-05 13:22:31,640] [    INFO][0m - loss: 0.4767725, learning_rate: 9.491525423728815e-06, global_step: 450, interval_runtime: 1.4933, interval_samples_per_second: 5.357, interval_steps_per_second: 6.696, epoch: 2.5424[0m
[32m[2022-09-05 13:22:33,130] [    INFO][0m - loss: 0.62087507, learning_rate: 9.480225988700566e-06, global_step: 460, interval_runtime: 1.4903, interval_samples_per_second: 5.368, interval_steps_per_second: 6.71, epoch: 2.5989[0m
[32m[2022-09-05 13:22:34,624] [    INFO][0m - loss: 0.53681931, learning_rate: 9.468926553672318e-06, global_step: 470, interval_runtime: 1.4936, interval_samples_per_second: 5.356, interval_steps_per_second: 6.695, epoch: 2.6554[0m
[32m[2022-09-05 13:22:36,114] [    INFO][0m - loss: 0.45845394, learning_rate: 9.457627118644069e-06, global_step: 480, interval_runtime: 1.49, interval_samples_per_second: 5.369, interval_steps_per_second: 6.711, epoch: 2.7119[0m
[32m[2022-09-05 13:22:37,604] [    INFO][0m - loss: 0.46897912, learning_rate: 9.44632768361582e-06, global_step: 490, interval_runtime: 1.49, interval_samples_per_second: 5.369, interval_steps_per_second: 6.711, epoch: 2.7684[0m
[32m[2022-09-05 13:22:39,094] [    INFO][0m - loss: 0.41817136, learning_rate: 9.435028248587572e-06, global_step: 500, interval_runtime: 1.4906, interval_samples_per_second: 5.367, interval_steps_per_second: 6.709, epoch: 2.8249[0m
[32m[2022-09-05 13:22:39,095] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:22:39,095] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:22:39,095] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:22:39,095] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:22:39,095] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:22:50,352] [    INFO][0m - eval_loss: 0.4131101667881012, eval_accuracy: 0.2376237623762376, eval_runtime: 11.2563, eval_samples_per_second: 125.619, eval_steps_per_second: 15.725, epoch: 2.8249[0m
[32m[2022-09-05 13:22:50,353] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-500[0m
[32m[2022-09-05 13:22:50,353] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:22:54,108] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-500/tokenizer_config.json[0m
[32m[2022-09-05 13:22:54,308] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-500/special_tokens_map.json[0m
[32m[2022-09-05 13:23:01,620] [    INFO][0m - loss: 0.43896537, learning_rate: 9.423728813559322e-06, global_step: 510, interval_runtime: 22.5257, interval_samples_per_second: 0.355, interval_steps_per_second: 0.444, epoch: 2.8814[0m
[32m[2022-09-05 13:23:03,121] [    INFO][0m - loss: 0.38856704, learning_rate: 9.412429378531073e-06, global_step: 520, interval_runtime: 1.5004, interval_samples_per_second: 5.332, interval_steps_per_second: 6.665, epoch: 2.9379[0m
[32m[2022-09-05 13:23:04,607] [    INFO][0m - loss: 0.29479511, learning_rate: 9.401129943502825e-06, global_step: 530, interval_runtime: 1.4866, interval_samples_per_second: 5.382, interval_steps_per_second: 6.727, epoch: 2.9944[0m
[32m[2022-09-05 13:23:06,115] [    INFO][0m - loss: 0.4456172, learning_rate: 9.389830508474576e-06, global_step: 540, interval_runtime: 1.5074, interval_samples_per_second: 5.307, interval_steps_per_second: 6.634, epoch: 3.0508[0m
[32m[2022-09-05 13:23:07,608] [    INFO][0m - loss: 0.52782345, learning_rate: 9.378531073446328e-06, global_step: 550, interval_runtime: 1.4938, interval_samples_per_second: 5.356, interval_steps_per_second: 6.694, epoch: 3.1073[0m
[32m[2022-09-05 13:23:09,102] [    INFO][0m - loss: 0.60171757, learning_rate: 9.367231638418079e-06, global_step: 560, interval_runtime: 1.4933, interval_samples_per_second: 5.357, interval_steps_per_second: 6.697, epoch: 3.1638[0m
[32m[2022-09-05 13:23:10,596] [    INFO][0m - loss: 0.49672766, learning_rate: 9.355932203389831e-06, global_step: 570, interval_runtime: 1.494, interval_samples_per_second: 5.355, interval_steps_per_second: 6.694, epoch: 3.2203[0m
[32m[2022-09-05 13:23:12,092] [    INFO][0m - loss: 0.4256547, learning_rate: 9.344632768361582e-06, global_step: 580, interval_runtime: 1.4961, interval_samples_per_second: 5.347, interval_steps_per_second: 6.684, epoch: 3.2768[0m
[32m[2022-09-05 13:23:13,585] [    INFO][0m - loss: 0.50224285, learning_rate: 9.333333333333334e-06, global_step: 590, interval_runtime: 1.4932, interval_samples_per_second: 5.358, interval_steps_per_second: 6.697, epoch: 3.3333[0m
[32m[2022-09-05 13:23:15,451] [    INFO][0m - loss: 0.47975302, learning_rate: 9.322033898305085e-06, global_step: 600, interval_runtime: 1.8663, interval_samples_per_second: 4.286, interval_steps_per_second: 5.358, epoch: 3.3898[0m
[32m[2022-09-05 13:23:15,452] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:23:15,452] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:23:15,452] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:23:15,452] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:23:15,452] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:23:26,743] [    INFO][0m - eval_loss: 0.4163878262042999, eval_accuracy: 0.2079207920792079, eval_runtime: 11.2899, eval_samples_per_second: 125.244, eval_steps_per_second: 15.678, epoch: 3.3898[0m
[32m[2022-09-05 13:23:26,743] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-600[0m
[32m[2022-09-05 13:23:26,743] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:23:29,948] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-600/tokenizer_config.json[0m
[32m[2022-09-05 13:23:29,949] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-600/special_tokens_map.json[0m
[32m[2022-09-05 13:23:37,493] [    INFO][0m - loss: 0.44300566, learning_rate: 9.310734463276837e-06, global_step: 610, interval_runtime: 22.0414, interval_samples_per_second: 0.363, interval_steps_per_second: 0.454, epoch: 3.4463[0m
[32m[2022-09-05 13:23:38,983] [    INFO][0m - loss: 0.52976642, learning_rate: 9.299435028248588e-06, global_step: 620, interval_runtime: 1.4905, interval_samples_per_second: 5.367, interval_steps_per_second: 6.709, epoch: 3.5028[0m
[32m[2022-09-05 13:23:40,483] [    INFO][0m - loss: 0.41914754, learning_rate: 9.28813559322034e-06, global_step: 630, interval_runtime: 1.4996, interval_samples_per_second: 5.335, interval_steps_per_second: 6.669, epoch: 3.5593[0m
[32m[2022-09-05 13:23:41,986] [    INFO][0m - loss: 0.43814282, learning_rate: 9.276836158192091e-06, global_step: 640, interval_runtime: 1.5028, interval_samples_per_second: 5.324, interval_steps_per_second: 6.654, epoch: 3.6158[0m
[32m[2022-09-05 13:23:43,478] [    INFO][0m - loss: 0.41021357, learning_rate: 9.265536723163843e-06, global_step: 650, interval_runtime: 1.4925, interval_samples_per_second: 5.36, interval_steps_per_second: 6.7, epoch: 3.6723[0m
[32m[2022-09-05 13:23:44,972] [    INFO][0m - loss: 0.4717268, learning_rate: 9.254237288135594e-06, global_step: 660, interval_runtime: 1.494, interval_samples_per_second: 5.355, interval_steps_per_second: 6.693, epoch: 3.7288[0m
[32m[2022-09-05 13:23:46,468] [    INFO][0m - loss: 0.39584422, learning_rate: 9.242937853107346e-06, global_step: 670, interval_runtime: 1.4954, interval_samples_per_second: 5.35, interval_steps_per_second: 6.687, epoch: 3.7853[0m
[32m[2022-09-05 13:23:47,958] [    INFO][0m - loss: 0.40601339, learning_rate: 9.231638418079097e-06, global_step: 680, interval_runtime: 1.491, interval_samples_per_second: 5.366, interval_steps_per_second: 6.707, epoch: 3.8418[0m
[32m[2022-09-05 13:23:49,450] [    INFO][0m - loss: 0.46774292, learning_rate: 9.220338983050847e-06, global_step: 690, interval_runtime: 1.4914, interval_samples_per_second: 5.364, interval_steps_per_second: 6.705, epoch: 3.8983[0m
[32m[2022-09-05 13:23:50,943] [    INFO][0m - loss: 0.5235847, learning_rate: 9.2090395480226e-06, global_step: 700, interval_runtime: 1.4926, interval_samples_per_second: 5.36, interval_steps_per_second: 6.7, epoch: 3.9548[0m
[32m[2022-09-05 13:23:50,943] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:23:50,944] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:23:50,944] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:23:50,944] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:23:50,944] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:24:02,141] [    INFO][0m - eval_loss: 0.41841310262680054, eval_accuracy: 0.19801980198019803, eval_runtime: 11.1963, eval_samples_per_second: 126.292, eval_steps_per_second: 15.809, epoch: 3.9548[0m
[32m[2022-09-05 13:24:02,141] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-700[0m
[32m[2022-09-05 13:24:02,141] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:24:05,589] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-700/tokenizer_config.json[0m
[32m[2022-09-05 13:24:05,589] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-700/special_tokens_map.json[0m
[32m[2022-09-05 13:24:11,089] [    INFO][0m - 
Training completed. 
[0m
[32m[2022-09-05 13:24:11,089] [    INFO][0m - Loading best model from ./checkpoints_chid/checkpoint-300 (score: 0.24752475247524752).[0m
[32m[2022-09-05 13:24:12,003] [    INFO][0m - train_runtime: 245.3225, train_samples_per_second: 288.192, train_steps_per_second: 36.075, train_loss: 0.5952039561952863, epoch: 3.9548[0m
[32m[2022-09-05 13:24:12,004] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/[0m
[32m[2022-09-05 13:24:12,005] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:24:19,346] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/tokenizer_config.json[0m
[32m[2022-09-05 13:24:19,347] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/special_tokens_map.json[0m
[32m[2022-09-05 13:24:19,349] [    INFO][0m - ***** train metrics *****[0m
[32m[2022-09-05 13:24:19,349] [    INFO][0m -   epoch                    =     3.9548[0m
[32m[2022-09-05 13:24:19,349] [    INFO][0m -   train_loss               =     0.5952[0m
[32m[2022-09-05 13:24:19,350] [    INFO][0m -   train_runtime            = 0:04:05.32[0m
[32m[2022-09-05 13:24:19,350] [    INFO][0m -   train_samples_per_second =    288.192[0m
[32m[2022-09-05 13:24:19,350] [    INFO][0m -   train_steps_per_second   =     36.075[0m
[32m[2022-09-05 13:24:19,356] [    INFO][0m - ***** Running Prediction *****[0m
[32m[2022-09-05 13:24:19,356] [    INFO][0m -   Num examples = 14014[0m
[32m[2022-09-05 13:24:19,356] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:24:19,356] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:24:19,356] [    INFO][0m -   Total prediction steps = 1752[0m
[32m[2022-09-05 13:26:13,697] [    INFO][0m - ***** test metrics *****[0m
[32m[2022-09-05 13:26:13,697] [    INFO][0m -   test_accuracy           =     0.2213[0m
[32m[2022-09-05 13:26:13,698] [    INFO][0m -   test_loss               =     0.4317[0m
[32m[2022-09-05 13:26:13,698] [    INFO][0m -   test_runtime            = 0:01:54.34[0m
[32m[2022-09-05 13:26:13,698] [    INFO][0m -   test_samples_per_second =    122.563[0m
[32m[2022-09-05 13:26:13,698] [    INFO][0m -   test_steps_per_second   =     15.323[0m
[33m[2022-09-05 13:26:32,353] [ WARNING][0m - evaluation_strategy reset to IntervalStrategy.STEPS for do_eval is True. you can also set evaluation_strategy='epoch'.[0m
[32m[2022-09-05 13:26:32,353] [    INFO][0m - The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).[0m
[32m[2022-09-05 13:26:32,353] [    INFO][0m - ============================================================[0m
[32m[2022-09-05 13:26:32,353] [    INFO][0m -      Model Configuration Arguments      [0m
[32m[2022-09-05 13:26:32,353] [    INFO][0m - paddle commit id              :65f388690048d0965ec7d3b43fb6ee9d8c6dee7c[0m
[32m[2022-09-05 13:26:32,354] [    INFO][0m - do_save                       :True[0m
[32m[2022-09-05 13:26:32,354] [    INFO][0m - do_test                       :True[0m
[32m[2022-09-05 13:26:32,354] [    INFO][0m - early_stop_patience           :4[0m
[32m[2022-09-05 13:26:32,354] [    INFO][0m - export_type                   :paddle[0m
[32m[2022-09-05 13:26:32,354] [    INFO][0m - model_name_or_path            :ernie-3.0-base-zh[0m
[32m[2022-09-05 13:26:32,354] [    INFO][0m - [0m
[32m[2022-09-05 13:26:32,354] [    INFO][0m - ============================================================[0m
[32m[2022-09-05 13:26:32,354] [    INFO][0m -       Data Configuration Arguments      [0m
[32m[2022-09-05 13:26:32,354] [    INFO][0m - paddle commit id              :65f388690048d0965ec7d3b43fb6ee9d8c6dee7c[0m
[32m[2022-09-05 13:26:32,354] [    INFO][0m - encoder_hidden_size           :200[0m
[32m[2022-09-05 13:26:32,354] [    INFO][0m - prompt                        :[0m
[32m[2022-09-05 13:26:32,354] [    INFO][0m - soft_encoder                  :lstm[0m
[32m[2022-09-05 13:26:32,354] [    INFO][0m - split_id                      :few_all[0m
[32m[2022-09-05 13:26:32,355] [    INFO][0m - task_name                     :chid[0m
[32m[2022-09-05 13:26:32,355] [    INFO][0m - [0m
[32m[2022-09-05 13:26:32,355] [    INFO][0m - Already cached /ssd2/wanghuijuan03/.paddlenlp/models/ernie-3.0-base-zh/ernie_3.0_base_zh.pdparams[0m
[32m[2022-09-05 13:26:33,618] [    INFO][0m - Already cached /ssd2/wanghuijuan03/.paddlenlp/models/ernie-3.0-base-zh/ernie_3.0_base_zh_vocab.txt[0m
[32m[2022-09-05 13:26:33,640] [    INFO][0m - tokenizer config file saved in /ssd2/wanghuijuan03/.paddlenlp/models/ernie-3.0-base-zh/tokenizer_config.json[0m
[32m[2022-09-05 13:26:33,640] [    INFO][0m - Special tokens file saved in /ssd2/wanghuijuan03/.paddlenlp/models/ernie-3.0-base-zh/special_tokens_map.json[0m
[32m[2022-09-05 13:26:33,641] [    INFO][0m - Using template: [{'add_prefix_space': '', 'text': 'text_a'}, {'add_prefix_space': '', 'hard': 'Êã¨Âè∑‰∏≠ÊàêËØ≠Â°´'}, {'add_prefix_space': '', 'text': 'text_b'}, {'add_prefix_space': '', 'hard': 'ÂØπÂêóÔºü'}, {'add_prefix_space': '', 'mask': None}][0m
2022-09-05 13:26:33,643 INFO [download.py:119] unique_endpoints {''}
[32m[2022-09-05 13:26:33,733] [    INFO][0m - ============================================================[0m
[32m[2022-09-05 13:26:33,733] [    INFO][0m -     Training Configuration Arguments    [0m
[32m[2022-09-05 13:26:33,734] [    INFO][0m - paddle commit id              :65f388690048d0965ec7d3b43fb6ee9d8c6dee7c[0m
[32m[2022-09-05 13:26:33,734] [    INFO][0m - _no_sync_in_gradient_accumulation:True[0m
[32m[2022-09-05 13:26:33,734] [    INFO][0m - adam_beta1                    :0.9[0m
[32m[2022-09-05 13:26:33,734] [    INFO][0m - adam_beta2                    :0.999[0m
[32m[2022-09-05 13:26:33,734] [    INFO][0m - adam_epsilon                  :1e-08[0m
[32m[2022-09-05 13:26:33,734] [    INFO][0m - alpha_rdrop                   :5.0[0m
[32m[2022-09-05 13:26:33,734] [    INFO][0m - alpha_rgl                     :0.5[0m
[32m[2022-09-05 13:26:33,734] [    INFO][0m - current_device                :gpu:0[0m
[32m[2022-09-05 13:26:33,734] [    INFO][0m - dataloader_drop_last          :False[0m
[32m[2022-09-05 13:26:33,734] [    INFO][0m - dataloader_num_workers        :0[0m
[32m[2022-09-05 13:26:33,734] [    INFO][0m - device                        :gpu[0m
[32m[2022-09-05 13:26:33,735] [    INFO][0m - disable_tqdm                  :True[0m
[32m[2022-09-05 13:26:33,735] [    INFO][0m - do_eval                       :True[0m
[32m[2022-09-05 13:26:33,735] [    INFO][0m - do_export                     :False[0m
[32m[2022-09-05 13:26:33,735] [    INFO][0m - do_predict                    :False[0m
[32m[2022-09-05 13:26:33,735] [    INFO][0m - do_train                      :True[0m
[32m[2022-09-05 13:26:33,735] [    INFO][0m - eval_batch_size               :8[0m
[32m[2022-09-05 13:26:33,735] [    INFO][0m - eval_steps                    :100[0m
[32m[2022-09-05 13:26:33,735] [    INFO][0m - evaluation_strategy           :IntervalStrategy.STEPS[0m
[32m[2022-09-05 13:26:33,735] [    INFO][0m - first_max_length              :None[0m
[32m[2022-09-05 13:26:33,735] [    INFO][0m - fp16                          :False[0m
[32m[2022-09-05 13:26:33,735] [    INFO][0m - fp16_opt_level                :O1[0m
[32m[2022-09-05 13:26:33,735] [    INFO][0m - freeze_dropout                :False[0m
[32m[2022-09-05 13:26:33,735] [    INFO][0m - freeze_plm                    :False[0m
[32m[2022-09-05 13:26:33,736] [    INFO][0m - gradient_accumulation_steps   :1[0m
[32m[2022-09-05 13:26:33,736] [    INFO][0m - greater_is_better             :True[0m
[32m[2022-09-05 13:26:33,736] [    INFO][0m - ignore_data_skip              :False[0m
[32m[2022-09-05 13:26:33,736] [    INFO][0m - label_names                   :None[0m
[32m[2022-09-05 13:26:33,736] [    INFO][0m - learning_rate                 :1e-05[0m
[32m[2022-09-05 13:26:33,736] [    INFO][0m - load_best_model_at_end        :True[0m
[32m[2022-09-05 13:26:33,736] [    INFO][0m - local_process_index           :0[0m
[32m[2022-09-05 13:26:33,736] [    INFO][0m - local_rank                    :-1[0m
[32m[2022-09-05 13:26:33,736] [    INFO][0m - log_level                     :-1[0m
[32m[2022-09-05 13:26:33,736] [    INFO][0m - log_level_replica             :-1[0m
[32m[2022-09-05 13:26:33,736] [    INFO][0m - log_on_each_node              :True[0m
[32m[2022-09-05 13:26:33,736] [    INFO][0m - logging_dir                   :./checkpoints_chid/runs/Sep05_13-26-32_instance-3bwob41y-01[0m
[32m[2022-09-05 13:26:33,736] [    INFO][0m - logging_first_step            :False[0m
[32m[2022-09-05 13:26:33,736] [    INFO][0m - logging_steps                 :10[0m
[32m[2022-09-05 13:26:33,737] [    INFO][0m - logging_strategy              :IntervalStrategy.STEPS[0m
[32m[2022-09-05 13:26:33,737] [    INFO][0m - lr_scheduler_type             :SchedulerType.LINEAR[0m
[32m[2022-09-05 13:26:33,737] [    INFO][0m - max_grad_norm                 :1.0[0m
[32m[2022-09-05 13:26:33,737] [    INFO][0m - max_seq_length                :256[0m
[32m[2022-09-05 13:26:33,737] [    INFO][0m - max_steps                     :-1[0m
[32m[2022-09-05 13:26:33,737] [    INFO][0m - metric_for_best_model         :accuracy[0m
[32m[2022-09-05 13:26:33,737] [    INFO][0m - minimum_eval_times            :None[0m
[32m[2022-09-05 13:26:33,737] [    INFO][0m - no_cuda                       :False[0m
[32m[2022-09-05 13:26:33,737] [    INFO][0m - num_train_epochs              :50.0[0m
[32m[2022-09-05 13:26:33,737] [    INFO][0m - optim                         :OptimizerNames.ADAMW[0m
[32m[2022-09-05 13:26:33,737] [    INFO][0m - other_max_length              :None[0m
[32m[2022-09-05 13:26:33,737] [    INFO][0m - output_dir                    :./checkpoints_chid/[0m
[32m[2022-09-05 13:26:33,737] [    INFO][0m - overwrite_output_dir          :False[0m
[32m[2022-09-05 13:26:33,738] [    INFO][0m - past_index                    :-1[0m
[32m[2022-09-05 13:26:33,738] [    INFO][0m - per_device_eval_batch_size    :8[0m
[32m[2022-09-05 13:26:33,738] [    INFO][0m - per_device_train_batch_size   :8[0m
[32m[2022-09-05 13:26:33,738] [    INFO][0m - ppt_adam_beta1                :0.9[0m
[32m[2022-09-05 13:26:33,738] [    INFO][0m - ppt_adam_beta2                :0.999[0m
[32m[2022-09-05 13:26:33,738] [    INFO][0m - ppt_adam_epsilon              :1e-08[0m
[32m[2022-09-05 13:26:33,738] [    INFO][0m - ppt_learning_rate             :1e-05[0m
[32m[2022-09-05 13:26:33,738] [    INFO][0m - ppt_weight_decay              :0.0[0m
[32m[2022-09-05 13:26:33,738] [    INFO][0m - prediction_loss_only          :False[0m
[32m[2022-09-05 13:26:33,738] [    INFO][0m - process_index                 :0[0m
[32m[2022-09-05 13:26:33,738] [    INFO][0m - remove_unused_columns         :True[0m
[32m[2022-09-05 13:26:33,738] [    INFO][0m - report_to                     :['visualdl'][0m
[32m[2022-09-05 13:26:33,738] [    INFO][0m - resume_from_checkpoint        :None[0m
[32m[2022-09-05 13:26:33,739] [    INFO][0m - run_name                      :./checkpoints_chid/[0m
[32m[2022-09-05 13:26:33,739] [    INFO][0m - save_on_each_node             :False[0m
[32m[2022-09-05 13:26:33,739] [    INFO][0m - save_steps                    :100[0m
[32m[2022-09-05 13:26:33,739] [    INFO][0m - save_strategy                 :IntervalStrategy.STEPS[0m
[32m[2022-09-05 13:26:33,739] [    INFO][0m - save_total_limit              :None[0m
[32m[2022-09-05 13:26:33,739] [    INFO][0m - scale_loss                    :32768[0m
[32m[2022-09-05 13:26:33,739] [    INFO][0m - seed                          :42[0m
[32m[2022-09-05 13:26:33,739] [    INFO][0m - should_log                    :True[0m
[32m[2022-09-05 13:26:33,739] [    INFO][0m - should_save                   :True[0m
[32m[2022-09-05 13:26:33,739] [    INFO][0m - task_type                     :multi-class[0m
[32m[2022-09-05 13:26:33,739] [    INFO][0m - train_batch_size              :8[0m
[32m[2022-09-05 13:26:33,739] [    INFO][0m - truncate_mode                 :tail[0m
[32m[2022-09-05 13:26:33,739] [    INFO][0m - use_rdrop                     :False[0m
[32m[2022-09-05 13:26:33,739] [    INFO][0m - use_rgl                       :False[0m
[32m[2022-09-05 13:26:33,740] [    INFO][0m - warmup_ratio                  :0.0[0m
[32m[2022-09-05 13:26:33,740] [    INFO][0m - warmup_steps                  :0[0m
[32m[2022-09-05 13:26:33,740] [    INFO][0m - weight_decay                  :0.0[0m
[32m[2022-09-05 13:26:33,740] [    INFO][0m - world_size                    :1[0m
[32m[2022-09-05 13:26:33,740] [    INFO][0m - [0m
[32m[2022-09-05 13:26:33,741] [    INFO][0m - ***** Running training *****[0m
[32m[2022-09-05 13:26:33,741] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:26:33,742] [    INFO][0m -   Num Epochs = 50[0m
[32m[2022-09-05 13:26:33,742] [    INFO][0m -   Instantaneous batch size per device = 8[0m
[32m[2022-09-05 13:26:33,742] [    INFO][0m -   Total train batch size (w. parallel, distributed & accumulation) = 8[0m
[32m[2022-09-05 13:26:33,742] [    INFO][0m -   Gradient Accumulation steps = 1[0m
[32m[2022-09-05 13:26:33,742] [    INFO][0m -   Total optimization steps = 8850.0[0m
[32m[2022-09-05 13:26:33,742] [    INFO][0m -   Total num train samples = 70700[0m
[32m[2022-09-05 13:26:35,306] [    INFO][0m - loss: 5.57272949, learning_rate: 9.988700564971753e-06, global_step: 10, interval_runtime: 1.5632, interval_samples_per_second: 5.118, interval_steps_per_second: 6.397, epoch: 0.0565[0m
[32m[2022-09-05 13:26:36,796] [    INFO][0m - loss: 0.80571547, learning_rate: 9.977401129943504e-06, global_step: 20, interval_runtime: 1.4906, interval_samples_per_second: 5.367, interval_steps_per_second: 6.709, epoch: 0.113[0m
[32m[2022-09-05 13:26:38,288] [    INFO][0m - loss: 0.89809189, learning_rate: 9.966101694915256e-06, global_step: 30, interval_runtime: 1.4912, interval_samples_per_second: 5.365, interval_steps_per_second: 6.706, epoch: 0.1695[0m
[32m[2022-09-05 13:26:39,780] [    INFO][0m - loss: 0.93759747, learning_rate: 9.954802259887007e-06, global_step: 40, interval_runtime: 1.4925, interval_samples_per_second: 5.36, interval_steps_per_second: 6.7, epoch: 0.226[0m
[32m[2022-09-05 13:26:41,378] [    INFO][0m - loss: 0.47796469, learning_rate: 9.943502824858759e-06, global_step: 50, interval_runtime: 1.5981, interval_samples_per_second: 5.006, interval_steps_per_second: 6.257, epoch: 0.2825[0m
[32m[2022-09-05 13:26:42,868] [    INFO][0m - loss: 0.2899776, learning_rate: 9.93220338983051e-06, global_step: 60, interval_runtime: 1.4897, interval_samples_per_second: 5.37, interval_steps_per_second: 6.713, epoch: 0.339[0m
[32m[2022-09-05 13:26:44,357] [    INFO][0m - loss: 1.11791687, learning_rate: 9.92090395480226e-06, global_step: 70, interval_runtime: 1.4896, interval_samples_per_second: 5.371, interval_steps_per_second: 6.713, epoch: 0.3955[0m
[32m[2022-09-05 13:26:45,847] [    INFO][0m - loss: 0.78380637, learning_rate: 9.909604519774013e-06, global_step: 80, interval_runtime: 1.4899, interval_samples_per_second: 5.369, interval_steps_per_second: 6.712, epoch: 0.452[0m
[32m[2022-09-05 13:26:47,336] [    INFO][0m - loss: 0.61140003, learning_rate: 9.898305084745763e-06, global_step: 90, interval_runtime: 1.4887, interval_samples_per_second: 5.374, interval_steps_per_second: 6.717, epoch: 0.5085[0m
[32m[2022-09-05 13:26:48,829] [    INFO][0m - loss: 0.51687355, learning_rate: 9.887005649717516e-06, global_step: 100, interval_runtime: 1.4932, interval_samples_per_second: 5.358, interval_steps_per_second: 6.697, epoch: 0.565[0m
[32m[2022-09-05 13:26:48,830] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:26:48,830] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:26:48,830] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:26:48,830] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:26:48,830] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:27:00,076] [    INFO][0m - eval_loss: 0.42581966519355774, eval_accuracy: 0.12376237623762376, eval_runtime: 11.2453, eval_samples_per_second: 125.742, eval_steps_per_second: 15.74, epoch: 0.565[0m
[32m[2022-09-05 13:27:00,076] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-100[0m
[32m[2022-09-05 13:27:00,077] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:27:03,391] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-100/tokenizer_config.json[0m
[32m[2022-09-05 13:27:03,392] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-100/special_tokens_map.json[0m
[32m[2022-09-05 13:27:10,214] [    INFO][0m - loss: 0.45533795, learning_rate: 9.875706214689266e-06, global_step: 110, interval_runtime: 21.385, interval_samples_per_second: 0.374, interval_steps_per_second: 0.468, epoch: 0.6215[0m
[32m[2022-09-05 13:27:11,707] [    INFO][0m - loss: 0.39855158, learning_rate: 9.864406779661017e-06, global_step: 120, interval_runtime: 1.493, interval_samples_per_second: 5.358, interval_steps_per_second: 6.698, epoch: 0.678[0m
[32m[2022-09-05 13:27:13,198] [    INFO][0m - loss: 0.5490128, learning_rate: 9.85310734463277e-06, global_step: 130, interval_runtime: 1.4907, interval_samples_per_second: 5.366, interval_steps_per_second: 6.708, epoch: 0.7345[0m
[32m[2022-09-05 13:27:14,688] [    INFO][0m - loss: 0.45490632, learning_rate: 9.84180790960452e-06, global_step: 140, interval_runtime: 1.4896, interval_samples_per_second: 5.37, interval_steps_per_second: 6.713, epoch: 0.791[0m
[32m[2022-09-05 13:27:16,179] [    INFO][0m - loss: 0.51315846, learning_rate: 9.830508474576272e-06, global_step: 150, interval_runtime: 1.4914, interval_samples_per_second: 5.364, interval_steps_per_second: 6.705, epoch: 0.8475[0m
[32m[2022-09-05 13:27:17,672] [    INFO][0m - loss: 0.5434957, learning_rate: 9.819209039548023e-06, global_step: 160, interval_runtime: 1.4925, interval_samples_per_second: 5.36, interval_steps_per_second: 6.7, epoch: 0.904[0m
[32m[2022-09-05 13:27:19,164] [    INFO][0m - loss: 0.49258685, learning_rate: 9.807909604519775e-06, global_step: 170, interval_runtime: 1.4925, interval_samples_per_second: 5.36, interval_steps_per_second: 6.7, epoch: 0.9605[0m
[32m[2022-09-05 13:27:20,676] [    INFO][0m - loss: 0.45276217, learning_rate: 9.796610169491526e-06, global_step: 180, interval_runtime: 1.5123, interval_samples_per_second: 5.29, interval_steps_per_second: 6.613, epoch: 1.0169[0m
[32m[2022-09-05 13:27:22,170] [    INFO][0m - loss: 0.50119476, learning_rate: 9.785310734463278e-06, global_step: 190, interval_runtime: 1.4935, interval_samples_per_second: 5.357, interval_steps_per_second: 6.696, epoch: 1.0734[0m
[32m[2022-09-05 13:27:23,663] [    INFO][0m - loss: 0.50604315, learning_rate: 9.774011299435029e-06, global_step: 200, interval_runtime: 1.4931, interval_samples_per_second: 5.358, interval_steps_per_second: 6.697, epoch: 1.1299[0m
[32m[2022-09-05 13:27:23,664] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:27:23,664] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:27:23,664] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:27:23,664] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:27:23,664] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:27:34,860] [    INFO][0m - eval_loss: 0.41784054040908813, eval_accuracy: 0.17326732673267325, eval_runtime: 11.1951, eval_samples_per_second: 126.305, eval_steps_per_second: 15.81, epoch: 1.1299[0m
[32m[2022-09-05 13:27:34,860] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-200[0m
[32m[2022-09-05 13:27:34,860] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:27:37,948] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-200/tokenizer_config.json[0m
[32m[2022-09-05 13:27:37,949] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-200/special_tokens_map.json[0m
[32m[2022-09-05 13:27:44,963] [    INFO][0m - loss: 0.37586541, learning_rate: 9.762711864406781e-06, global_step: 210, interval_runtime: 21.2998, interval_samples_per_second: 0.376, interval_steps_per_second: 0.469, epoch: 1.1864[0m
[32m[2022-09-05 13:27:46,455] [    INFO][0m - loss: 0.75052481, learning_rate: 9.751412429378532e-06, global_step: 220, interval_runtime: 1.4915, interval_samples_per_second: 5.364, interval_steps_per_second: 6.705, epoch: 1.2429[0m
[32m[2022-09-05 13:27:47,944] [    INFO][0m - loss: 0.43194833, learning_rate: 9.740112994350284e-06, global_step: 230, interval_runtime: 1.4893, interval_samples_per_second: 5.372, interval_steps_per_second: 6.714, epoch: 1.2994[0m
[32m[2022-09-05 13:27:49,437] [    INFO][0m - loss: 0.49932055, learning_rate: 9.728813559322035e-06, global_step: 240, interval_runtime: 1.4935, interval_samples_per_second: 5.357, interval_steps_per_second: 6.696, epoch: 1.3559[0m
[32m[2022-09-05 13:27:50,929] [    INFO][0m - loss: 0.28007872, learning_rate: 9.717514124293787e-06, global_step: 250, interval_runtime: 1.4919, interval_samples_per_second: 5.362, interval_steps_per_second: 6.703, epoch: 1.4124[0m
[32m[2022-09-05 13:27:52,420] [    INFO][0m - loss: 0.67099338, learning_rate: 9.706214689265538e-06, global_step: 260, interval_runtime: 1.4912, interval_samples_per_second: 5.365, interval_steps_per_second: 6.706, epoch: 1.4689[0m
[32m[2022-09-05 13:27:53,914] [    INFO][0m - loss: 0.36774392, learning_rate: 9.69491525423729e-06, global_step: 270, interval_runtime: 1.4938, interval_samples_per_second: 5.356, interval_steps_per_second: 6.694, epoch: 1.5254[0m
[32m[2022-09-05 13:27:55,405] [    INFO][0m - loss: 0.57305989, learning_rate: 9.68361581920904e-06, global_step: 280, interval_runtime: 1.4911, interval_samples_per_second: 5.365, interval_steps_per_second: 6.706, epoch: 1.5819[0m
[32m[2022-09-05 13:27:56,904] [    INFO][0m - loss: 0.36054213, learning_rate: 9.672316384180791e-06, global_step: 290, interval_runtime: 1.4988, interval_samples_per_second: 5.338, interval_steps_per_second: 6.672, epoch: 1.6384[0m
[32m[2022-09-05 13:27:58,398] [    INFO][0m - loss: 0.62934895, learning_rate: 9.661016949152544e-06, global_step: 300, interval_runtime: 1.4936, interval_samples_per_second: 5.356, interval_steps_per_second: 6.695, epoch: 1.6949[0m
[32m[2022-09-05 13:27:58,398] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:27:58,398] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:27:58,398] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:27:58,398] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:27:58,399] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:28:09,598] [    INFO][0m - eval_loss: 0.43760231137275696, eval_accuracy: 0.22772277227722773, eval_runtime: 11.1989, eval_samples_per_second: 126.263, eval_steps_per_second: 15.805, epoch: 1.6949[0m
[32m[2022-09-05 13:28:09,598] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-300[0m
[32m[2022-09-05 13:28:09,599] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:28:12,626] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-300/tokenizer_config.json[0m
[32m[2022-09-05 13:28:12,627] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-300/special_tokens_map.json[0m
[32m[2022-09-05 13:28:19,156] [    INFO][0m - loss: 0.42530465, learning_rate: 9.649717514124294e-06, global_step: 310, interval_runtime: 20.7585, interval_samples_per_second: 0.385, interval_steps_per_second: 0.482, epoch: 1.7514[0m
[32m[2022-09-05 13:28:20,647] [    INFO][0m - loss: 0.42520146, learning_rate: 9.638418079096045e-06, global_step: 320, interval_runtime: 1.4901, interval_samples_per_second: 5.369, interval_steps_per_second: 6.711, epoch: 1.8079[0m
[32m[2022-09-05 13:28:22,141] [    INFO][0m - loss: 0.72450004, learning_rate: 9.627118644067797e-06, global_step: 330, interval_runtime: 1.4943, interval_samples_per_second: 5.354, interval_steps_per_second: 6.692, epoch: 1.8644[0m
[32m[2022-09-05 13:28:23,636] [    INFO][0m - loss: 0.31073408, learning_rate: 9.615819209039548e-06, global_step: 340, interval_runtime: 1.4956, interval_samples_per_second: 5.349, interval_steps_per_second: 6.686, epoch: 1.9209[0m
[32m[2022-09-05 13:28:25,128] [    INFO][0m - loss: 0.39330707, learning_rate: 9.6045197740113e-06, global_step: 350, interval_runtime: 1.4913, interval_samples_per_second: 5.364, interval_steps_per_second: 6.705, epoch: 1.9774[0m
[32m[2022-09-05 13:28:26,631] [    INFO][0m - loss: 0.3938144, learning_rate: 9.593220338983051e-06, global_step: 360, interval_runtime: 1.5036, interval_samples_per_second: 5.32, interval_steps_per_second: 6.651, epoch: 2.0339[0m
[32m[2022-09-05 13:28:28,126] [    INFO][0m - loss: 0.4179028, learning_rate: 9.581920903954803e-06, global_step: 370, interval_runtime: 1.4941, interval_samples_per_second: 5.354, interval_steps_per_second: 6.693, epoch: 2.0904[0m
[32m[2022-09-05 13:28:29,616] [    INFO][0m - loss: 0.64126525, learning_rate: 9.570621468926554e-06, global_step: 380, interval_runtime: 1.4905, interval_samples_per_second: 5.367, interval_steps_per_second: 6.709, epoch: 2.1469[0m
[32m[2022-09-05 13:28:31,107] [    INFO][0m - loss: 0.53129406, learning_rate: 9.559322033898306e-06, global_step: 390, interval_runtime: 1.4914, interval_samples_per_second: 5.364, interval_steps_per_second: 6.705, epoch: 2.2034[0m
[32m[2022-09-05 13:28:32,600] [    INFO][0m - loss: 0.48730931, learning_rate: 9.548022598870057e-06, global_step: 400, interval_runtime: 1.4925, interval_samples_per_second: 5.36, interval_steps_per_second: 6.7, epoch: 2.2599[0m
[32m[2022-09-05 13:28:32,600] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:28:32,600] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:28:32,600] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:28:32,600] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:28:32,601] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:28:43,822] [    INFO][0m - eval_loss: 0.5314068794250488, eval_accuracy: 0.28217821782178215, eval_runtime: 11.2211, eval_samples_per_second: 126.013, eval_steps_per_second: 15.774, epoch: 2.2599[0m
[32m[2022-09-05 13:28:43,823] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-400[0m
[32m[2022-09-05 13:28:43,823] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:28:46,796] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-400/tokenizer_config.json[0m
[32m[2022-09-05 13:28:46,797] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-400/special_tokens_map.json[0m
[32m[2022-09-05 13:28:53,531] [    INFO][0m - loss: 0.60631123, learning_rate: 9.53672316384181e-06, global_step: 410, interval_runtime: 20.9317, interval_samples_per_second: 0.382, interval_steps_per_second: 0.478, epoch: 2.3164[0m
[32m[2022-09-05 13:28:55,023] [    INFO][0m - loss: 0.39404626, learning_rate: 9.52542372881356e-06, global_step: 420, interval_runtime: 1.4917, interval_samples_per_second: 5.363, interval_steps_per_second: 6.704, epoch: 2.3729[0m
[32m[2022-09-05 13:28:56,514] [    INFO][0m - loss: 0.45560932, learning_rate: 9.514124293785312e-06, global_step: 430, interval_runtime: 1.4907, interval_samples_per_second: 5.366, interval_steps_per_second: 6.708, epoch: 2.4294[0m
[32m[2022-09-05 13:28:58,005] [    INFO][0m - loss: 0.51622305, learning_rate: 9.502824858757063e-06, global_step: 440, interval_runtime: 1.4914, interval_samples_per_second: 5.364, interval_steps_per_second: 6.705, epoch: 2.4859[0m
[32m[2022-09-05 13:28:59,497] [    INFO][0m - loss: 0.48380742, learning_rate: 9.491525423728815e-06, global_step: 450, interval_runtime: 1.4918, interval_samples_per_second: 5.363, interval_steps_per_second: 6.703, epoch: 2.5424[0m
[32m[2022-09-05 13:29:00,988] [    INFO][0m - loss: 0.60278139, learning_rate: 9.480225988700566e-06, global_step: 460, interval_runtime: 1.4906, interval_samples_per_second: 5.367, interval_steps_per_second: 6.709, epoch: 2.5989[0m
[32m[2022-09-05 13:29:02,480] [    INFO][0m - loss: 0.4905139, learning_rate: 9.468926553672318e-06, global_step: 470, interval_runtime: 1.4921, interval_samples_per_second: 5.362, interval_steps_per_second: 6.702, epoch: 2.6554[0m
[32m[2022-09-05 13:29:03,971] [    INFO][0m - loss: 0.45390253, learning_rate: 9.457627118644069e-06, global_step: 480, interval_runtime: 1.4913, interval_samples_per_second: 5.364, interval_steps_per_second: 6.706, epoch: 2.7119[0m
[32m[2022-09-05 13:29:05,463] [    INFO][0m - loss: 0.44744463, learning_rate: 9.44632768361582e-06, global_step: 490, interval_runtime: 1.492, interval_samples_per_second: 5.362, interval_steps_per_second: 6.702, epoch: 2.7684[0m
[32m[2022-09-05 13:29:06,953] [    INFO][0m - loss: 0.37206645, learning_rate: 9.435028248587572e-06, global_step: 500, interval_runtime: 1.49, interval_samples_per_second: 5.369, interval_steps_per_second: 6.711, epoch: 2.8249[0m
[32m[2022-09-05 13:29:06,954] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:29:06,954] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:29:06,954] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:29:06,954] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:29:06,954] [    INFO][0m -   Total prediction steps = 177[0m
[6 5 0 4 0 0 5 2 5 3 0 2 5 3 1 4 1 1 3 3 6 1 1 5 5 0 3 5 0 4 3 3 3 3 3 5 5
 4 3 3 6 0 0 3 1 2 0 2 2 4 0 3 0 5 0 6 4 2 5 3 2 6 6 2 6 3 4 2 1 2 4 5 4 3
 6 6 3 4 3 6 6 4 0 4 4 3 2 0 6 4 3 6 4 1 5 4 5 0 0 4 2 3 3 0 4 3 3 4 2 5 0
 4 2 3 6 4 4 3 6 6 5 6 2 6 6 4 0 1 5 6 5 3 1 5 5 5 3 6 4 3 4 6 3 0 6 5 0 0
 1 2 0 4 0 6 3 5 6 2 5 4 1 3 0 0 0 1 2 0 1 2 4 3 3 4 0 5 0 5 3 3 2 4 1 2 3
 1 1 1 6 1 3 1 3 2 5 1 1 4 3 6 3 2]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[6 0 5 6 4 0 1 2 6 3 5 2 4 3 1 6 0 5 5 6 6 3 0 2 1 5 2 2 4 4 3 0 2 6 3 3 2
 5 0 1 1 2 4 3 0 2 2 2 2 5 0 3 5 5 0 6 0 1 6 3 6 0 4 3 2 3 6 5 4 6 3 6 4 3
 4 2 3 5 6 6 5 0 5 5 0 3 4 0 4 4 2 6 4 0 5 4 5 1 4 3 2 4 4 0 0 4 6 4 2 5 4
 2 2 3 5 6 4 5 6 4 5 0 6 3 0 4 0 1 3 2 6 1 1 4 5 5 1 1 6 5 5 2 0 1 5 5 4 6
 1 5 0 2 1 3 3 6 3 0 5 6 4 2 0 1 0 4 0 5 2 5 1 2 4 1 0 6 0 4 1 3 3 4 5 6 0
 2 1 5 1 1 3 3 1 4 2 3 5 1 1 0 6 1]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[3 2 0 3 2 3 5 3 2 3 2 1 2 5 5 3 0 1 1 6 4 4 2 3 2 6 4 2 2 4 3 1 3 6 3 0 0
 5 6 6 2 2 4 1 0 3 2 0 3 1 0 2 2 1 0 6 5 6 0 3 5 6 4 4 6 4 5 6 6 5 6 4 6 3
 6 2 3 1 1 6 2 5 5 0 2 1 4 4 5 6 3 3 5 5 4 3 5 1 4 3 5 4 5 2 0 6 4 5 2 5 1
 0 4 4 0 4 6 1 0 5 6 0 4 5 3 5 1 2 0 2 5 2 3 4 5 5 6 6 3 2 4 0 5 6 6 4 4 0
 2 5 2 2 1 3 3 3 6 6 5 0 0 4 1 2 1 1 5 3 2 5 4 2 6 5 5 3 0 4 3 3 1 4 5 4 1
 6 5 5 1 1 0 5 5 0 6 1 2 6 1 1 6 4]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[6 5 1 3 2 3 4 1 2 3 4 2 5 4 5 1 2 1 0 6 5 1 1 2 2 6 4 5 2 4 4 2 5 3 3 0 3
 3 3 2 0 6 6 4 6 6 2 3 1 1 1 2 3 1 4 5 4 5 0 5 5 1 6 2 2 6 0 4 2 0 2 6 4 3
 3 1 2 1 3 2 1 6 5 4 3 3 1 2 2 2 2 6 5 4 1 5 4 3 1 4 3 1 5 6 2 6 6 4 6 5 5
 5 4 4 5 4 6 4 2 5 0 4 4 0 1 4 5 4 4 6 6 2 3 3 1 1 5 6 1 6 3 6 3 0 6 2 0 1
 1 2 3 2 1 3 0 3 0 0 5 1 4 0 4 0 1 1 4 3 5 6 6 4 6 0 3 0 1 1 6 2 1 0 1 3 0
 5 5 3 6 1 3 3 5 3 4 1 5 6 1 6 3 1]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[3 3 6 3 5 3 1 1 3 3 2 5 3 2 6 1 2 1 1 2 2 0 6 2 6 6 4 1 2 3 6 2 3 0 1 2 0
 3 1 2 0 5 4 3 0 0 6 4 3 1 6 2 3 5 0 6 4 1 6 4 3 0 4 4 3 4 2 6 2 3 6 2 3 3
 3 2 3 1 3 4 6 3 5 2 5 2 5 2 1 4 6 4 5 1 4 0 6 6 4 6 3 4 2 5 1 6 6 0 2 4 5
 6 6 6 6 4 0 1 2 5 1 6 4 0 1 3 3 5 2 0 2 6 6 0 0 5 0 6 3 6 5 3 3 5 6 4 1 1
 2 1 0 2 1 0 2 3 6 3 0 5 1 4 1 6 4 1 5 6 4 3 2 6 0 5 0 0 0 3 4 1 1 5 1 1 3
 2 5 5 3 4 4 2 5 1 2 1 1 6 2 6 0 1]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[3 1 4 ... 2 1 5]
[1 1 1 ... 1 1 1]
0
= 0 ===================
[('Âê¶', 12012)]
----------
[('ÊòØ', 12012)]
----------
[('‰∏ç', 11056), ('Êúâ', 956)]
----------
[('Êúâ', 9830), ('Ê≤°', 1222), ('‰∏ç', 956), ('?', 2), ('‰πà', 2)]
----------
[('Ê≤°', 10412), ('Êúâ', 1160), ('?', 395), ('Âêó', 25), ('‰πà', 9), ('‰∏∫', 5), ('Êó†', 4), ('ÁöÑ', 2)]
----------
1
= 0 ===================
[('Âê¶', 2002)]
----------
[('ÊòØ', 2002)]
----------
[('‰∏ç', 1810), ('Êúâ', 192)]
----------
[('Êúâ', 1614), ('Ê≤°', 194), ('‰∏ç', 192), ('?', 1), ('‰πà', 1)]
----------
[('Ê≤°', 1724), ('Êúâ', 186), ('?', 86), ('Âêó', 4), ('‰∏∫', 1), ('ÁöÑ', 1)]
----------
====================
[1 6 4 6 3 1 3 6 2 5 4 1 0 4 2 6 6 0 5 0 3 0 0 5 6 2 0 3 0 2 1 5 2 4 2 0 6
 1 1 6 6 0 2 1 3 2 2 5 0 0 4 4 4 2 0 4 2 3 4 6 4 2 3 6 3 6 6 0 0 0 2 2 4 0
 1 3 1 1 5 1 5 6 3 4 6 2 0 3 0 5 2 1 0 3 5 1 4 4 4 3 0 3 3 2 0 3 6 0 1 3 2
 3 1 4 5 1 3 4 3 4 4 3 0 2 3 2 1 4 5 2 5 2 3 2 2 0 3 5 2 5 3 5 2 5 5 4 6 0
 5 3 2 5 1 3 0 2 5 1 6 6 4 5 3 6 3 5 3 1 4 3 5 6 2 4 3 0 5 2 0 5 3 5 3 3 3
 4 5 5 2 6 1 6 0 3 2 3 4 2 0 5 2 1]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[1 6 5 5 4 1 1 6 1 6 6 5 2 6 6 2 1 1 4 4 3 2 5 3 6 2 2 5 6 2 5 3 6 3 3 0 4
 1 0 6 0 0 2 4 1 6 2 0 4 0 5 6 4 4 5 2 0 5 5 6 0 5 5 1 6 6 6 5 1 0 2 0 5 4
 1 5 4 6 2 1 3 6 3 0 6 2 6 2 1 5 4 4 4 2 6 1 4 2 0 3 5 0 5 2 2 1 0 2 1 3 0
 3 6 4 5 0 6 6 2 1 1 3 0 5 2 6 0 4 5 5 5 1 3 6 4 5 2 0 2 3 4 3 3 5 0 2 1 6
 3 4 1 5 6 4 0 2 4 0 1 4 0 5 3 6 2 4 3 4 1 2 5 1 2 3 3 5 5 3 3 5 0 5 0 3 4
 0 0 1 1 5 2 0 1 4 0 3 6 1 1 2 3 4]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[0 6 5 3 2 2 1 2 2 6 6 4 0 0 5 6 5 2 4 3 3 0 4 3 1 2 1 2 2 3 2 0 6 4 3 0 6
 4 4 6 0 3 2 4 3 5 0 5 4 5 4 3 3 5 3 3 1 6 2 6 0 5 3 6 6 6 5 1 1 1 2 6 4 3
 0 2 5 1 4 1 1 6 3 2 2 1 6 6 3 4 2 4 5 3 1 4 4 4 2 3 3 3 3 4 0 3 4 0 5 3 6
 2 1 0 2 3 4 4 0 4 1 3 0 5 2 6 0 4 6 2 5 0 2 2 2 2 4 0 2 2 3 2 2 4 5 4 6 3
 5 4 1 5 0 3 0 5 6 0 1 3 0 1 3 1 1 1 3 3 4 3 5 1 6 5 3 6 5 3 1 5 5 5 1 5 0
 0 5 1 1 5 4 3 1 4 4 4 2 6 1 1 3 6]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[1 0 5 5 2 2 0 6 1 6 6 5 2 6 4 4 4 2 3 4 3 2 6 2 2 2 5 2 6 2 0 2 5 3 3 0 4
 4 6 6 0 3 3 4 0 2 0 0 4 4 5 3 4 4 3 1 3 6 2 6 5 5 5 1 2 6 5 0 3 6 2 6 0 3
 5 6 4 1 4 1 1 6 3 5 6 6 6 6 1 5 2 4 5 5 5 4 4 1 6 3 3 3 3 2 3 5 5 0 5 3 4
 2 6 4 4 3 2 5 1 4 1 5 3 5 2 5 0 4 5 2 5 4 2 2 3 1 4 2 3 2 4 0 5 5 5 2 0 1
 0 5 1 0 3 3 0 4 0 0 1 4 0 0 3 6 1 6 3 1 1 0 5 1 6 0 4 4 5 0 1 4 0 1 4 4 5
 0 5 1 1 5 1 4 1 4 0 3 2 6 1 6 3 3]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[32m[2022-09-05 13:29:18,187] [    INFO][0m - eval_loss: 0.43422508239746094, eval_accuracy: 0.3465346534653465, eval_runtime: 11.2323, eval_samples_per_second: 125.886, eval_steps_per_second: 15.758, epoch: 2.8249[0m
[32m[2022-09-05 13:29:18,187] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-500[0m
[32m[2022-09-05 13:29:18,187] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:29:21,483] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-500/tokenizer_config.json[0m
[32m[2022-09-05 13:29:21,483] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-500/special_tokens_map.json[0m
[32m[2022-09-05 13:29:28,260] [    INFO][0m - loss: 0.38655529, learning_rate: 9.423728813559322e-06, global_step: 510, interval_runtime: 21.3066, interval_samples_per_second: 0.375, interval_steps_per_second: 0.469, epoch: 2.8814[0m
[32m[2022-09-05 13:29:29,750] [    INFO][0m - loss: 0.39607966, learning_rate: 9.412429378531073e-06, global_step: 520, interval_runtime: 1.4906, interval_samples_per_second: 5.367, interval_steps_per_second: 6.709, epoch: 2.9379[0m
[32m[2022-09-05 13:29:31,232] [    INFO][0m - loss: 0.31526518, learning_rate: 9.401129943502825e-06, global_step: 530, interval_runtime: 1.4818, interval_samples_per_second: 5.399, interval_steps_per_second: 6.748, epoch: 2.9944[0m
[32m[2022-09-05 13:29:32,737] [    INFO][0m - loss: 0.36877201, learning_rate: 9.389830508474576e-06, global_step: 540, interval_runtime: 1.5049, interval_samples_per_second: 5.316, interval_steps_per_second: 6.645, epoch: 3.0508[0m
[32m[2022-09-05 13:29:34,228] [    INFO][0m - loss: 0.52008724, learning_rate: 9.378531073446328e-06, global_step: 550, interval_runtime: 1.4912, interval_samples_per_second: 5.365, interval_steps_per_second: 6.706, epoch: 3.1073[0m
[32m[2022-09-05 13:29:35,718] [    INFO][0m - loss: 0.57628865, learning_rate: 9.367231638418079e-06, global_step: 560, interval_runtime: 1.4898, interval_samples_per_second: 5.37, interval_steps_per_second: 6.712, epoch: 3.1638[0m
[32m[2022-09-05 13:29:37,208] [    INFO][0m - loss: 0.5060534, learning_rate: 9.355932203389831e-06, global_step: 570, interval_runtime: 1.4895, interval_samples_per_second: 5.371, interval_steps_per_second: 6.714, epoch: 3.2203[0m
[32m[2022-09-05 13:29:38,698] [    INFO][0m - loss: 0.41394911, learning_rate: 9.344632768361582e-06, global_step: 580, interval_runtime: 1.4908, interval_samples_per_second: 5.366, interval_steps_per_second: 6.708, epoch: 3.2768[0m
[32m[2022-09-05 13:29:40,190] [    INFO][0m - loss: 0.49632959, learning_rate: 9.333333333333334e-06, global_step: 590, interval_runtime: 1.4912, interval_samples_per_second: 5.365, interval_steps_per_second: 6.706, epoch: 3.3333[0m
[32m[2022-09-05 13:29:41,679] [    INFO][0m - loss: 0.48681421, learning_rate: 9.322033898305085e-06, global_step: 600, interval_runtime: 1.4892, interval_samples_per_second: 5.372, interval_steps_per_second: 6.715, epoch: 3.3898[0m
[32m[2022-09-05 13:29:41,679] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:29:41,679] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:29:41,679] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:29:41,680] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:29:41,680] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:29:52,854] [    INFO][0m - eval_loss: 0.41554030776023865, eval_accuracy: 0.3712871287128713, eval_runtime: 11.1742, eval_samples_per_second: 126.541, eval_steps_per_second: 15.84, epoch: 3.3898[0m
[32m[2022-09-05 13:29:52,855] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-600[0m
[32m[2022-09-05 13:29:52,855] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:29:55,856] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-600/tokenizer_config.json[0m
[32m[2022-09-05 13:29:55,856] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-600/special_tokens_map.json[0m
[32m[2022-09-05 13:30:02,412] [    INFO][0m - loss: 0.41701064, learning_rate: 9.310734463276837e-06, global_step: 610, interval_runtime: 20.7329, interval_samples_per_second: 0.386, interval_steps_per_second: 0.482, epoch: 3.4463[0m
[32m[2022-09-05 13:30:03,904] [    INFO][0m - loss: 0.44922905, learning_rate: 9.299435028248588e-06, global_step: 620, interval_runtime: 1.4922, interval_samples_per_second: 5.361, interval_steps_per_second: 6.701, epoch: 3.5028[0m
[32m[2022-09-05 13:30:05,394] [    INFO][0m - loss: 0.37156558, learning_rate: 9.28813559322034e-06, global_step: 630, interval_runtime: 1.4898, interval_samples_per_second: 5.37, interval_steps_per_second: 6.713, epoch: 3.5593[0m
[32m[2022-09-05 13:30:06,884] [    INFO][0m - loss: 0.4238904, learning_rate: 9.276836158192091e-06, global_step: 640, interval_runtime: 1.4901, interval_samples_per_second: 5.369, interval_steps_per_second: 6.711, epoch: 3.6158[0m
[32m[2022-09-05 13:30:08,374] [    INFO][0m - loss: 0.37222044, learning_rate: 9.265536723163843e-06, global_step: 650, interval_runtime: 1.49, interval_samples_per_second: 5.369, interval_steps_per_second: 6.711, epoch: 3.6723[0m
[32m[2022-09-05 13:30:09,865] [    INFO][0m - loss: 0.40105939, learning_rate: 9.254237288135594e-06, global_step: 660, interval_runtime: 1.4912, interval_samples_per_second: 5.365, interval_steps_per_second: 6.706, epoch: 3.7288[0m
[32m[2022-09-05 13:30:11,358] [    INFO][0m - loss: 0.32354915, learning_rate: 9.242937853107346e-06, global_step: 670, interval_runtime: 1.4927, interval_samples_per_second: 5.359, interval_steps_per_second: 6.699, epoch: 3.7853[0m
[32m[2022-09-05 13:30:12,849] [    INFO][0m - loss: 0.41683121, learning_rate: 9.231638418079097e-06, global_step: 680, interval_runtime: 1.4911, interval_samples_per_second: 5.365, interval_steps_per_second: 6.707, epoch: 3.8418[0m
[32m[2022-09-05 13:30:14,343] [    INFO][0m - loss: 0.42225862, learning_rate: 9.220338983050847e-06, global_step: 690, interval_runtime: 1.4941, interval_samples_per_second: 5.354, interval_steps_per_second: 6.693, epoch: 3.8983[0m
[32m[2022-09-05 13:30:15,837] [    INFO][0m - loss: 0.44933038, learning_rate: 9.2090395480226e-06, global_step: 700, interval_runtime: 1.4942, interval_samples_per_second: 5.354, interval_steps_per_second: 6.692, epoch: 3.9548[0m
[32m[2022-09-05 13:30:15,838] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:30:15,838] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:30:15,838] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:30:15,838] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:30:15,838] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:30:27,125] [    INFO][0m - eval_loss: 0.36499184370040894, eval_accuracy: 0.4752475247524752, eval_runtime: 11.287, eval_samples_per_second: 125.277, eval_steps_per_second: 15.682, epoch: 3.9548[0m
[32m[2022-09-05 13:30:27,126] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-700[0m
[32m[2022-09-05 13:30:27,126] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:30:30,173] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-700/tokenizer_config.json[0m
[32m[2022-09-05 13:30:30,173] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-700/special_tokens_map.json[0m
[32m[2022-09-05 13:30:36,639] [    INFO][0m - loss: 0.49299788, learning_rate: 9.19774011299435e-06, global_step: 710, interval_runtime: 20.8014, interval_samples_per_second: 0.385, interval_steps_per_second: 0.481, epoch: 4.0113[0m
[32m[2022-09-05 13:30:38,142] [    INFO][0m - loss: 0.34469869, learning_rate: 9.186440677966101e-06, global_step: 720, interval_runtime: 1.5033, interval_samples_per_second: 5.322, interval_steps_per_second: 6.652, epoch: 4.0678[0m
[32m[2022-09-05 13:30:39,638] [    INFO][0m - loss: 0.42930598, learning_rate: 9.175141242937853e-06, global_step: 730, interval_runtime: 1.4954, interval_samples_per_second: 5.35, interval_steps_per_second: 6.687, epoch: 4.1243[0m
[32m[2022-09-05 13:30:41,132] [    INFO][0m - loss: 0.38009613, learning_rate: 9.163841807909604e-06, global_step: 740, interval_runtime: 1.4947, interval_samples_per_second: 5.352, interval_steps_per_second: 6.69, epoch: 4.1808[0m
[32m[2022-09-05 13:30:42,626] [    INFO][0m - loss: 0.40587387, learning_rate: 9.152542372881356e-06, global_step: 750, interval_runtime: 1.4944, interval_samples_per_second: 5.353, interval_steps_per_second: 6.692, epoch: 4.2373[0m
[32m[2022-09-05 13:30:44,115] [    INFO][0m - loss: 0.48405161, learning_rate: 9.141242937853107e-06, global_step: 760, interval_runtime: 1.4888, interval_samples_per_second: 5.373, interval_steps_per_second: 6.717, epoch: 4.2938[0m
[32m[2022-09-05 13:30:45,605] [    INFO][0m - loss: 0.39771752, learning_rate: 9.12994350282486e-06, global_step: 770, interval_runtime: 1.4893, interval_samples_per_second: 5.371, interval_steps_per_second: 6.714, epoch: 4.3503[0m
[32m[2022-09-05 13:30:47,098] [    INFO][0m - loss: 0.44782495, learning_rate: 9.11864406779661e-06, global_step: 780, interval_runtime: 1.4931, interval_samples_per_second: 5.358, interval_steps_per_second: 6.697, epoch: 4.4068[0m
[32m[2022-09-05 13:30:48,589] [    INFO][0m - loss: 0.48040175, learning_rate: 9.107344632768362e-06, global_step: 790, interval_runtime: 1.491, interval_samples_per_second: 5.366, interval_steps_per_second: 6.707, epoch: 4.4633[0m
[32m[2022-09-05 13:30:50,081] [    INFO][0m - loss: 0.31970203, learning_rate: 9.096045197740113e-06, global_step: 800, interval_runtime: 1.4921, interval_samples_per_second: 5.362, interval_steps_per_second: 6.702, epoch: 4.5198[0m
[32m[2022-09-05 13:30:50,081] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:30:50,081] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:30:50,082] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:30:50,082] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:30:50,082] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:31:01,348] [    INFO][0m - eval_loss: 0.34958428144454956, eval_accuracy: 0.4801980198019802, eval_runtime: 11.2661, eval_samples_per_second: 125.509, eval_steps_per_second: 15.711, epoch: 4.5198[0m
[32m[2022-09-05 13:31:01,349] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-800[0m
[32m[2022-09-05 13:31:01,349] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:31:06,019] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-800/tokenizer_config.json[0m
[32m[2022-09-05 13:31:06,019] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-800/special_tokens_map.json[0m
[32m[2022-09-05 13:31:15,375] [    INFO][0m - loss: 0.31089053, learning_rate: 9.084745762711865e-06, global_step: 810, interval_runtime: 25.2939, interval_samples_per_second: 0.316, interval_steps_per_second: 0.395, epoch: 4.5763[0m
[32m[2022-09-05 13:31:16,868] [    INFO][0m - loss: 0.32774019, learning_rate: 9.073446327683618e-06, global_step: 820, interval_runtime: 1.4929, interval_samples_per_second: 5.359, interval_steps_per_second: 6.698, epoch: 4.6328[0m
[32m[2022-09-05 13:31:18,361] [    INFO][0m - loss: 0.48455219, learning_rate: 9.062146892655368e-06, global_step: 830, interval_runtime: 1.4936, interval_samples_per_second: 5.356, interval_steps_per_second: 6.695, epoch: 4.6893[0m
[32m[2022-09-05 13:31:19,855] [    INFO][0m - loss: 0.44240365, learning_rate: 9.05084745762712e-06, global_step: 840, interval_runtime: 1.4936, interval_samples_per_second: 5.356, interval_steps_per_second: 6.695, epoch: 4.7458[0m
[32m[2022-09-05 13:31:21,348] [    INFO][0m - loss: 0.31281254, learning_rate: 9.039548022598871e-06, global_step: 850, interval_runtime: 1.4933, interval_samples_per_second: 5.357, interval_steps_per_second: 6.697, epoch: 4.8023[0m
[32m[2022-09-05 13:31:22,840] [    INFO][0m - loss: 0.51777501, learning_rate: 9.028248587570622e-06, global_step: 860, interval_runtime: 1.4914, interval_samples_per_second: 5.364, interval_steps_per_second: 6.705, epoch: 4.8588[0m
[32m[2022-09-05 13:31:24,333] [    INFO][0m - loss: 0.39300957, learning_rate: 9.016949152542374e-06, global_step: 870, interval_runtime: 1.4937, interval_samples_per_second: 5.356, interval_steps_per_second: 6.695, epoch: 4.9153[0m
[32m[2022-09-05 13:31:25,825] [    INFO][0m - loss: 0.37424107, learning_rate: 9.005649717514125e-06, global_step: 880, interval_runtime: 1.492, interval_samples_per_second: 5.362, interval_steps_per_second: 6.702, epoch: 4.9718[0m
[32m[2022-09-05 13:31:27,333] [    INFO][0m - loss: 0.29459138, learning_rate: 8.994350282485876e-06, global_step: 890, interval_runtime: 1.5068, interval_samples_per_second: 5.309, interval_steps_per_second: 6.637, epoch: 5.0282[0m
[32m[2022-09-05 13:31:28,829] [    INFO][0m - loss: 0.42914696, learning_rate: 8.983050847457628e-06, global_step: 900, interval_runtime: 1.4965, interval_samples_per_second: 5.346, interval_steps_per_second: 6.682, epoch: 5.0847[0m
[32m[2022-09-05 13:31:28,829] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:31:28,829] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:31:28,829] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:31:28,830] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:31:28,830] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:31:39,982] [    INFO][0m - eval_loss: 0.48561185598373413, eval_accuracy: 0.4752475247524752, eval_runtime: 11.1519, eval_samples_per_second: 126.794, eval_steps_per_second: 15.872, epoch: 5.0847[0m
[32m[2022-09-05 13:31:39,983] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-900[0m
[32m[2022-09-05 13:31:39,983] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:31:43,323] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-900/tokenizer_config.json[0m
[32m[2022-09-05 13:31:43,323] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-900/special_tokens_map.json[0m
[32m[2022-09-05 13:31:50,688] [    INFO][0m - loss: 0.33229344, learning_rate: 8.971751412429379e-06, global_step: 910, interval_runtime: 21.8589, interval_samples_per_second: 0.366, interval_steps_per_second: 0.457, epoch: 5.1412[0m
[32m[2022-09-05 13:31:52,174] [    INFO][0m - loss: 0.2895632, learning_rate: 8.960451977401131e-06, global_step: 920, interval_runtime: 1.4859, interval_samples_per_second: 5.384, interval_steps_per_second: 6.73, epoch: 5.1977[0m
[32m[2022-09-05 13:31:53,662] [    INFO][0m - loss: 0.39743352, learning_rate: 8.949152542372881e-06, global_step: 930, interval_runtime: 1.4884, interval_samples_per_second: 5.375, interval_steps_per_second: 6.718, epoch: 5.2542[0m
[32m[2022-09-05 13:31:55,149] [    INFO][0m - loss: 0.14817653, learning_rate: 8.937853107344634e-06, global_step: 940, interval_runtime: 1.4871, interval_samples_per_second: 5.379, interval_steps_per_second: 6.724, epoch: 5.3107[0m
[32m[2022-09-05 13:31:56,637] [    INFO][0m - loss: 0.52577581, learning_rate: 8.926553672316384e-06, global_step: 950, interval_runtime: 1.488, interval_samples_per_second: 5.377, interval_steps_per_second: 6.721, epoch: 5.3672[0m
[32m[2022-09-05 13:31:58,129] [    INFO][0m - loss: 0.25798881, learning_rate: 8.915254237288137e-06, global_step: 960, interval_runtime: 1.4916, interval_samples_per_second: 5.363, interval_steps_per_second: 6.704, epoch: 5.4237[0m
[32m[2022-09-05 13:31:59,621] [    INFO][0m - loss: 0.32950356, learning_rate: 8.903954802259887e-06, global_step: 970, interval_runtime: 1.4925, interval_samples_per_second: 5.36, interval_steps_per_second: 6.7, epoch: 5.4802[0m
[32m[2022-09-05 13:32:01,112] [    INFO][0m - loss: 0.38483403, learning_rate: 8.89265536723164e-06, global_step: 980, interval_runtime: 1.4903, interval_samples_per_second: 5.368, interval_steps_per_second: 6.71, epoch: 5.5367[0m
[32m[2022-09-05 13:32:02,603] [    INFO][0m - loss: 0.61870327, learning_rate: 8.88135593220339e-06, global_step: 990, interval_runtime: 1.4912, interval_samples_per_second: 5.365, interval_steps_per_second: 6.706, epoch: 5.5932[0m
[32m[2022-09-05 13:32:04,094] [    INFO][0m - loss: 0.47173877, learning_rate: 8.870056497175143e-06, global_step: 1000, interval_runtime: 1.4915, interval_samples_per_second: 5.364, interval_steps_per_second: 6.705, epoch: 5.6497[0m
[32m[2022-09-05 13:32:04,095] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:32:04,095] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:32:04,095] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:32:04,095] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:32:04,095] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:32:15,385] [    INFO][0m - eval_loss: 0.932917594909668, eval_accuracy: 0.4306930693069307, eval_runtime: 11.2899, eval_samples_per_second: 125.244, eval_steps_per_second: 15.678, epoch: 5.6497[0m
[32m[2022-09-05 13:32:15,386] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-1000[0m
[32m[2022-09-05 13:32:15,386] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:32:18,972] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-1000/tokenizer_config.json[0m
[32m[2022-09-05 13:32:18,973] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-1000/special_tokens_map.json[0m
[32m[2022-09-05 13:32:27,083] [    INFO][0m - loss: 0.28053613, learning_rate: 8.858757062146893e-06, global_step: 1010, interval_runtime: 22.9892, interval_samples_per_second: 0.348, interval_steps_per_second: 0.435, epoch: 5.7062[0m
[32m[2022-09-05 13:32:28,572] [    INFO][0m - loss: 0.30972362, learning_rate: 8.847457627118646e-06, global_step: 1020, interval_runtime: 1.4885, interval_samples_per_second: 5.375, interval_steps_per_second: 6.718, epoch: 5.7627[0m
[32m[2022-09-05 13:32:30,062] [    INFO][0m - loss: 0.41287923, learning_rate: 8.836158192090396e-06, global_step: 1030, interval_runtime: 1.4905, interval_samples_per_second: 5.367, interval_steps_per_second: 6.709, epoch: 5.8192[0m
[32m[2022-09-05 13:32:31,553] [    INFO][0m - loss: 0.2939054, learning_rate: 8.824858757062149e-06, global_step: 1040, interval_runtime: 1.4906, interval_samples_per_second: 5.367, interval_steps_per_second: 6.709, epoch: 5.8757[0m
[32m[2022-09-05 13:32:33,044] [    INFO][0m - loss: 0.37659974, learning_rate: 8.8135593220339e-06, global_step: 1050, interval_runtime: 1.4905, interval_samples_per_second: 5.367, interval_steps_per_second: 6.709, epoch: 5.9322[0m
[32m[2022-09-05 13:32:34,529] [    INFO][0m - loss: 0.36645064, learning_rate: 8.80225988700565e-06, global_step: 1060, interval_runtime: 1.4856, interval_samples_per_second: 5.385, interval_steps_per_second: 6.731, epoch: 5.9887[0m
[32m[2022-09-05 13:32:36,036] [    INFO][0m - loss: 0.35019679, learning_rate: 8.790960451977402e-06, global_step: 1070, interval_runtime: 1.5065, interval_samples_per_second: 5.31, interval_steps_per_second: 6.638, epoch: 6.0452[0m
[32m[2022-09-05 13:32:37,528] [    INFO][0m - loss: 0.23888364, learning_rate: 8.779661016949153e-06, global_step: 1080, interval_runtime: 1.4918, interval_samples_per_second: 5.363, interval_steps_per_second: 6.703, epoch: 6.1017[0m
[32m[2022-09-05 13:32:39,021] [    INFO][0m - loss: 0.34338276, learning_rate: 8.768361581920905e-06, global_step: 1090, interval_runtime: 1.4933, interval_samples_per_second: 5.357, interval_steps_per_second: 6.697, epoch: 6.1582[0m
[32m[2022-09-05 13:32:40,513] [    INFO][0m - loss: 0.41234698, learning_rate: 8.757062146892656e-06, global_step: 1100, interval_runtime: 1.4926, interval_samples_per_second: 5.36, interval_steps_per_second: 6.7, epoch: 6.2147[0m
[32m[2022-09-05 13:32:40,514] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:32:40,514] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:32:40,514] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:32:40,514] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:32:40,514] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:32:51,985] [    INFO][0m - eval_loss: 0.751891553401947, eval_accuracy: 0.5099009900990099, eval_runtime: 11.4703, eval_samples_per_second: 123.275, eval_steps_per_second: 15.431, epoch: 6.2147[0m
[32m[2022-09-05 13:32:51,986] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-1100[0m
[32m[2022-09-05 13:32:51,986] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:32:55,620] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-1100/tokenizer_config.json[0m
[32m[2022-09-05 13:32:55,620] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-1100/special_tokens_map.json[0m
[32m[2022-09-05 13:33:03,093] [    INFO][0m - loss: 0.10987844, learning_rate: 8.745762711864407e-06, global_step: 1110, interval_runtime: 22.5798, interval_samples_per_second: 0.354, interval_steps_per_second: 0.443, epoch: 6.2712[0m
[32m[2022-09-05 13:33:04,580] [    INFO][0m - loss: 0.27969813, learning_rate: 8.734463276836159e-06, global_step: 1120, interval_runtime: 1.4863, interval_samples_per_second: 5.382, interval_steps_per_second: 6.728, epoch: 6.3277[0m
[32m[2022-09-05 13:33:06,068] [    INFO][0m - loss: 0.38273399, learning_rate: 8.72316384180791e-06, global_step: 1130, interval_runtime: 1.4882, interval_samples_per_second: 5.376, interval_steps_per_second: 6.72, epoch: 6.3842[0m
[32m[2022-09-05 13:33:07,556] [    INFO][0m - loss: 0.33205984, learning_rate: 8.711864406779662e-06, global_step: 1140, interval_runtime: 1.4885, interval_samples_per_second: 5.375, interval_steps_per_second: 6.718, epoch: 6.4407[0m
[32m[2022-09-05 13:33:09,044] [    INFO][0m - loss: 0.30471454, learning_rate: 8.700564971751413e-06, global_step: 1150, interval_runtime: 1.4878, interval_samples_per_second: 5.377, interval_steps_per_second: 6.721, epoch: 6.4972[0m
[32m[2022-09-05 13:33:10,535] [    INFO][0m - loss: 0.28908274, learning_rate: 8.689265536723165e-06, global_step: 1160, interval_runtime: 1.491, interval_samples_per_second: 5.366, interval_steps_per_second: 6.707, epoch: 6.5537[0m
[32m[2022-09-05 13:33:12,027] [    INFO][0m - loss: 0.19400342, learning_rate: 8.677966101694915e-06, global_step: 1170, interval_runtime: 1.4922, interval_samples_per_second: 5.361, interval_steps_per_second: 6.701, epoch: 6.6102[0m
[32m[2022-09-05 13:33:13,520] [    INFO][0m - loss: 0.23970759, learning_rate: 8.666666666666668e-06, global_step: 1180, interval_runtime: 1.4925, interval_samples_per_second: 5.36, interval_steps_per_second: 6.7, epoch: 6.6667[0m
[32m[2022-09-05 13:33:15,014] [    INFO][0m - loss: 0.30674829, learning_rate: 8.655367231638418e-06, global_step: 1190, interval_runtime: 1.4938, interval_samples_per_second: 5.355, interval_steps_per_second: 6.694, epoch: 6.7232[0m
[32m[2022-09-05 13:33:16,505] [    INFO][0m - loss: 0.35469244, learning_rate: 8.64406779661017e-06, global_step: 1200, interval_runtime: 1.4913, interval_samples_per_second: 5.364, interval_steps_per_second: 6.705, epoch: 6.7797[0m
[32m[2022-09-05 13:33:16,505] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:33:16,506] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:33:16,506] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:33:16,506] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:33:16,506] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:33:27,663] [    INFO][0m - eval_loss: 0.9614529013633728, eval_accuracy: 0.4900990099009901, eval_runtime: 11.1567, eval_samples_per_second: 126.74, eval_steps_per_second: 15.865, epoch: 6.7797[0m
[32m[2022-09-05 13:33:27,663] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-1200[0m
[32m[2022-09-05 13:33:27,663] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:33:30,906] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-1200/tokenizer_config.json[0m
[32m[2022-09-05 13:33:30,907] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-1200/special_tokens_map.json[0m
[32m[2022-09-05 13:33:38,416] [    INFO][0m - loss: 0.41742764, learning_rate: 8.632768361581921e-06, global_step: 1210, interval_runtime: 21.9109, interval_samples_per_second: 0.365, interval_steps_per_second: 0.456, epoch: 6.8362[0m
[32m[2022-09-05 13:33:39,912] [    INFO][0m - loss: 0.20831895, learning_rate: 8.621468926553674e-06, global_step: 1220, interval_runtime: 1.4958, interval_samples_per_second: 5.348, interval_steps_per_second: 6.685, epoch: 6.8927[0m
[32m[2022-09-05 13:33:41,400] [    INFO][0m - loss: 0.32329383, learning_rate: 8.610169491525424e-06, global_step: 1230, interval_runtime: 1.4888, interval_samples_per_second: 5.373, interval_steps_per_second: 6.717, epoch: 6.9492[0m
[32m[2022-09-05 13:33:42,914] [    INFO][0m - loss: 0.08465309, learning_rate: 8.598870056497177e-06, global_step: 1240, interval_runtime: 1.5138, interval_samples_per_second: 5.285, interval_steps_per_second: 6.606, epoch: 7.0056[0m
[32m[2022-09-05 13:33:44,408] [    INFO][0m - loss: 0.22703514, learning_rate: 8.587570621468927e-06, global_step: 1250, interval_runtime: 1.494, interval_samples_per_second: 5.355, interval_steps_per_second: 6.694, epoch: 7.0621[0m
[32m[2022-09-05 13:33:45,903] [    INFO][0m - loss: 0.11811608, learning_rate: 8.57627118644068e-06, global_step: 1260, interval_runtime: 1.4943, interval_samples_per_second: 5.354, interval_steps_per_second: 6.692, epoch: 7.1186[0m
[32m[2022-09-05 13:33:47,396] [    INFO][0m - loss: 0.47529998, learning_rate: 8.56497175141243e-06, global_step: 1270, interval_runtime: 1.4931, interval_samples_per_second: 5.358, interval_steps_per_second: 6.697, epoch: 7.1751[0m
[32m[2022-09-05 13:33:48,890] [    INFO][0m - loss: 0.21899889, learning_rate: 8.553672316384181e-06, global_step: 1280, interval_runtime: 1.4944, interval_samples_per_second: 5.353, interval_steps_per_second: 6.692, epoch: 7.2316[0m
[32m[2022-09-05 13:33:50,387] [    INFO][0m - loss: 0.25664656, learning_rate: 8.542372881355933e-06, global_step: 1290, interval_runtime: 1.4972, interval_samples_per_second: 5.343, interval_steps_per_second: 6.679, epoch: 7.2881[0m
[32m[2022-09-05 13:33:51,889] [    INFO][0m - loss: 0.27926829, learning_rate: 8.531073446327684e-06, global_step: 1300, interval_runtime: 1.5013, interval_samples_per_second: 5.329, interval_steps_per_second: 6.661, epoch: 7.3446[0m
[32m[2022-09-05 13:33:51,889] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:33:51,889] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:33:51,889] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:33:51,889] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:33:51,890] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:34:03,203] [    INFO][0m - eval_loss: 0.8205718994140625, eval_accuracy: 0.5346534653465347, eval_runtime: 11.313, eval_samples_per_second: 124.989, eval_steps_per_second: 15.646, epoch: 7.3446[0m
[32m[2022-09-05 13:34:03,203] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-1300[0m
[32m[2022-09-05 13:34:03,203] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:34:06,643] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-1300/tokenizer_config.json[0m
[32m[2022-09-05 13:34:06,643] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-1300/special_tokens_map.json[0m
[32m[2022-09-05 13:34:14,012] [    INFO][0m - loss: 0.23092456, learning_rate: 8.519774011299435e-06, global_step: 1310, interval_runtime: 22.1234, interval_samples_per_second: 0.362, interval_steps_per_second: 0.452, epoch: 7.4011[0m
[32m[2022-09-05 13:34:15,500] [    INFO][0m - loss: 0.05013864, learning_rate: 8.508474576271187e-06, global_step: 1320, interval_runtime: 1.4885, interval_samples_per_second: 5.375, interval_steps_per_second: 6.718, epoch: 7.4576[0m
[32m[2022-09-05 13:34:16,990] [    INFO][0m - loss: 0.18241664, learning_rate: 8.497175141242938e-06, global_step: 1330, interval_runtime: 1.4891, interval_samples_per_second: 5.372, interval_steps_per_second: 6.715, epoch: 7.5141[0m
[32m[2022-09-05 13:34:18,479] [    INFO][0m - loss: 0.07467192, learning_rate: 8.48587570621469e-06, global_step: 1340, interval_runtime: 1.4893, interval_samples_per_second: 5.372, interval_steps_per_second: 6.714, epoch: 7.5706[0m
[32m[2022-09-05 13:34:19,970] [    INFO][0m - loss: 0.42357101, learning_rate: 8.47457627118644e-06, global_step: 1350, interval_runtime: 1.4909, interval_samples_per_second: 5.366, interval_steps_per_second: 6.707, epoch: 7.6271[0m
[32m[2022-09-05 13:34:21,464] [    INFO][0m - loss: 0.04641795, learning_rate: 8.463276836158193e-06, global_step: 1360, interval_runtime: 1.4939, interval_samples_per_second: 5.355, interval_steps_per_second: 6.694, epoch: 7.6836[0m
[32m[2022-09-05 13:34:22,956] [    INFO][0m - loss: 0.27864003, learning_rate: 8.451977401129944e-06, global_step: 1370, interval_runtime: 1.4919, interval_samples_per_second: 5.362, interval_steps_per_second: 6.703, epoch: 7.7401[0m
[32m[2022-09-05 13:34:24,460] [    INFO][0m - loss: 0.48929396, learning_rate: 8.440677966101696e-06, global_step: 1380, interval_runtime: 1.5042, interval_samples_per_second: 5.318, interval_steps_per_second: 6.648, epoch: 7.7966[0m
[32m[2022-09-05 13:34:25,951] [    INFO][0m - loss: 0.23445358, learning_rate: 8.429378531073447e-06, global_step: 1390, interval_runtime: 1.4908, interval_samples_per_second: 5.366, interval_steps_per_second: 6.708, epoch: 7.8531[0m
[32m[2022-09-05 13:34:27,446] [    INFO][0m - loss: 0.32432258, learning_rate: 8.418079096045199e-06, global_step: 1400, interval_runtime: 1.4953, interval_samples_per_second: 5.35, interval_steps_per_second: 6.688, epoch: 7.9096[0m
[32m[2022-09-05 13:34:27,446] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:34:27,447] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:34:27,447] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:34:27,447] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:34:27,447] [    INFO][0m -   Total prediction steps = 177[0m
[1 0 5 5 2 1 2 2 2 6 6 6 6 0 2 4 0 2 6 4 3 2 6 2 5 6 4 5 6 4 5 3 5 3 3 4 4
 1 4 6 0 0 2 3 0 2 2 3 4 5 5 6 2 2 3 3 1 6 3 2 0 5 5 6 2 6 6 5 3 6 2 6 0 3
 5 6 0 1 4 6 1 6 3 5 6 6 6 6 1 5 2 5 5 2 4 4 4 0 4 3 3 0 5 2 2 5 0 4 2 2 4
 2 4 4 4 3 4 0 2 4 5 5 0 5 2 3 0 5 4 2 5 4 6 4 3 1 0 5 5 2 4 6 5 5 5 2 4 0
 3 3 1 0 0 2 0 5 0 0 1 0 0 4 3 2 2 1 5 0 1 0 1 4 6 4 3 3 5 1 6 5 1 1 0 4 4
 1 5 1 1 1 1 1 1 3 0 1 6 6 1 6 1 3]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[1 0 5 0 2 1 2 2 2 6 2 6 6 1 2 4 1 2 3 4 3 2 2 2 3 0 5 2 6 4 2 3 5 3 3 5 1
 1 4 4 6 0 2 3 3 2 0 3 4 5 5 4 2 1 3 3 3 6 3 3 0 6 3 6 2 6 6 5 1 2 2 6 0 5
 5 6 4 6 4 1 6 6 5 6 6 6 6 0 6 5 1 5 5 2 4 4 4 1 4 3 4 0 5 2 2 2 0 4 6 5 4
 0 4 3 4 0 4 4 5 4 5 5 5 5 2 5 0 4 5 0 5 4 6 4 3 1 4 2 1 2 4 0 5 4 5 6 4 0
 3 3 3 0 0 2 0 5 6 0 0 4 4 4 0 0 2 1 5 4 1 0 1 4 6 4 0 3 1 1 6 6 6 5 0 1 3
 2 1 5 1 1 3 1 1 2 0 1 6 6 1 1 1 4]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[6 0 6 2 2 1 2 2 2 0 2 6 6 2 2 4 0 2 3 4 2 2 2 2 3 0 2 2 6 4 3 3 5 3 3 5 3
 1 4 4 3 0 2 3 0 3 3 3 4 5 5 4 2 1 3 3 1 6 3 3 6 6 6 0 2 6 6 5 6 2 6 6 6 3
 5 6 4 6 4 6 6 6 1 0 6 6 6 6 1 0 1 5 5 4 4 4 6 1 4 3 4 0 4 2 4 2 0 4 2 2 4
 1 4 3 4 0 4 4 0 2 2 5 5 5 5 5 1 5 5 2 5 4 6 4 5 1 0 5 1 2 4 0 5 5 5 4 4 0
 3 2 3 0 0 0 0 5 6 0 0 0 4 4 0 0 2 1 5 4 1 0 1 1 6 4 0 3 5 1 6 5 1 0 1 6 3
 1 1 1 1 1 1 1 1 0 0 1 6 6 1 6 1 1]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[6 0 6 2 2 1 2 2 2 0 2 2 6 0 2 4 0 2 3 4 2 2 2 2 3 0 4 2 6 4 3 3 2 3 3 5 1
 1 4 4 0 0 0 3 3 3 3 3 4 5 5 5 5 3 0 3 0 6 3 2 4 6 6 0 6 5 6 5 6 2 6 6 6 5
 5 6 4 6 4 6 6 6 0 6 6 6 6 4 4 0 4 5 5 4 4 4 6 0 4 4 4 0 4 2 5 2 0 4 2 2 4
 1 4 3 4 0 4 4 0 2 5 5 5 5 5 3 1 5 5 0 5 4 6 4 5 1 0 5 2 1 4 0 5 3 5 6 4 0
 0 2 3 0 0 0 0 5 0 0 0 0 4 6 0 0 2 1 5 4 0 0 1 1 6 4 0 3 5 1 6 5 1 0 3 1 3
 2 1 4 1 1 3 1 1 0 1 1 6 1 1 6 1 4]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[5 0 6 2 2 1 2 2 2 3 2 5 6 5 2 4 0 2 3 4 2 2 2 2 6 1 2 2 6 4 3 3 2 6 3 5 4
 1 4 3 3 0 0 3 3 3 3 3 4 1 5 0 5 1 0 3 0 6 3 2 6 6 3 0 6 6 6 5 1 2 6 6 6 5
 5 6 4 6 0 6 6 6 0 6 6 6 6 6 4 5 4 5 5 4 4 4 6 3 4 4 2 4 4 2 4 2 0 4 3 2 4
 2 4 3 4 4 4 4 0 2 2 5 5 5 5 5 1 2 5 0 5 4 6 4 5 1 2 5 1 5 4 6 5 3 2 6 4 0
 6 2 3 0 0 0 0 5 0 0 0 0 4 4 0 0 3 1 5 1 0 0 1 1 6 4 0 3 0 1 6 5 1 5 3 1 3
 2 1 1 1 1 3 1 1 0 1 1 6 1 1 6 0 4]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[6 0 6 0 2 5 2 2 5 3 2 6 6 3 0 2 0 2 3 4 2 6 0 2 6 2 4 2 6 4 3 3 2 3 3 5 3
 1 4 3 3 0 0 3 3 3 3 3 4 5 5 4 3 3 0 3 0 6 3 2 6 6 3 0 2 5 6 3 6 2 6 6 6 5
 5 6 3 6 4 5 6 6 0 6 2 6 6 4 2 0 4 5 5 4 4 4 6 3 4 4 2 3 4 2 4 2 0 0 3 2 4
 1 4 3 4 0 4 4 0 2 1 5 5 5 1 3 1 5 5 0 5 4 6 4 5 0 4 5 2 2 6 6 5 3 5 6 4 0
 3 2 3 0 0 0 0 5 0 0 0 5 0 0 0 0 2 3 5 0 1 0 1 1 6 4 0 3 3 1 6 5 6 0 3 6 3
 2 1 4 1 1 3 1 2 0 1 6 6 1 1 1 1 4]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[5 4 6 2 4 1 2 2 5 0 2 6 0 3 2 2 0 2 4 4 2 6 2 2 6 1 4 2 6 4 3 3 2 3 3 5 3
 1 4 4 3 0 5 3 3 3 3 0 3 1 5 0 3 3 3 3 0 6 3 2 6 6 6 0 2 6 3 6 6 2 6 6 6 3
 5 6 3 6 1 6 6 6 0 6 6 6 6 6 1 5 4 5 5 4 4 4 4 0 4 4 2 4 4 2 4 2 4 4 3 2 4
 1 4 3 4 0 4 5 0 2 5 0 5 5 5 3 1 5 5 0 5 4 6 5 5 0 5 5 5 2 4 6 5 3 5 4 4 0
 3 2 3 0 0 0 0 5 0 2 0 0 0 4 0 0 3 1 5 4 0 0 1 1 3 4 0 3 0 1 6 5 1 0 3 4 1
 2 1 4 1 1 3 1 1 5 1 1 6 1 1 1 1 4]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[5 4 0 2 4 1 2 2 2 0 2 2 2 3 0 2 0 2 4 4 2 6 2 2 6 1 3 2 6 4 3 3 2 3 3 5 3
 1 4 4 3 0 5 3 3 3 3 0 3 1 4 0 3 3 3 3 0 6 3 2 6 6 6 0 2 6 3 2 1 2 6 6 6 5
 5 6 3 6 1 6 6 6 0 6 2 6 6 4 5 5 4 5 5 4 4 4 4 0 4 4 2 0 4 2 4 2 0 4 3 6 4
 1 4 3 4 5 4 5 0 2 3 0 5 5 5 3 1 5 5 0 5 4 1 5 5 0 2 5 1 2 4 6 5 3 2 0 4 0
 6 2 0 0 0 0 0 5 0 0 1 0 4 0 0 0 3 1 5 4 0 0 1 1 6 4 0 3 0 1 6 5 1 4 1 1 1
 2 1 4 1 1 3 1 1 5 1 1 6 1 1 1 0 4]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[5 0 0 2 4 1 3 2 2 3 2 2 2 0 0 2 0 2 2 4 2 6 2 2 6 1 2 2 2 4 3 3 2 3 3 5 3
 1 4 6 3 0 5 3 3 3 3 0 3 1 4 0 3 3 3 3 0 6 3 2 6 6 6 0 2 6 6 2 1 6 6 6 6 3
 5 6 3 6 1 6 6 6 0 6 6 6 6 4 0 5 4 5 5 4 4 4 6 3 4 4 2 0 4 4 4 4 4 4 3 2 4
 1 4 3 4 4 4 5 0 2 2 0 0 5 5 5 1 5 5 5 5 4 1 4 5 0 4 5 2 2 6 6 5 3 5 0 4 0
 6 2 3 0 0 0 0 5 0 0 1 0 0 0 0 0 0 1 5 4 0 0 1 1 4 6 1 3 0 1 6 5 1 4 4 1 1
 2 1 4 0 1 3 1 2 5 1 1 6 1 1 1 0 1]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[5 0 0 2 4 1 1 2 2 3 2 2 2 0 0 2 0 2 3 4 2 6 0 2 6 1 3 2 6 4 3 3 2 3 3 5 3
 1 4 6 3 0 5 3 3 3 2 0 5 1 4 0 5 3 3 3 0 6 3 2 6 6 6 0 2 6 6 2 1 2 6 4 6 3
 5 6 0 5 1 6 6 6 0 6 6 6 6 4 5 5 4 5 5 4 4 4 6 0 1 4 4 4 4 4 4 2 0 4 3 2 4
 1 4 3 4 6 4 5 0 2 2 0 0 5 5 3 0 5 5 1 5 4 1 4 5 0 5 5 1 2 4 6 5 3 2 5 4 0
 3 2 0 0 0 0 0 5 0 0 1 0 0 0 0 0 0 1 5 4 0 0 1 1 6 4 0 3 0 1 0 5 1 0 4 1 3
 2 1 4 0 1 3 1 2 5 1 1 6 1 1 1 1 1]
[32m[2022-09-05 13:34:38,678] [    INFO][0m - eval_loss: 1.204084873199463, eval_accuracy: 0.47029702970297027, eval_runtime: 11.2302, eval_samples_per_second: 125.911, eval_steps_per_second: 15.761, epoch: 7.9096[0m
[32m[2022-09-05 13:34:38,678] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-1400[0m
[32m[2022-09-05 13:34:38,678] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:34:42,411] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-1400/tokenizer_config.json[0m
[32m[2022-09-05 13:34:42,411] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-1400/special_tokens_map.json[0m
[32m[2022-09-05 13:34:50,447] [    INFO][0m - loss: 0.15291325, learning_rate: 8.40677966101695e-06, global_step: 1410, interval_runtime: 23.0007, interval_samples_per_second: 0.348, interval_steps_per_second: 0.435, epoch: 7.9661[0m
[32m[2022-09-05 13:34:51,960] [    INFO][0m - loss: 0.50132003, learning_rate: 8.395480225988702e-06, global_step: 1420, interval_runtime: 1.5132, interval_samples_per_second: 5.287, interval_steps_per_second: 6.609, epoch: 8.0226[0m
[32m[2022-09-05 13:34:53,453] [    INFO][0m - loss: 0.34857948, learning_rate: 8.384180790960452e-06, global_step: 1430, interval_runtime: 1.4926, interval_samples_per_second: 5.36, interval_steps_per_second: 6.7, epoch: 8.0791[0m
[32m[2022-09-05 13:34:54,945] [    INFO][0m - loss: 0.1024189, learning_rate: 8.372881355932205e-06, global_step: 1440, interval_runtime: 1.4922, interval_samples_per_second: 5.361, interval_steps_per_second: 6.702, epoch: 8.1356[0m
[32m[2022-09-05 13:34:56,438] [    INFO][0m - loss: 0.22688715, learning_rate: 8.361581920903955e-06, global_step: 1450, interval_runtime: 1.4934, interval_samples_per_second: 5.357, interval_steps_per_second: 6.696, epoch: 8.1921[0m
[32m[2022-09-05 13:34:57,933] [    INFO][0m - loss: 0.14071823, learning_rate: 8.350282485875708e-06, global_step: 1460, interval_runtime: 1.4947, interval_samples_per_second: 5.352, interval_steps_per_second: 6.69, epoch: 8.2486[0m
[32m[2022-09-05 13:34:59,426] [    INFO][0m - loss: 0.09612367, learning_rate: 8.338983050847458e-06, global_step: 1470, interval_runtime: 1.4934, interval_samples_per_second: 5.357, interval_steps_per_second: 6.696, epoch: 8.3051[0m
[32m[2022-09-05 13:35:00,919] [    INFO][0m - loss: 0.09486706, learning_rate: 8.327683615819209e-06, global_step: 1480, interval_runtime: 1.4931, interval_samples_per_second: 5.358, interval_steps_per_second: 6.698, epoch: 8.3616[0m
[32m[2022-09-05 13:35:02,415] [    INFO][0m - loss: 0.11920836, learning_rate: 8.316384180790961e-06, global_step: 1490, interval_runtime: 1.4958, interval_samples_per_second: 5.348, interval_steps_per_second: 6.686, epoch: 8.4181[0m
[32m[2022-09-05 13:35:03,907] [    INFO][0m - loss: 0.15450013, learning_rate: 8.305084745762712e-06, global_step: 1500, interval_runtime: 1.4924, interval_samples_per_second: 5.361, interval_steps_per_second: 6.701, epoch: 8.4746[0m
[32m[2022-09-05 13:35:03,908] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:35:03,908] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:35:03,908] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:35:03,908] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:35:03,908] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:35:15,307] [    INFO][0m - eval_loss: 1.130920648574829, eval_accuracy: 0.5099009900990099, eval_runtime: 11.3988, eval_samples_per_second: 124.048, eval_steps_per_second: 15.528, epoch: 8.4746[0m
[32m[2022-09-05 13:35:15,308] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-1500[0m
[32m[2022-09-05 13:35:15,308] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:35:18,617] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-1500/tokenizer_config.json[0m
[32m[2022-09-05 13:35:18,618] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-1500/special_tokens_map.json[0m
[32m[2022-09-05 13:35:25,210] [    INFO][0m - loss: 0.20882833, learning_rate: 8.293785310734463e-06, global_step: 1510, interval_runtime: 21.3026, interval_samples_per_second: 0.376, interval_steps_per_second: 0.469, epoch: 8.5311[0m
[32m[2022-09-05 13:35:26,702] [    INFO][0m - loss: 0.10328804, learning_rate: 8.282485875706215e-06, global_step: 1520, interval_runtime: 1.4917, interval_samples_per_second: 5.363, interval_steps_per_second: 6.704, epoch: 8.5876[0m
[32m[2022-09-05 13:35:28,192] [    INFO][0m - loss: 0.0729893, learning_rate: 8.271186440677966e-06, global_step: 1530, interval_runtime: 1.4904, interval_samples_per_second: 5.368, interval_steps_per_second: 6.71, epoch: 8.6441[0m
[32m[2022-09-05 13:35:29,684] [    INFO][0m - loss: 0.08945034, learning_rate: 8.259887005649718e-06, global_step: 1540, interval_runtime: 1.4921, interval_samples_per_second: 5.361, interval_steps_per_second: 6.702, epoch: 8.7006[0m
[32m[2022-09-05 13:35:31,177] [    INFO][0m - loss: 0.12064984, learning_rate: 8.248587570621469e-06, global_step: 1550, interval_runtime: 1.4924, interval_samples_per_second: 5.361, interval_steps_per_second: 6.701, epoch: 8.7571[0m
[32m[2022-09-05 13:35:32,671] [    INFO][0m - loss: 0.01373216, learning_rate: 8.237288135593221e-06, global_step: 1560, interval_runtime: 1.494, interval_samples_per_second: 5.355, interval_steps_per_second: 6.694, epoch: 8.8136[0m
[32m[2022-09-05 13:35:34,163] [    INFO][0m - loss: 0.38095074, learning_rate: 8.225988700564972e-06, global_step: 1570, interval_runtime: 1.4919, interval_samples_per_second: 5.362, interval_steps_per_second: 6.703, epoch: 8.8701[0m
[32m[2022-09-05 13:35:35,654] [    INFO][0m - loss: 0.20783689, learning_rate: 8.214689265536724e-06, global_step: 1580, interval_runtime: 1.4914, interval_samples_per_second: 5.364, interval_steps_per_second: 6.705, epoch: 8.9266[0m
[32m[2022-09-05 13:35:37,144] [    INFO][0m - loss: 0.33778758, learning_rate: 8.203389830508475e-06, global_step: 1590, interval_runtime: 1.4904, interval_samples_per_second: 5.368, interval_steps_per_second: 6.71, epoch: 8.9831[0m
[32m[2022-09-05 13:35:38,652] [    INFO][0m - loss: 0.10764964, learning_rate: 8.192090395480227e-06, global_step: 1600, interval_runtime: 1.5081, interval_samples_per_second: 5.305, interval_steps_per_second: 6.631, epoch: 9.0395[0m
[32m[2022-09-05 13:35:38,653] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:35:38,653] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:35:38,653] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:35:38,653] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:35:38,653] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:35:49,868] [    INFO][0m - eval_loss: 1.113036036491394, eval_accuracy: 0.5, eval_runtime: 11.2145, eval_samples_per_second: 126.087, eval_steps_per_second: 15.783, epoch: 9.0395[0m
[32m[2022-09-05 13:35:49,869] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-1600[0m
[32m[2022-09-05 13:35:49,869] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:35:52,801] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-1600/tokenizer_config.json[0m
[32m[2022-09-05 13:35:52,801] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-1600/special_tokens_map.json[0m
[32m[2022-09-05 13:36:01,303] [    INFO][0m - loss: 0.14894893, learning_rate: 8.18079096045198e-06, global_step: 1610, interval_runtime: 22.6508, interval_samples_per_second: 0.353, interval_steps_per_second: 0.441, epoch: 9.096[0m
[32m[2022-09-05 13:36:02,796] [    INFO][0m - loss: 0.00169131, learning_rate: 8.16949152542373e-06, global_step: 1620, interval_runtime: 1.4928, interval_samples_per_second: 5.359, interval_steps_per_second: 6.699, epoch: 9.1525[0m
[32m[2022-09-05 13:36:04,294] [    INFO][0m - loss: 0.00281185, learning_rate: 8.158192090395482e-06, global_step: 1630, interval_runtime: 1.4974, interval_samples_per_second: 5.343, interval_steps_per_second: 6.678, epoch: 9.209[0m
[32m[2022-09-05 13:36:05,788] [    INFO][0m - loss: 0.00069855, learning_rate: 8.146892655367233e-06, global_step: 1640, interval_runtime: 1.4949, interval_samples_per_second: 5.351, interval_steps_per_second: 6.689, epoch: 9.2655[0m
[32m[2022-09-05 13:36:07,288] [    INFO][0m - loss: 0.24967718, learning_rate: 8.135593220338983e-06, global_step: 1650, interval_runtime: 1.4997, interval_samples_per_second: 5.334, interval_steps_per_second: 6.668, epoch: 9.322[0m
[32m[2022-09-05 13:36:08,784] [    INFO][0m - loss: 0.09473139, learning_rate: 8.124293785310736e-06, global_step: 1660, interval_runtime: 1.496, interval_samples_per_second: 5.348, interval_steps_per_second: 6.684, epoch: 9.3785[0m
[32m[2022-09-05 13:36:10,280] [    INFO][0m - loss: 0.0455822, learning_rate: 8.112994350282486e-06, global_step: 1670, interval_runtime: 1.4964, interval_samples_per_second: 5.346, interval_steps_per_second: 6.683, epoch: 9.435[0m
[32m[2022-09-05 13:36:11,776] [    INFO][0m - loss: 0.22429984, learning_rate: 8.101694915254237e-06, global_step: 1680, interval_runtime: 1.4952, interval_samples_per_second: 5.35, interval_steps_per_second: 6.688, epoch: 9.4915[0m
[32m[2022-09-05 13:36:13,272] [    INFO][0m - loss: 0.02949565, learning_rate: 8.09039548022599e-06, global_step: 1690, interval_runtime: 1.4959, interval_samples_per_second: 5.348, interval_steps_per_second: 6.685, epoch: 9.548[0m
[32m[2022-09-05 13:36:14,770] [    INFO][0m - loss: 0.26774681, learning_rate: 8.07909604519774e-06, global_step: 1700, interval_runtime: 1.4978, interval_samples_per_second: 5.341, interval_steps_per_second: 6.676, epoch: 9.6045[0m
[32m[2022-09-05 13:36:14,770] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:36:14,770] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:36:14,770] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:36:14,770] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:36:14,771] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:36:25,988] [    INFO][0m - eval_loss: 1.310479998588562, eval_accuracy: 0.504950495049505, eval_runtime: 11.2175, eval_samples_per_second: 126.053, eval_steps_per_second: 15.779, epoch: 9.6045[0m
[32m[2022-09-05 13:36:25,989] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-1700[0m
[32m[2022-09-05 13:36:25,989] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:36:29,380] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-1700/tokenizer_config.json[0m
[32m[2022-09-05 13:36:29,714] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-1700/special_tokens_map.json[0m
[32m[2022-09-05 13:36:35,597] [    INFO][0m - 
Training completed. 
[0m
[32m[2022-09-05 13:36:35,597] [    INFO][0m - Loading best model from ./checkpoints_chid/checkpoint-1300 (score: 0.5346534653465347).[0m
[32m[2022-09-05 13:36:36,514] [    INFO][0m - train_runtime: 602.7717, train_samples_per_second: 117.292, train_steps_per_second: 14.682, train_loss: 0.3970552276773378, epoch: 9.6045[0m
[32m[2022-09-05 13:36:36,516] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/[0m
[32m[2022-09-05 13:36:36,516] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:36:39,917] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/tokenizer_config.json[0m
[32m[2022-09-05 13:36:39,918] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/special_tokens_map.json[0m
[32m[2022-09-05 13:36:39,919] [    INFO][0m - ***** train metrics *****[0m
[32m[2022-09-05 13:36:39,919] [    INFO][0m -   epoch                    =     9.6045[0m
[32m[2022-09-05 13:36:39,919] [    INFO][0m -   train_loss               =     0.3971[0m
[32m[2022-09-05 13:36:39,920] [    INFO][0m -   train_runtime            = 0:10:02.77[0m
[32m[2022-09-05 13:36:39,920] [    INFO][0m -   train_samples_per_second =    117.292[0m
[32m[2022-09-05 13:36:39,920] [    INFO][0m -   train_steps_per_second   =     14.682[0m
[32m[2022-09-05 13:36:39,931] [    INFO][0m - ***** Running Prediction *****[0m
[32m[2022-09-05 13:36:39,931] [    INFO][0m -   Num examples = 14014[0m
[32m[2022-09-05 13:36:39,931] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:36:39,931] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:36:39,931] [    INFO][0m -   Total prediction steps = 1752[0m
[32m[2022-09-05 13:38:33,505] [    INFO][0m - ***** test metrics *****[0m
[32m[2022-09-05 13:38:33,506] [    INFO][0m -   test_accuracy           =     0.5185[0m
[32m[2022-09-05 13:38:33,506] [    INFO][0m -   test_loss               =     0.8424[0m
[32m[2022-09-05 13:38:33,506] [    INFO][0m -   test_runtime            = 0:01:53.57[0m
[32m[2022-09-05 13:38:33,506] [    INFO][0m -   test_samples_per_second =     123.39[0m
[32m[2022-09-05 13:38:33,506] [    INFO][0m -   test_steps_per_second   =     15.426[0m
[33m[2022-09-05 13:38:52,134] [ WARNING][0m - evaluation_strategy reset to IntervalStrategy.STEPS for do_eval is True. you can also set evaluation_strategy='epoch'.[0m
[32m[2022-09-05 13:38:52,134] [    INFO][0m - The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).[0m
[32m[2022-09-05 13:38:52,134] [    INFO][0m - ============================================================[0m
[32m[2022-09-05 13:38:52,134] [    INFO][0m -      Model Configuration Arguments      [0m
[32m[2022-09-05 13:38:52,134] [    INFO][0m - paddle commit id              :65f388690048d0965ec7d3b43fb6ee9d8c6dee7c[0m
[32m[2022-09-05 13:38:52,134] [    INFO][0m - do_save                       :True[0m
[32m[2022-09-05 13:38:52,134] [    INFO][0m - do_test                       :True[0m
[32m[2022-09-05 13:38:52,134] [    INFO][0m - early_stop_patience           :4[0m
[32m[2022-09-05 13:38:52,134] [    INFO][0m - export_type                   :paddle[0m
[32m[2022-09-05 13:38:52,135] [    INFO][0m - model_name_or_path            :ernie-3.0-base-zh[0m
[32m[2022-09-05 13:38:52,135] [    INFO][0m - [0m
[32m[2022-09-05 13:38:52,135] [    INFO][0m - ============================================================[0m
[32m[2022-09-05 13:38:52,135] [    INFO][0m -       Data Configuration Arguments      [0m
[32m[2022-09-05 13:38:52,135] [    INFO][0m - paddle commit id              :65f388690048d0965ec7d3b43fb6ee9d8c6dee7c[0m
[32m[2022-09-05 13:38:52,135] [    INFO][0m - encoder_hidden_size           :200[0m
[32m[2022-09-05 13:38:52,135] [    INFO][0m - prompt                        :[0m
[32m[2022-09-05 13:38:52,135] [    INFO][0m - soft_encoder                  :lstm[0m
[32m[2022-09-05 13:38:52,135] [    INFO][0m - split_id                      :few_all[0m
[32m[2022-09-05 13:38:52,136] [    INFO][0m - task_name                     :chid[0m
[32m[2022-09-05 13:38:52,136] [    INFO][0m - [0m
[32m[2022-09-05 13:38:52,136] [    INFO][0m - Already cached /ssd2/wanghuijuan03/.paddlenlp/models/ernie-3.0-base-zh/ernie_3.0_base_zh.pdparams[0m
[32m[2022-09-05 13:38:53,398] [    INFO][0m - Already cached /ssd2/wanghuijuan03/.paddlenlp/models/ernie-3.0-base-zh/ernie_3.0_base_zh_vocab.txt[0m
[32m[2022-09-05 13:38:53,419] [    INFO][0m - tokenizer config file saved in /ssd2/wanghuijuan03/.paddlenlp/models/ernie-3.0-base-zh/tokenizer_config.json[0m
[32m[2022-09-05 13:38:53,420] [    INFO][0m - Special tokens file saved in /ssd2/wanghuijuan03/.paddlenlp/models/ernie-3.0-base-zh/special_tokens_map.json[0m
[32m[2022-09-05 13:38:53,421] [    INFO][0m - Using template: [{'add_prefix_space': '', 'text': 'text_a'}, {'add_prefix_space': '', 'hard': 'ËøôÂè•ËØù‰∏≠Á©∫Ê†ºÂ§ÑÂ°´'}, {'add_prefix_space': '', 'text': 'text_b'}, {'add_prefix_space': '', 'mask': None}, {'add_prefix_space': '', 'hard': 'ÂêàÈÄÇ„ÄÇ'}][0m
2022-09-05 13:38:53,422 INFO [download.py:119] unique_endpoints {''}
[32m[2022-09-05 13:38:53,513] [    INFO][0m - ============================================================[0m
[32m[2022-09-05 13:38:53,513] [    INFO][0m -     Training Configuration Arguments    [0m
[32m[2022-09-05 13:38:53,515] [    INFO][0m - paddle commit id              :65f388690048d0965ec7d3b43fb6ee9d8c6dee7c[0m
[32m[2022-09-05 13:38:53,515] [    INFO][0m - _no_sync_in_gradient_accumulation:True[0m
[32m[2022-09-05 13:38:53,515] [    INFO][0m - adam_beta1                    :0.9[0m
[32m[2022-09-05 13:38:53,515] [    INFO][0m - adam_beta2                    :0.999[0m
[32m[2022-09-05 13:38:53,515] [    INFO][0m - adam_epsilon                  :1e-08[0m
[32m[2022-09-05 13:38:53,515] [    INFO][0m - alpha_rdrop                   :5.0[0m
[32m[2022-09-05 13:38:53,516] [    INFO][0m - alpha_rgl                     :0.5[0m
[32m[2022-09-05 13:38:53,516] [    INFO][0m - current_device                :gpu:0[0m
[32m[2022-09-05 13:38:53,516] [    INFO][0m - dataloader_drop_last          :False[0m
[32m[2022-09-05 13:38:53,516] [    INFO][0m - dataloader_num_workers        :0[0m
[32m[2022-09-05 13:38:53,516] [    INFO][0m - device                        :gpu[0m
[32m[2022-09-05 13:38:53,516] [    INFO][0m - disable_tqdm                  :True[0m
[32m[2022-09-05 13:38:53,516] [    INFO][0m - do_eval                       :True[0m
[32m[2022-09-05 13:38:53,516] [    INFO][0m - do_export                     :False[0m
[32m[2022-09-05 13:38:53,516] [    INFO][0m - do_predict                    :False[0m
[32m[2022-09-05 13:38:53,516] [    INFO][0m - do_train                      :True[0m
[32m[2022-09-05 13:38:53,516] [    INFO][0m - eval_batch_size               :8[0m
[32m[2022-09-05 13:38:53,516] [    INFO][0m - eval_steps                    :100[0m
[32m[2022-09-05 13:38:53,516] [    INFO][0m - evaluation_strategy           :IntervalStrategy.STEPS[0m
[32m[2022-09-05 13:38:53,517] [    INFO][0m - first_max_length              :None[0m
[32m[2022-09-05 13:38:53,517] [    INFO][0m - fp16                          :False[0m
[32m[2022-09-05 13:38:53,517] [    INFO][0m - fp16_opt_level                :O1[0m
[32m[2022-09-05 13:38:53,517] [    INFO][0m - freeze_dropout                :False[0m
[32m[2022-09-05 13:38:53,517] [    INFO][0m - freeze_plm                    :False[0m
[32m[2022-09-05 13:38:53,517] [    INFO][0m - gradient_accumulation_steps   :1[0m
[32m[2022-09-05 13:38:53,517] [    INFO][0m - greater_is_better             :True[0m
[32m[2022-09-05 13:38:53,517] [    INFO][0m - ignore_data_skip              :False[0m
[32m[2022-09-05 13:38:53,517] [    INFO][0m - label_names                   :None[0m
[32m[2022-09-05 13:38:53,517] [    INFO][0m - learning_rate                 :1e-05[0m
[32m[2022-09-05 13:38:53,517] [    INFO][0m - load_best_model_at_end        :True[0m
[32m[2022-09-05 13:38:53,517] [    INFO][0m - local_process_index           :0[0m
[32m[2022-09-05 13:38:53,517] [    INFO][0m - local_rank                    :-1[0m
[32m[2022-09-05 13:38:53,518] [    INFO][0m - log_level                     :-1[0m
[32m[2022-09-05 13:38:53,518] [    INFO][0m - log_level_replica             :-1[0m
[32m[2022-09-05 13:38:53,518] [    INFO][0m - log_on_each_node              :True[0m
[32m[2022-09-05 13:38:53,518] [    INFO][0m - logging_dir                   :./checkpoints_chid/runs/Sep05_13-38-52_instance-3bwob41y-01[0m
[32m[2022-09-05 13:38:53,518] [    INFO][0m - logging_first_step            :False[0m
[32m[2022-09-05 13:38:53,518] [    INFO][0m - logging_steps                 :10[0m
[32m[2022-09-05 13:38:53,518] [    INFO][0m - logging_strategy              :IntervalStrategy.STEPS[0m
[32m[2022-09-05 13:38:53,518] [    INFO][0m - lr_scheduler_type             :SchedulerType.LINEAR[0m
[32m[2022-09-05 13:38:53,518] [    INFO][0m - max_grad_norm                 :1.0[0m
[32m[2022-09-05 13:38:53,518] [    INFO][0m - max_seq_length                :256[0m
[32m[2022-09-05 13:38:53,518] [    INFO][0m - max_steps                     :-1[0m
[32m[2022-09-05 13:38:53,518] [    INFO][0m - metric_for_best_model         :accuracy[0m
[32m[2022-09-05 13:38:53,518] [    INFO][0m - minimum_eval_times            :None[0m
[32m[2022-09-05 13:38:53,519] [    INFO][0m - no_cuda                       :False[0m
[32m[2022-09-05 13:38:53,519] [    INFO][0m - num_train_epochs              :50.0[0m
[32m[2022-09-05 13:38:53,519] [    INFO][0m - optim                         :OptimizerNames.ADAMW[0m
[32m[2022-09-05 13:38:53,519] [    INFO][0m - other_max_length              :None[0m
[32m[2022-09-05 13:38:53,519] [    INFO][0m - output_dir                    :./checkpoints_chid/[0m
[32m[2022-09-05 13:38:53,519] [    INFO][0m - overwrite_output_dir          :False[0m
[32m[2022-09-05 13:38:53,519] [    INFO][0m - past_index                    :-1[0m
[32m[2022-09-05 13:38:53,519] [    INFO][0m - per_device_eval_batch_size    :8[0m
[32m[2022-09-05 13:38:53,519] [    INFO][0m - per_device_train_batch_size   :8[0m
[32m[2022-09-05 13:38:53,519] [    INFO][0m - ppt_adam_beta1                :0.9[0m
[32m[2022-09-05 13:38:53,519] [    INFO][0m - ppt_adam_beta2                :0.999[0m
[32m[2022-09-05 13:38:53,519] [    INFO][0m - ppt_adam_epsilon              :1e-08[0m
[32m[2022-09-05 13:38:53,520] [    INFO][0m - ppt_learning_rate             :1e-05[0m
[32m[2022-09-05 13:38:53,520] [    INFO][0m - ppt_weight_decay              :0.0[0m
[32m[2022-09-05 13:38:53,520] [    INFO][0m - prediction_loss_only          :False[0m
[32m[2022-09-05 13:38:53,520] [    INFO][0m - process_index                 :0[0m
[32m[2022-09-05 13:38:53,520] [    INFO][0m - remove_unused_columns         :True[0m
[32m[2022-09-05 13:38:53,520] [    INFO][0m - report_to                     :['visualdl'][0m
[32m[2022-09-05 13:38:53,520] [    INFO][0m - resume_from_checkpoint        :None[0m
[32m[2022-09-05 13:38:53,520] [    INFO][0m - run_name                      :./checkpoints_chid/[0m
[32m[2022-09-05 13:38:53,520] [    INFO][0m - save_on_each_node             :False[0m
[32m[2022-09-05 13:38:53,520] [    INFO][0m - save_steps                    :100[0m
[32m[2022-09-05 13:38:53,520] [    INFO][0m - save_strategy                 :IntervalStrategy.STEPS[0m
[32m[2022-09-05 13:38:53,520] [    INFO][0m - save_total_limit              :None[0m
[32m[2022-09-05 13:38:53,520] [    INFO][0m - scale_loss                    :32768[0m
[32m[2022-09-05 13:38:53,520] [    INFO][0m - seed                          :42[0m
[32m[2022-09-05 13:38:53,521] [    INFO][0m - should_log                    :True[0m
[32m[2022-09-05 13:38:53,521] [    INFO][0m - should_save                   :True[0m
[32m[2022-09-05 13:38:53,521] [    INFO][0m - task_type                     :multi-class[0m
[32m[2022-09-05 13:38:53,521] [    INFO][0m - train_batch_size              :8[0m
[32m[2022-09-05 13:38:53,521] [    INFO][0m - truncate_mode                 :tail[0m
[32m[2022-09-05 13:38:53,521] [    INFO][0m - use_rdrop                     :False[0m
[32m[2022-09-05 13:38:53,521] [    INFO][0m - use_rgl                       :False[0m
[32m[2022-09-05 13:38:53,521] [    INFO][0m - warmup_ratio                  :0.0[0m
[32m[2022-09-05 13:38:53,521] [    INFO][0m - warmup_steps                  :0[0m
[32m[2022-09-05 13:38:53,521] [    INFO][0m - weight_decay                  :0.0[0m
[32m[2022-09-05 13:38:53,521] [    INFO][0m - world_size                    :1[0m
[32m[2022-09-05 13:38:53,521] [    INFO][0m - [0m
[32m[2022-09-05 13:38:53,523] [    INFO][0m - ***** Running training *****[0m
[32m[2022-09-05 13:38:53,523] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:38:53,523] [    INFO][0m -   Num Epochs = 50[0m
[32m[2022-09-05 13:38:53,523] [    INFO][0m -   Instantaneous batch size per device = 8[0m
[32m[2022-09-05 13:38:53,523] [    INFO][0m -   Total train batch size (w. parallel, distributed & accumulation) = 8[0m
[32m[2022-09-05 13:38:53,523] [    INFO][0m -   Gradient Accumulation steps = 1[0m
[32m[2022-09-05 13:38:53,523] [    INFO][0m -   Total optimization steps = 8850.0[0m
[32m[2022-09-05 13:38:53,523] [    INFO][0m -   Total num train samples = 70700[0m
[32m[2022-09-05 13:38:55,120] [    INFO][0m - loss: 2.33096962, learning_rate: 9.988700564971753e-06, global_step: 10, interval_runtime: 1.5954, interval_samples_per_second: 5.014, interval_steps_per_second: 6.268, epoch: 0.0565[0m
[32m[2022-09-05 13:38:56,606] [    INFO][0m - loss: 0.64067507, learning_rate: 9.977401129943504e-06, global_step: 20, interval_runtime: 1.4867, interval_samples_per_second: 5.381, interval_steps_per_second: 6.726, epoch: 0.113[0m
[32m[2022-09-05 13:38:58,093] [    INFO][0m - loss: 0.62240496, learning_rate: 9.966101694915256e-06, global_step: 30, interval_runtime: 1.487, interval_samples_per_second: 5.38, interval_steps_per_second: 6.725, epoch: 0.1695[0m
[32m[2022-09-05 13:38:59,580] [    INFO][0m - loss: 0.69252019, learning_rate: 9.954802259887007e-06, global_step: 40, interval_runtime: 1.4873, interval_samples_per_second: 5.379, interval_steps_per_second: 6.724, epoch: 0.226[0m
[32m[2022-09-05 13:39:01,071] [    INFO][0m - loss: 0.45925403, learning_rate: 9.943502824858759e-06, global_step: 50, interval_runtime: 1.4908, interval_samples_per_second: 5.366, interval_steps_per_second: 6.708, epoch: 0.2825[0m
[32m[2022-09-05 13:39:02,561] [    INFO][0m - loss: 0.32268996, learning_rate: 9.93220338983051e-06, global_step: 60, interval_runtime: 1.4892, interval_samples_per_second: 5.372, interval_steps_per_second: 6.715, epoch: 0.339[0m
[32m[2022-09-05 13:39:04,047] [    INFO][0m - loss: 1.10799294, learning_rate: 9.92090395480226e-06, global_step: 70, interval_runtime: 1.4869, interval_samples_per_second: 5.38, interval_steps_per_second: 6.725, epoch: 0.3955[0m
[32m[2022-09-05 13:39:05,536] [    INFO][0m - loss: 0.74853339, learning_rate: 9.909604519774013e-06, global_step: 80, interval_runtime: 1.4882, interval_samples_per_second: 5.376, interval_steps_per_second: 6.72, epoch: 0.452[0m
[32m[2022-09-05 13:39:07,027] [    INFO][0m - loss: 0.53707137, learning_rate: 9.898305084745763e-06, global_step: 90, interval_runtime: 1.4912, interval_samples_per_second: 5.365, interval_steps_per_second: 6.706, epoch: 0.5085[0m
[32m[2022-09-05 13:39:08,513] [    INFO][0m - loss: 0.44485245, learning_rate: 9.887005649717516e-06, global_step: 100, interval_runtime: 1.4862, interval_samples_per_second: 5.383, interval_steps_per_second: 6.729, epoch: 0.565[0m
[32m[2022-09-05 13:39:08,513] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:39:08,514] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:39:08,514] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:39:08,514] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:39:08,514] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:39:19,773] [    INFO][0m - eval_loss: 0.42447802424430847, eval_accuracy: 0.09405940594059406, eval_runtime: 11.259, eval_samples_per_second: 125.588, eval_steps_per_second: 15.721, epoch: 0.565[0m
[32m[2022-09-05 13:39:19,774] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-100[0m
[32m[2022-09-05 13:39:19,774] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:39:22,758] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-100/tokenizer_config.json[0m
[32m[2022-09-05 13:39:22,758] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-100/special_tokens_map.json[0m
[32m[2022-09-05 13:39:29,345] [    INFO][0m - loss: 0.55027308, learning_rate: 9.875706214689266e-06, global_step: 110, interval_runtime: 20.8316, interval_samples_per_second: 0.384, interval_steps_per_second: 0.48, epoch: 0.6215[0m
[32m[2022-09-05 13:39:30,832] [    INFO][0m - loss: 0.40845122, learning_rate: 9.864406779661017e-06, global_step: 120, interval_runtime: 1.4874, interval_samples_per_second: 5.379, interval_steps_per_second: 6.723, epoch: 0.678[0m
[32m[2022-09-05 13:39:32,318] [    INFO][0m - loss: 0.52758751, learning_rate: 9.85310734463277e-06, global_step: 130, interval_runtime: 1.486, interval_samples_per_second: 5.383, interval_steps_per_second: 6.729, epoch: 0.7345[0m
[32m[2022-09-05 13:39:33,806] [    INFO][0m - loss: 0.45452185, learning_rate: 9.84180790960452e-06, global_step: 140, interval_runtime: 1.4882, interval_samples_per_second: 5.376, interval_steps_per_second: 6.72, epoch: 0.791[0m
[32m[2022-09-05 13:39:35,296] [    INFO][0m - loss: 0.58680205, learning_rate: 9.830508474576272e-06, global_step: 150, interval_runtime: 1.49, interval_samples_per_second: 5.369, interval_steps_per_second: 6.712, epoch: 0.8475[0m
[32m[2022-09-05 13:39:36,798] [    INFO][0m - loss: 0.51350107, learning_rate: 9.819209039548023e-06, global_step: 160, interval_runtime: 1.5018, interval_samples_per_second: 5.327, interval_steps_per_second: 6.659, epoch: 0.904[0m
[32m[2022-09-05 13:39:38,291] [    INFO][0m - loss: 0.41615558, learning_rate: 9.807909604519775e-06, global_step: 170, interval_runtime: 1.493, interval_samples_per_second: 5.358, interval_steps_per_second: 6.698, epoch: 0.9605[0m
[32m[2022-09-05 13:39:39,808] [    INFO][0m - loss: 0.39457581, learning_rate: 9.796610169491526e-06, global_step: 180, interval_runtime: 1.5168, interval_samples_per_second: 5.274, interval_steps_per_second: 6.593, epoch: 1.0169[0m
[32m[2022-09-05 13:39:41,308] [    INFO][0m - loss: 0.48933806, learning_rate: 9.785310734463278e-06, global_step: 190, interval_runtime: 1.5003, interval_samples_per_second: 5.332, interval_steps_per_second: 6.665, epoch: 1.0734[0m
[32m[2022-09-05 13:39:42,801] [    INFO][0m - loss: 0.45306573, learning_rate: 9.774011299435029e-06, global_step: 200, interval_runtime: 1.4921, interval_samples_per_second: 5.362, interval_steps_per_second: 6.702, epoch: 1.1299[0m
[32m[2022-09-05 13:39:42,801] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:39:42,801] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:39:42,802] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:39:42,802] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:39:42,802] [    INFO][0m -   Total prediction steps = 177[0m
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[5 0 0 2 4 1 1 2 2 0 2 2 2 0 0 2 0 2 2 4 2 6 2 2 0 1 3 2 2 4 2 3 2 3 3 1 3
 1 4 4 3 0 5 3 3 3 2 3 5 1 3 5 3 3 3 3 0 6 4 2 6 6 6 0 2 6 6 2 1 2 6 4 6 3
 5 6 0 6 1 6 2 6 1 6 6 6 6 4 2 5 4 5 5 4 4 4 6 0 1 4 2 4 4 4 4 5 4 4 2 2 4
 1 4 3 4 6 4 5 0 2 2 0 0 5 5 3 0 5 5 1 5 4 1 5 5 5 5 5 2 2 4 6 5 3 5 4 4 0
 0 2 3 0 0 0 0 1 0 0 1 5 3 0 0 0 0 1 5 4 0 0 1 1 4 4 1 3 0 1 6 5 1 0 1 1 1
 2 1 4 0 1 3 1 1 5 1 1 6 1 1 1 0 1]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[5 0 0 2 4 2 1 2 5 3 2 2 2 3 0 2 0 2 4 4 2 6 2 2 6 1 3 2 2 4 3 3 2 3 3 5 3
 1 4 6 3 0 0 3 3 3 2 0 5 1 3 4 3 3 3 3 0 6 4 2 6 6 6 0 2 6 6 2 1 2 6 4 6 3
 5 6 0 5 1 6 2 6 0 6 6 6 6 4 0 5 4 5 5 4 4 4 6 1 1 4 2 3 4 4 4 2 4 4 3 6 4
 1 4 3 4 6 4 5 0 2 5 0 0 5 5 3 0 5 5 1 5 4 1 4 5 0 5 5 1 2 4 6 5 3 5 1 4 0
 0 2 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 5 4 0 0 1 4 6 4 1 3 0 1 0 5 1 0 1 1 0
 2 1 4 0 1 3 1 1 5 1 1 6 1 1 1 0 1]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[5 0 0 2 2 2 1 2 2 3 2 2 2 0 0 2 0 2 4 4 2 2 2 2 6 1 4 2 6 4 3 3 2 6 3 5 3
 1 4 6 3 0 0 3 3 3 2 3 5 1 3 4 3 3 3 3 0 6 3 2 6 6 6 0 2 6 6 2 6 2 6 4 6 5
 5 6 0 5 1 6 2 6 0 6 6 6 6 4 0 5 4 5 5 4 4 4 6 1 1 4 2 3 4 4 4 5 0 4 3 6 6
 1 4 3 4 6 4 5 0 2 5 5 0 5 5 3 0 5 5 1 5 4 3 5 5 5 0 5 2 2 4 6 5 3 5 4 4 0
 5 2 3 0 0 0 0 1 0 0 1 0 3 0 0 0 0 1 5 4 0 0 1 4 6 4 1 3 0 1 6 5 1 0 1 1 0
 2 1 4 0 1 3 1 1 5 1 1 6 1 1 1 1 1]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[3 1 1 ... 1 1 0]
[1 1 1 ... 1 1 1]
0
= 0 ===================
[('Èîô', 11058), ('ÂØπ', 954)]
----------
[('ÂØπ', 11058), ('Èîô', 941), ('ÊòØ', 6), ('Êúâ', 5), ('‰∫∫', 1), ('ÁöÑ', 1)]
----------
[('ËØØ', 7875), ('Âêë', 1124), ('Âèç', 1060), ('ÊòØ', 834), ('Â•Ω', 385), ('Á°Æ', 142), ('ÁöÑ', 72), ('Ëøá', 71), ('Âæó', 65), ('Áúü', 59), ('Êúâ', 59), ('‰∏Ä', 38), ('Áõ¥', 35), ('Êó†', 33), ('Â§ß', 31), ('Ê≠£', 24), ('Âêå', 13), ('Â§ö', 11), ('‰∫∫', 9), ('Èîô', 9), ('Âπ≥', 7), ('ÂÖ®', 6), ('ÂèØ', 6), ('Êñ∞', 6), ('Èöè', 5), ('Áõ∏', 5), ('-', 3), ('Âπ∂', 3), ('Âéü', 2), ('Â∑Æ', 2), ('Ê≤°', 2), ('Êé•', 2), ('Âøò', 1), ('Èù¢', 1), ('ÂÖ∂', 1), ('Âèå', 1), ('Èáç', 1), ('ÊØî', 1), ('ËÉΩ', 1), ('‰∏â', 1), ('Êàê', 1), ('‰∏≠', 1), ('ÁÇπ', 1), ('‰ª•', 1), ('Â¶Ç', 1), ('Ëøû', 1)]
----------
[('Âêë', 4295), ('Âèç', 3454), ('ËØØ', 1213), ('Â•Ω', 684), ('Á°Æ', 621), ('ÊòØ', 387), ('ÁöÑ', 291), ('Ê≠£', 260), ('Êúâ', 213), ('Ëøá', 153), ('Âæó', 101), ('Áõ¥', 77), ('Áúü', 57), ('Â∑Æ', 29), ('‰∏Ä', 21), ('Êó†', 21), ('Â§ß', 20), ('‰∫∫', 13), ('-', 13), ('Áõ∏', 11), ('ÂÖ®', 8), ('Âêå', 7), ('Âπ∂', 6), ('Âπ≥', 5), ('Â¶Ç', 5), ('Êñ∞', 5), ('Â§ö', 3), ('Âêà', 3), ('ÁÑ∂', 3), ('Ê≤°', 3), ('Èîô', 3), ('ÂèØ', 2), ('Èáç', 2), ('ÁÇπ', 2), ('Èöæ', 2), ('ÈÄö', 2), ('ÂÆû', 1), ('Ë°å', 1), ('Êé•', 1), ('ÂÆå', 1), ('ÊâÄ', 1), ('Èöè', 1), ('Âèë', 1), ('ÂàÜ', 1), ('Âê¨', 1), ('‰ª•', 1), ('‰∏ç', 1), ('‰∏é', 1), ('Âú®', 1), ('Âèå', 1), ('‚Äî', 1), ('Áúã', 1), ('ÂÆö', 1)]
----------
[('Âèç', 3874), ('Âêë', 2430), ('Á°Æ', 1697), ('Â•Ω', 1112), ('Ê≠£', 701), ('ËØØ', 441), ('ÁöÑ', 380), ('ÊòØ', 228), ('Ëøá', 217), ('Êúâ', 186), ('Âæó', 186), ('Áõ¥', 145), ('Áúü', 65), ('Â∑Æ', 64), ('‰∏Ä', 35), ('Êó†', 28), ('-', 25), ('Â§ß', 23), ('ÂÖ®', 17), ('Âπ∂', 17), ('Áõ∏', 15), ('Â§ö', 11), ('Âêå', 10), ('‰∫∫', 9), ('ÁÇπ', 9), ('Ê≤°', 8), ('‰∏ç', 7), ('Â¶Ç', 6), ('Èöè', 5), ('Êé•', 5), ('ÁÑ∂', 4), ('Âøò', 3), ('ÂèØ', 3), ('Ëøû', 3), ('Êñ∞', 3), ('Âπ≥', 3), ('Â§±', 3), ('ÂÆö', 3), ('Âú®', 2), ('‰∏â', 2), ('Âê¨', 2), ('‰∏é', 2), ('Âèå', 2), ('‚Äî', 2), ('‰ª•', 2), ('Êâã', 1), ('Áî®', 1), ('ÂÆû', 1), ('Âπ¥', 1), ('„ÄÅ', 1), ('Ë°å', 1), ('Ëá™', 1), ('ÂÖ∂', 1), ('Áîü', 1), ('Èáç', 1), ('ÂÜ≥', 1), ('Ê≠ª', 1), ('‰πã', 1), ('Âçï', 1), ('ÂàÜ', 1), ('Ëµ∑', 1), ('Áü•', 1)]
----------
1
= 0 ===================
[('Èîô', 1121), ('ÂØπ', 881)]
----------
[('ÂØπ', 1121), ('Èîô', 834), ('ÊòØ', 20), ('Êúâ', 19), ('ÁöÑ', 8)]
----------
[('ÊòØ', 547), ('ËØØ', 511), ('Âèç', 233), ('ÁöÑ', 123), ('Âêë', 122), ('Â•Ω', 119), ('Êúâ', 99), ('Á°Æ', 44), ('Âæó', 32), ('Áúü', 23), ('Èîô', 21), ('Ëøá', 16), ('‰∏Ä', 15), ('Ê≠£', 14), ('‰∫∫', 13), ('Áõ¥', 9), ('Êó†', 8), ('Â§ß', 8), ('ÂÖ®', 6), ('Áõ∏', 5), ('Â§ö', 4), ('Â∑Æ', 4), ('Âêå', 4), ('ÁÑ∂', 2), ('Âπ∂', 2), ('Êñ∞', 2), ('ÂèØ', 2), ('ÂÆû', 1), ('‰∏â', 1), ('‰∏é', 1), ('ÁÇπ', 1), ('Èáç', 1), ('Èöè', 1), ('Â¶Ç', 1), ('‰ª•', 1), ('Âêà', 1), ('Áªì', 1), ('-', 1), ('Êé•', 1), ('Ê≤°', 1), ('Âπ≥', 1)]
----------
[('Âèç', 358), ('Âêë', 267), ('ÊòØ', 250), ('Â•Ω', 242), ('ÁöÑ', 220), ('Êúâ', 183), ('ËØØ', 135), ('Á°Æ', 110), ('Âæó', 52), ('‰∏Ä', 20), ('‰∫∫', 19), ('Ëøá', 16), ('Ê≠£', 15), ('Áõ¥', 14), ('Èîô', 14), ('Áõ∏', 12), ('Áúü', 10), ('Êó†', 6), ('ÂÖ®', 6), ('-', 5), ('Â§ß', 5), ('‰∏é', 5), ('Êñ∞', 4), ('Â∑Æ', 4), ('Âêå', 3), ('Êé•', 3), ('Â§ö', 3), ('Ëøû', 2), ('ÁÇπ', 2), ('‰∏≠', 2), ('‰ª•', 2), ('Áî®', 1), ('ÂÆö', 1), ('ÂèØ', 1), ('Âêé', 1), ('Âêç', 1), ('Âπ∂', 1), ('‰πã', 1), ('ÂÆå', 1), ('‰∏ç', 1), ('Âçï', 1), ('Âú®', 1), ('Âêà', 1), ('ÁÑ∂', 1)]
----------
[('Âèç', 290), ('ÁöÑ', 275), ('Â•Ω', 258), ('Âêë', 226), ('Á°Æ', 202), ('Êúâ', 193), ('ÊòØ', 127), ('Âæó', 88), ('ËØØ', 70), ('Ê≠£', 42), ('Ëøá', 37), ('Áúü', 27), ('Áõ¥', 27), ('‰∏Ä', 18), ('‰∫∫', 15), ('Êó†', 12), ('Â§ß', 9), ('Èîô', 9), ('-', 8), ('Â∑Æ', 6), ('ÂÖ®', 6), ('Âêå', 5), ('Ê≤°', 5), ('Áõ∏', 4), ('‰∏é', 4), ('ÂèØ', 4), ('Áî®', 3), ('Â§ö', 3), ('Âèå', 3), ('Ë°å', 2), ('ÊØî', 2), ('Âú®', 2), ('ÁÑ∂', 2), ('‰∏â', 2), ('Êàê', 1), ('Â§©', 1), ('Âú∞', 1), ('ËÉΩ', 1), ('‰∏ç', 1), ('Â§±', 1), ('ÂøÉ', 1), ('Âêç', 1), ('Êé•', 1), ('Áü•', 1), ('Êñ∞', 1), ('‰∫Ü', 1), ('Âπ∂', 1), ('Âä†', 1), ('Âêà', 1), ('ÂÆû', 1)]
----------
====================
[6 2 1 2 4 3 6 0 0 6 1 3 6 5 4 4 4 6 5 4 0 3 1 1 5 2 5 4 1 1 6 5 5 4 2 5 2
 0 1 0 1 4 0 5 5 5 3 6 2 4 0 2 0 5 3 2 2 4 0 5 3 6 3 0 5 2 2 3 2 6 0 4 1 1
 2 4 0 2 5 6 5 5 1 5 5 3 2 1 2 6 0 6 5 2 6 4 5 0 0 0 0 6 0 2 5 6 5 3 3 0 3
 0 6 3 6 0 5 6 4 6 2 2 3 6 0 1 1 1 6 3 6 0 3 6 3 0 1 2 3 1 6 2 3 5 1 0 4 5
 0 1 5 0 3 6 3 6 1 6 1 1 5 3 6 4 1 4 3 0 5 3 6 4 1 1 5 0 4 4 2 1 4 2 1 3 4
 3 5 2 1 3 6 2 6 5 3 2 0 4 4 2 1 4]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[32m[2022-09-05 13:39:54,132] [    INFO][0m - eval_loss: 0.4122244417667389, eval_accuracy: 0.19306930693069307, eval_runtime: 11.3303, eval_samples_per_second: 124.798, eval_steps_per_second: 15.622, epoch: 1.1299[0m
[32m[2022-09-05 13:39:54,133] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-200[0m
[32m[2022-09-05 13:39:54,133] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:39:59,271] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-200/tokenizer_config.json[0m
[32m[2022-09-05 13:39:59,271] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-200/special_tokens_map.json[0m
[32m[2022-09-05 13:40:07,708] [    INFO][0m - loss: 0.37744262, learning_rate: 9.762711864406781e-06, global_step: 210, interval_runtime: 24.9075, interval_samples_per_second: 0.321, interval_steps_per_second: 0.401, epoch: 1.1864[0m
[32m[2022-09-05 13:40:09,195] [    INFO][0m - loss: 0.55593233, learning_rate: 9.751412429378532e-06, global_step: 220, interval_runtime: 1.4875, interval_samples_per_second: 5.378, interval_steps_per_second: 6.723, epoch: 1.2429[0m
[32m[2022-09-05 13:40:10,683] [    INFO][0m - loss: 0.44579964, learning_rate: 9.740112994350284e-06, global_step: 230, interval_runtime: 1.4875, interval_samples_per_second: 5.378, interval_steps_per_second: 6.723, epoch: 1.2994[0m
[32m[2022-09-05 13:40:12,172] [    INFO][0m - loss: 0.50225596, learning_rate: 9.728813559322035e-06, global_step: 240, interval_runtime: 1.4885, interval_samples_per_second: 5.375, interval_steps_per_second: 6.718, epoch: 1.3559[0m
[32m[2022-09-05 13:40:13,662] [    INFO][0m - loss: 0.29613466, learning_rate: 9.717514124293787e-06, global_step: 250, interval_runtime: 1.4904, interval_samples_per_second: 5.368, interval_steps_per_second: 6.71, epoch: 1.4124[0m
[32m[2022-09-05 13:40:15,152] [    INFO][0m - loss: 0.6613337, learning_rate: 9.706214689265538e-06, global_step: 260, interval_runtime: 1.4905, interval_samples_per_second: 5.367, interval_steps_per_second: 6.709, epoch: 1.4689[0m
[32m[2022-09-05 13:40:16,641] [    INFO][0m - loss: 0.43345265, learning_rate: 9.69491525423729e-06, global_step: 270, interval_runtime: 1.4885, interval_samples_per_second: 5.375, interval_steps_per_second: 6.718, epoch: 1.5254[0m
[32m[2022-09-05 13:40:18,131] [    INFO][0m - loss: 0.52493458, learning_rate: 9.68361581920904e-06, global_step: 280, interval_runtime: 1.4903, interval_samples_per_second: 5.368, interval_steps_per_second: 6.71, epoch: 1.5819[0m
[32m[2022-09-05 13:40:19,619] [    INFO][0m - loss: 0.31805177, learning_rate: 9.672316384180791e-06, global_step: 290, interval_runtime: 1.4874, interval_samples_per_second: 5.378, interval_steps_per_second: 6.723, epoch: 1.6384[0m
[32m[2022-09-05 13:40:21,108] [    INFO][0m - loss: 0.62102332, learning_rate: 9.661016949152544e-06, global_step: 300, interval_runtime: 1.489, interval_samples_per_second: 5.373, interval_steps_per_second: 6.716, epoch: 1.6949[0m
[32m[2022-09-05 13:40:21,108] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:40:21,108] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:40:21,108] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:40:21,109] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:40:21,109] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:40:32,248] [    INFO][0m - eval_loss: 0.4425628185272217, eval_accuracy: 0.19306930693069307, eval_runtime: 11.1387, eval_samples_per_second: 126.945, eval_steps_per_second: 15.891, epoch: 1.6949[0m
[32m[2022-09-05 13:40:32,248] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-300[0m
[32m[2022-09-05 13:40:32,249] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:40:35,274] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-300/tokenizer_config.json[0m
[32m[2022-09-05 13:40:35,274] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-300/special_tokens_map.json[0m
[32m[2022-09-05 13:40:42,083] [    INFO][0m - loss: 0.37971342, learning_rate: 9.649717514124294e-06, global_step: 310, interval_runtime: 20.9749, interval_samples_per_second: 0.381, interval_steps_per_second: 0.477, epoch: 1.7514[0m
[32m[2022-09-05 13:40:43,571] [    INFO][0m - loss: 0.40404978, learning_rate: 9.638418079096045e-06, global_step: 320, interval_runtime: 1.4886, interval_samples_per_second: 5.374, interval_steps_per_second: 6.718, epoch: 1.8079[0m
[32m[2022-09-05 13:40:45,060] [    INFO][0m - loss: 0.60826025, learning_rate: 9.627118644067797e-06, global_step: 330, interval_runtime: 1.4888, interval_samples_per_second: 5.373, interval_steps_per_second: 6.717, epoch: 1.8644[0m
[32m[2022-09-05 13:40:46,551] [    INFO][0m - loss: 0.31527615, learning_rate: 9.615819209039548e-06, global_step: 340, interval_runtime: 1.4906, interval_samples_per_second: 5.367, interval_steps_per_second: 6.708, epoch: 1.9209[0m
[32m[2022-09-05 13:40:48,044] [    INFO][0m - loss: 0.34012685, learning_rate: 9.6045197740113e-06, global_step: 350, interval_runtime: 1.4934, interval_samples_per_second: 5.357, interval_steps_per_second: 6.696, epoch: 1.9774[0m
[32m[2022-09-05 13:40:49,547] [    INFO][0m - loss: 0.43283167, learning_rate: 9.593220338983051e-06, global_step: 360, interval_runtime: 1.5034, interval_samples_per_second: 5.321, interval_steps_per_second: 6.652, epoch: 2.0339[0m
[32m[2022-09-05 13:40:51,035] [    INFO][0m - loss: 0.38864145, learning_rate: 9.581920903954803e-06, global_step: 370, interval_runtime: 1.4875, interval_samples_per_second: 5.378, interval_steps_per_second: 6.723, epoch: 2.0904[0m
[32m[2022-09-05 13:40:52,529] [    INFO][0m - loss: 0.59604597, learning_rate: 9.570621468926554e-06, global_step: 380, interval_runtime: 1.4941, interval_samples_per_second: 5.354, interval_steps_per_second: 6.693, epoch: 2.1469[0m
[32m[2022-09-05 13:40:54,021] [    INFO][0m - loss: 0.57697797, learning_rate: 9.559322033898306e-06, global_step: 390, interval_runtime: 1.4918, interval_samples_per_second: 5.363, interval_steps_per_second: 6.703, epoch: 2.2034[0m
[32m[2022-09-05 13:40:55,518] [    INFO][0m - loss: 0.45583615, learning_rate: 9.548022598870057e-06, global_step: 400, interval_runtime: 1.4966, interval_samples_per_second: 5.345, interval_steps_per_second: 6.682, epoch: 2.2599[0m
[32m[2022-09-05 13:40:55,518] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:40:55,518] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:40:55,518] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:40:55,518] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:40:55,519] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:41:06,729] [    INFO][0m - eval_loss: 0.422233521938324, eval_accuracy: 0.2376237623762376, eval_runtime: 11.2102, eval_samples_per_second: 126.135, eval_steps_per_second: 15.789, epoch: 2.2599[0m
[32m[2022-09-05 13:41:06,730] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-400[0m
[32m[2022-09-05 13:41:06,730] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:41:10,139] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-400/tokenizer_config.json[0m
[32m[2022-09-05 13:41:10,139] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-400/special_tokens_map.json[0m
[32m[2022-09-05 13:41:16,858] [    INFO][0m - loss: 0.53950729, learning_rate: 9.53672316384181e-06, global_step: 410, interval_runtime: 21.3403, interval_samples_per_second: 0.375, interval_steps_per_second: 0.469, epoch: 2.3164[0m
[32m[2022-09-05 13:41:18,361] [    INFO][0m - loss: 0.34909098, learning_rate: 9.52542372881356e-06, global_step: 420, interval_runtime: 1.503, interval_samples_per_second: 5.323, interval_steps_per_second: 6.654, epoch: 2.3729[0m
[32m[2022-09-05 13:41:19,852] [    INFO][0m - loss: 0.42645545, learning_rate: 9.514124293785312e-06, global_step: 430, interval_runtime: 1.4903, interval_samples_per_second: 5.368, interval_steps_per_second: 6.71, epoch: 2.4294[0m
[32m[2022-09-05 13:41:21,342] [    INFO][0m - loss: 0.50357308, learning_rate: 9.502824858757063e-06, global_step: 440, interval_runtime: 1.4907, interval_samples_per_second: 5.367, interval_steps_per_second: 6.708, epoch: 2.4859[0m
[32m[2022-09-05 13:41:22,832] [    INFO][0m - loss: 0.43298769, learning_rate: 9.491525423728815e-06, global_step: 450, interval_runtime: 1.4901, interval_samples_per_second: 5.369, interval_steps_per_second: 6.711, epoch: 2.5424[0m
[32m[2022-09-05 13:41:24,321] [    INFO][0m - loss: 0.57880678, learning_rate: 9.480225988700566e-06, global_step: 460, interval_runtime: 1.4892, interval_samples_per_second: 5.372, interval_steps_per_second: 6.715, epoch: 2.5989[0m
[32m[2022-09-05 13:41:25,810] [    INFO][0m - loss: 0.55474901, learning_rate: 9.468926553672318e-06, global_step: 470, interval_runtime: 1.4878, interval_samples_per_second: 5.377, interval_steps_per_second: 6.721, epoch: 2.6554[0m
[32m[2022-09-05 13:41:27,299] [    INFO][0m - loss: 0.43735404, learning_rate: 9.457627118644069e-06, global_step: 480, interval_runtime: 1.4897, interval_samples_per_second: 5.37, interval_steps_per_second: 6.713, epoch: 2.7119[0m
[32m[2022-09-05 13:41:28,790] [    INFO][0m - loss: 0.42582259, learning_rate: 9.44632768361582e-06, global_step: 490, interval_runtime: 1.4908, interval_samples_per_second: 5.366, interval_steps_per_second: 6.708, epoch: 2.7684[0m
[32m[2022-09-05 13:41:30,280] [    INFO][0m - loss: 0.350037, learning_rate: 9.435028248587572e-06, global_step: 500, interval_runtime: 1.4903, interval_samples_per_second: 5.368, interval_steps_per_second: 6.71, epoch: 2.8249[0m
[32m[2022-09-05 13:41:30,281] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:41:30,281] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:41:30,281] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:41:30,281] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:41:30,281] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:41:41,480] [    INFO][0m - eval_loss: 0.41534537076950073, eval_accuracy: 0.25742574257425743, eval_runtime: 11.198, eval_samples_per_second: 126.273, eval_steps_per_second: 15.806, epoch: 2.8249[0m
[32m[2022-09-05 13:41:41,480] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-500[0m
[32m[2022-09-05 13:41:41,480] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:41:44,471] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-500/tokenizer_config.json[0m
[32m[2022-09-05 13:41:44,472] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-500/special_tokens_map.json[0m
[32m[2022-09-05 13:41:51,446] [    INFO][0m - loss: 0.38743725, learning_rate: 9.423728813559322e-06, global_step: 510, interval_runtime: 21.1657, interval_samples_per_second: 0.378, interval_steps_per_second: 0.472, epoch: 2.8814[0m
[32m[2022-09-05 13:41:52,935] [    INFO][0m - loss: 0.35935566, learning_rate: 9.412429378531073e-06, global_step: 520, interval_runtime: 1.4896, interval_samples_per_second: 5.371, interval_steps_per_second: 6.713, epoch: 2.9379[0m
[32m[2022-09-05 13:41:54,417] [    INFO][0m - loss: 0.32537265, learning_rate: 9.401129943502825e-06, global_step: 530, interval_runtime: 1.4823, interval_samples_per_second: 5.397, interval_steps_per_second: 6.746, epoch: 2.9944[0m
[32m[2022-09-05 13:41:55,927] [    INFO][0m - loss: 0.31010392, learning_rate: 9.389830508474576e-06, global_step: 540, interval_runtime: 1.5098, interval_samples_per_second: 5.299, interval_steps_per_second: 6.623, epoch: 3.0508[0m
[32m[2022-09-05 13:41:57,419] [    INFO][0m - loss: 0.45294523, learning_rate: 9.378531073446328e-06, global_step: 550, interval_runtime: 1.4918, interval_samples_per_second: 5.363, interval_steps_per_second: 6.703, epoch: 3.1073[0m
[32m[2022-09-05 13:41:58,911] [    INFO][0m - loss: 0.53199487, learning_rate: 9.367231638418079e-06, global_step: 560, interval_runtime: 1.4915, interval_samples_per_second: 5.364, interval_steps_per_second: 6.705, epoch: 3.1638[0m
[32m[2022-09-05 13:42:00,412] [    INFO][0m - loss: 0.44437876, learning_rate: 9.355932203389831e-06, global_step: 570, interval_runtime: 1.501, interval_samples_per_second: 5.33, interval_steps_per_second: 6.662, epoch: 3.2203[0m
[32m[2022-09-05 13:42:01,903] [    INFO][0m - loss: 0.39189487, learning_rate: 9.344632768361582e-06, global_step: 580, interval_runtime: 1.4912, interval_samples_per_second: 5.365, interval_steps_per_second: 6.706, epoch: 3.2768[0m
[32m[2022-09-05 13:42:03,394] [    INFO][0m - loss: 0.47670951, learning_rate: 9.333333333333334e-06, global_step: 590, interval_runtime: 1.491, interval_samples_per_second: 5.365, interval_steps_per_second: 6.707, epoch: 3.3333[0m
[32m[2022-09-05 13:42:04,888] [    INFO][0m - loss: 0.45055747, learning_rate: 9.322033898305085e-06, global_step: 600, interval_runtime: 1.4938, interval_samples_per_second: 5.356, interval_steps_per_second: 6.694, epoch: 3.3898[0m
[32m[2022-09-05 13:42:04,889] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:42:04,889] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:42:04,889] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:42:04,889] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:42:04,889] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:42:16,124] [    INFO][0m - eval_loss: 0.43760454654693604, eval_accuracy: 0.27722772277227725, eval_runtime: 11.2345, eval_samples_per_second: 125.862, eval_steps_per_second: 15.755, epoch: 3.3898[0m
[32m[2022-09-05 13:42:16,124] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-600[0m
[32m[2022-09-05 13:42:16,125] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:42:19,100] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-600/tokenizer_config.json[0m
[32m[2022-09-05 13:42:19,101] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-600/special_tokens_map.json[0m
[32m[2022-09-05 13:42:25,591] [    INFO][0m - loss: 0.40400105, learning_rate: 9.310734463276837e-06, global_step: 610, interval_runtime: 20.7034, interval_samples_per_second: 0.386, interval_steps_per_second: 0.483, epoch: 3.4463[0m
[32m[2022-09-05 13:42:27,080] [    INFO][0m - loss: 0.42451434, learning_rate: 9.299435028248588e-06, global_step: 620, interval_runtime: 1.4889, interval_samples_per_second: 5.373, interval_steps_per_second: 6.716, epoch: 3.5028[0m
[32m[2022-09-05 13:42:28,573] [    INFO][0m - loss: 0.41413159, learning_rate: 9.28813559322034e-06, global_step: 630, interval_runtime: 1.4929, interval_samples_per_second: 5.359, interval_steps_per_second: 6.698, epoch: 3.5593[0m
[32m[2022-09-05 13:42:30,062] [    INFO][0m - loss: 0.45085731, learning_rate: 9.276836158192091e-06, global_step: 640, interval_runtime: 1.4889, interval_samples_per_second: 5.373, interval_steps_per_second: 6.716, epoch: 3.6158[0m
[32m[2022-09-05 13:42:31,552] [    INFO][0m - loss: 0.36059012, learning_rate: 9.265536723163843e-06, global_step: 650, interval_runtime: 1.4899, interval_samples_per_second: 5.369, interval_steps_per_second: 6.712, epoch: 3.6723[0m
[32m[2022-09-05 13:42:33,040] [    INFO][0m - loss: 0.37936945, learning_rate: 9.254237288135594e-06, global_step: 660, interval_runtime: 1.488, interval_samples_per_second: 5.376, interval_steps_per_second: 6.72, epoch: 3.7288[0m
[32m[2022-09-05 13:42:34,526] [    INFO][0m - loss: 0.30074368, learning_rate: 9.242937853107346e-06, global_step: 670, interval_runtime: 1.4863, interval_samples_per_second: 5.382, interval_steps_per_second: 6.728, epoch: 3.7853[0m
[32m[2022-09-05 13:42:36,017] [    INFO][0m - loss: 0.382967, learning_rate: 9.231638418079097e-06, global_step: 680, interval_runtime: 1.4903, interval_samples_per_second: 5.368, interval_steps_per_second: 6.71, epoch: 3.8418[0m
[32m[2022-09-05 13:42:37,509] [    INFO][0m - loss: 0.55988679, learning_rate: 9.220338983050847e-06, global_step: 690, interval_runtime: 1.4921, interval_samples_per_second: 5.362, interval_steps_per_second: 6.702, epoch: 3.8983[0m
[32m[2022-09-05 13:42:39,013] [    INFO][0m - loss: 0.53897486, learning_rate: 9.2090395480226e-06, global_step: 700, interval_runtime: 1.5041, interval_samples_per_second: 5.319, interval_steps_per_second: 6.649, epoch: 3.9548[0m
[32m[2022-09-05 13:42:39,013] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:42:39,013] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:42:39,014] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:42:39,015] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:42:39,015] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:42:50,182] [    INFO][0m - eval_loss: 0.4169565439224243, eval_accuracy: 0.2722772277227723, eval_runtime: 11.1685, eval_samples_per_second: 126.606, eval_steps_per_second: 15.848, epoch: 3.9548[0m
[32m[2022-09-05 13:42:50,183] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-700[0m
[32m[2022-09-05 13:42:50,183] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:42:53,206] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-700/tokenizer_config.json[0m
[32m[2022-09-05 13:42:53,207] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-700/special_tokens_map.json[0m
[32m[2022-09-05 13:43:00,791] [    INFO][0m - loss: 0.49517512, learning_rate: 9.19774011299435e-06, global_step: 710, interval_runtime: 21.7786, interval_samples_per_second: 0.367, interval_steps_per_second: 0.459, epoch: 4.0113[0m
[32m[2022-09-05 13:43:02,280] [    INFO][0m - loss: 0.4009459, learning_rate: 9.186440677966101e-06, global_step: 720, interval_runtime: 1.4888, interval_samples_per_second: 5.373, interval_steps_per_second: 6.717, epoch: 4.0678[0m
[32m[2022-09-05 13:43:03,768] [    INFO][0m - loss: 0.43274484, learning_rate: 9.175141242937853e-06, global_step: 730, interval_runtime: 1.4876, interval_samples_per_second: 5.378, interval_steps_per_second: 6.722, epoch: 4.1243[0m
[32m[2022-09-05 13:43:05,256] [    INFO][0m - loss: 0.38391311, learning_rate: 9.163841807909604e-06, global_step: 740, interval_runtime: 1.4887, interval_samples_per_second: 5.374, interval_steps_per_second: 6.717, epoch: 4.1808[0m
[32m[2022-09-05 13:43:06,750] [    INFO][0m - loss: 0.33449292, learning_rate: 9.152542372881356e-06, global_step: 750, interval_runtime: 1.4938, interval_samples_per_second: 5.356, interval_steps_per_second: 6.694, epoch: 4.2373[0m
[32m[2022-09-05 13:43:08,239] [    INFO][0m - loss: 0.46577411, learning_rate: 9.141242937853107e-06, global_step: 760, interval_runtime: 1.4888, interval_samples_per_second: 5.373, interval_steps_per_second: 6.717, epoch: 4.2938[0m
[32m[2022-09-05 13:43:09,728] [    INFO][0m - loss: 0.41211419, learning_rate: 9.12994350282486e-06, global_step: 770, interval_runtime: 1.4892, interval_samples_per_second: 5.372, interval_steps_per_second: 6.715, epoch: 4.3503[0m
[32m[2022-09-05 13:43:11,216] [    INFO][0m - loss: 0.48243823, learning_rate: 9.11864406779661e-06, global_step: 780, interval_runtime: 1.488, interval_samples_per_second: 5.376, interval_steps_per_second: 6.72, epoch: 4.4068[0m
[32m[2022-09-05 13:43:12,707] [    INFO][0m - loss: 0.47246466, learning_rate: 9.107344632768362e-06, global_step: 790, interval_runtime: 1.4909, interval_samples_per_second: 5.366, interval_steps_per_second: 6.707, epoch: 4.4633[0m
[32m[2022-09-05 13:43:14,196] [    INFO][0m - loss: 0.41516991, learning_rate: 9.096045197740113e-06, global_step: 800, interval_runtime: 1.4889, interval_samples_per_second: 5.373, interval_steps_per_second: 6.716, epoch: 4.5198[0m
[32m[2022-09-05 13:43:14,196] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:43:14,197] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:43:14,197] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:43:14,197] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:43:14,197] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:43:25,448] [    INFO][0m - eval_loss: 0.41515690088272095, eval_accuracy: 0.26732673267326734, eval_runtime: 11.2504, eval_samples_per_second: 125.685, eval_steps_per_second: 15.733, epoch: 4.5198[0m
[32m[2022-09-05 13:43:25,448] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-800[0m
[32m[2022-09-05 13:43:25,448] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:43:28,439] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-800/tokenizer_config.json[0m
[32m[2022-09-05 13:43:28,439] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-800/special_tokens_map.json[0m
[32m[2022-09-05 13:43:37,062] [    INFO][0m - loss: 0.36488767, learning_rate: 9.084745762711865e-06, global_step: 810, interval_runtime: 22.8661, interval_samples_per_second: 0.35, interval_steps_per_second: 0.437, epoch: 4.5763[0m
[32m[2022-09-05 13:43:38,552] [    INFO][0m - loss: 0.36320691, learning_rate: 9.073446327683618e-06, global_step: 820, interval_runtime: 1.4899, interval_samples_per_second: 5.369, interval_steps_per_second: 6.712, epoch: 4.6328[0m
[32m[2022-09-05 13:43:40,040] [    INFO][0m - loss: 0.43710299, learning_rate: 9.062146892655368e-06, global_step: 830, interval_runtime: 1.4881, interval_samples_per_second: 5.376, interval_steps_per_second: 6.72, epoch: 4.6893[0m
[32m[2022-09-05 13:43:41,529] [    INFO][0m - loss: 0.47789044, learning_rate: 9.05084745762712e-06, global_step: 840, interval_runtime: 1.4892, interval_samples_per_second: 5.372, interval_steps_per_second: 6.715, epoch: 4.7458[0m
[32m[2022-09-05 13:43:43,020] [    INFO][0m - loss: 0.45504498, learning_rate: 9.039548022598871e-06, global_step: 850, interval_runtime: 1.4902, interval_samples_per_second: 5.368, interval_steps_per_second: 6.711, epoch: 4.8023[0m
[32m[2022-09-05 13:43:44,509] [    INFO][0m - loss: 0.51677322, learning_rate: 9.028248587570622e-06, global_step: 860, interval_runtime: 1.4892, interval_samples_per_second: 5.372, interval_steps_per_second: 6.715, epoch: 4.8588[0m
[32m[2022-09-05 13:43:46,002] [    INFO][0m - loss: 0.38599534, learning_rate: 9.016949152542374e-06, global_step: 870, interval_runtime: 1.4929, interval_samples_per_second: 5.359, interval_steps_per_second: 6.699, epoch: 4.9153[0m
[32m[2022-09-05 13:43:47,493] [    INFO][0m - loss: 0.51097412, learning_rate: 9.005649717514125e-06, global_step: 880, interval_runtime: 1.4915, interval_samples_per_second: 5.364, interval_steps_per_second: 6.705, epoch: 4.9718[0m
[32m[2022-09-05 13:43:49,046] [    INFO][0m - loss: 0.32319338, learning_rate: 8.994350282485876e-06, global_step: 890, interval_runtime: 1.5521, interval_samples_per_second: 5.154, interval_steps_per_second: 6.443, epoch: 5.0282[0m
[32m[2022-09-05 13:43:50,536] [    INFO][0m - loss: 0.49462132, learning_rate: 8.983050847457628e-06, global_step: 900, interval_runtime: 1.4904, interval_samples_per_second: 5.368, interval_steps_per_second: 6.71, epoch: 5.0847[0m
[32m[2022-09-05 13:43:50,536] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:43:50,536] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:43:50,536] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:43:50,536] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:43:50,536] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:44:01,769] [    INFO][0m - eval_loss: 0.4805334508419037, eval_accuracy: 0.31683168316831684, eval_runtime: 11.2322, eval_samples_per_second: 125.888, eval_steps_per_second: 15.758, epoch: 5.0847[0m
[32m[2022-09-05 13:44:01,770] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-900[0m
[32m[2022-09-05 13:44:01,770] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:44:04,810] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-900/tokenizer_config.json[0m
[32m[2022-09-05 13:44:04,811] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-900/special_tokens_map.json[0m
[32m[2022-09-05 13:44:13,115] [    INFO][0m - loss: 0.52653303, learning_rate: 8.971751412429379e-06, global_step: 910, interval_runtime: 22.5795, interval_samples_per_second: 0.354, interval_steps_per_second: 0.443, epoch: 5.1412[0m
[32m[2022-09-05 13:44:14,604] [    INFO][0m - loss: 0.44651475, learning_rate: 8.960451977401131e-06, global_step: 920, interval_runtime: 1.4886, interval_samples_per_second: 5.374, interval_steps_per_second: 6.718, epoch: 5.1977[0m
[32m[2022-09-05 13:44:16,091] [    INFO][0m - loss: 0.35965648, learning_rate: 8.949152542372881e-06, global_step: 930, interval_runtime: 1.4875, interval_samples_per_second: 5.378, interval_steps_per_second: 6.723, epoch: 5.2542[0m
[32m[2022-09-05 13:44:17,582] [    INFO][0m - loss: 0.21104307, learning_rate: 8.937853107344634e-06, global_step: 940, interval_runtime: 1.4903, interval_samples_per_second: 5.368, interval_steps_per_second: 6.71, epoch: 5.3107[0m
[32m[2022-09-05 13:44:19,076] [    INFO][0m - loss: 0.74270267, learning_rate: 8.926553672316384e-06, global_step: 950, interval_runtime: 1.4944, interval_samples_per_second: 5.353, interval_steps_per_second: 6.692, epoch: 5.3672[0m
[32m[2022-09-05 13:44:20,564] [    INFO][0m - loss: 0.52871299, learning_rate: 8.915254237288137e-06, global_step: 960, interval_runtime: 1.4881, interval_samples_per_second: 5.376, interval_steps_per_second: 6.72, epoch: 5.4237[0m
[32m[2022-09-05 13:44:22,054] [    INFO][0m - loss: 0.39050159, learning_rate: 8.903954802259887e-06, global_step: 970, interval_runtime: 1.4898, interval_samples_per_second: 5.37, interval_steps_per_second: 6.712, epoch: 5.4802[0m
[32m[2022-09-05 13:44:23,545] [    INFO][0m - loss: 0.36976123, learning_rate: 8.89265536723164e-06, global_step: 980, interval_runtime: 1.491, interval_samples_per_second: 5.365, interval_steps_per_second: 6.707, epoch: 5.5367[0m
[32m[2022-09-05 13:44:25,037] [    INFO][0m - loss: 0.50404243, learning_rate: 8.88135593220339e-06, global_step: 990, interval_runtime: 1.4921, interval_samples_per_second: 5.361, interval_steps_per_second: 6.702, epoch: 5.5932[0m
[32m[2022-09-05 13:44:26,527] [    INFO][0m - loss: 0.39870131, learning_rate: 8.870056497175143e-06, global_step: 1000, interval_runtime: 1.4895, interval_samples_per_second: 5.371, interval_steps_per_second: 6.714, epoch: 5.6497[0m
[32m[2022-09-05 13:44:26,527] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:44:26,527] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:44:26,527] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:44:26,527] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:44:26,528] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:44:37,748] [    INFO][0m - eval_loss: 0.4007248878479004, eval_accuracy: 0.3316831683168317, eval_runtime: 11.22, eval_samples_per_second: 126.025, eval_steps_per_second: 15.775, epoch: 5.6497[0m
[32m[2022-09-05 13:44:37,748] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-1000[0m
[32m[2022-09-05 13:44:37,749] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:44:40,736] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-1000/tokenizer_config.json[0m
[32m[2022-09-05 13:44:40,736] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-1000/special_tokens_map.json[0m
[32m[2022-09-05 13:44:47,242] [    INFO][0m - loss: 0.35981071, learning_rate: 8.858757062146893e-06, global_step: 1010, interval_runtime: 20.7156, interval_samples_per_second: 0.386, interval_steps_per_second: 0.483, epoch: 5.7062[0m
[32m[2022-09-05 13:44:48,731] [    INFO][0m - loss: 0.32664084, learning_rate: 8.847457627118646e-06, global_step: 1020, interval_runtime: 1.4888, interval_samples_per_second: 5.373, interval_steps_per_second: 6.717, epoch: 5.7627[0m
[32m[2022-09-05 13:44:50,219] [    INFO][0m - loss: 0.36474683, learning_rate: 8.836158192090396e-06, global_step: 1030, interval_runtime: 1.4884, interval_samples_per_second: 5.375, interval_steps_per_second: 6.718, epoch: 5.8192[0m
[32m[2022-09-05 13:44:51,708] [    INFO][0m - loss: 0.39991872, learning_rate: 8.824858757062149e-06, global_step: 1040, interval_runtime: 1.4885, interval_samples_per_second: 5.375, interval_steps_per_second: 6.718, epoch: 5.8757[0m
[32m[2022-09-05 13:44:53,197] [    INFO][0m - loss: 0.63971481, learning_rate: 8.8135593220339e-06, global_step: 1050, interval_runtime: 1.4886, interval_samples_per_second: 5.374, interval_steps_per_second: 6.718, epoch: 5.9322[0m
[32m[2022-09-05 13:44:54,682] [    INFO][0m - loss: 0.63260703, learning_rate: 8.80225988700565e-06, global_step: 1060, interval_runtime: 1.4855, interval_samples_per_second: 5.385, interval_steps_per_second: 6.732, epoch: 5.9887[0m
[32m[2022-09-05 13:44:56,188] [    INFO][0m - loss: 0.41176238, learning_rate: 8.790960451977402e-06, global_step: 1070, interval_runtime: 1.5056, interval_samples_per_second: 5.313, interval_steps_per_second: 6.642, epoch: 6.0452[0m
[32m[2022-09-05 13:44:57,677] [    INFO][0m - loss: 0.27263324, learning_rate: 8.779661016949153e-06, global_step: 1080, interval_runtime: 1.4894, interval_samples_per_second: 5.371, interval_steps_per_second: 6.714, epoch: 6.1017[0m
[32m[2022-09-05 13:44:59,164] [    INFO][0m - loss: 0.45436244, learning_rate: 8.768361581920905e-06, global_step: 1090, interval_runtime: 1.4872, interval_samples_per_second: 5.379, interval_steps_per_second: 6.724, epoch: 6.1582[0m
[32m[2022-09-05 13:45:00,653] [    INFO][0m - loss: 0.35779526, learning_rate: 8.757062146892656e-06, global_step: 1100, interval_runtime: 1.4889, interval_samples_per_second: 5.373, interval_steps_per_second: 6.717, epoch: 6.2147[0m
[32m[2022-09-05 13:45:00,654] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:45:00,654] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:45:00,654] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:45:00,654] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:45:00,654] [    INFO][0m -   Total prediction steps = 177[0m
[6 5 3 2 4 3 5 2 0 6 5 2 6 5 4 6 4 6 5 4 2 6 6 1 6 2 5 4 6 1 1 3 0 0 2 4 4
 6 2 0 1 3 2 4 0 2 3 1 2 4 3 2 3 0 1 4 2 6 0 3 0 2 3 4 5 0 3 5 3 6 4 6 1 1
 2 4 3 5 5 2 1 2 5 2 6 2 3 6 1 0 6 6 2 2 6 4 6 0 4 4 3 2 4 2 3 5 5 3 3 0 5
 0 6 4 3 0 0 5 5 3 0 3 3 6 0 1 1 4 3 5 5 1 6 5 3 0 6 6 4 1 0 6 1 5 3 4 4 0
 0 0 3 4 3 4 1 2 1 6 1 3 5 4 5 0 2 4 1 4 1 3 2 6 1 4 3 1 2 0 5 1 2 1 6 0 5
 2 5 1 1 1 0 1 1 5 6 4 2 0 0 6 1 4]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[2 2 2 0 4 3 2 4 0 5 0 6 5 6 0 0 3 1 1 4 0 6 6 6 5 2 5 1 3 4 2 3 2 3 2 5 3
 4 0 6 1 3 0 3 0 5 3 0 0 4 6 4 3 0 3 0 2 2 2 5 0 1 3 5 6 1 3 5 2 6 0 4 5 5
 2 5 0 5 5 5 0 1 2 0 5 1 2 0 1 1 0 6 2 2 1 4 6 2 0 4 0 6 1 2 5 6 4 4 3 6 3
 3 3 4 0 0 3 6 4 6 5 6 0 4 0 1 6 1 6 5 5 2 6 5 2 0 6 5 1 5 6 5 0 1 5 1 4 6
 5 2 3 0 3 4 1 6 1 6 1 3 5 4 4 4 5 2 5 0 5 3 1 6 1 4 3 4 6 3 5 1 6 0 6 0 1
 6 2 5 6 1 3 1 1 5 5 1 1 1 2 3 0 3]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[2 2 2 0 4 5 3 4 0 0 2 6 5 5 0 1 3 1 5 0 0 0 2 0 3 5 5 4 3 1 3 6 5 3 3 5 3
 4 2 4 1 0 1 3 0 5 3 5 2 4 4 6 2 3 5 6 1 6 0 6 3 4 3 1 6 2 3 4 2 6 5 4 0 3
 6 5 6 6 0 2 3 5 5 6 5 4 2 2 4 6 0 6 2 2 1 4 5 2 4 4 4 0 5 1 3 0 4 4 3 6 3
 1 3 4 6 0 3 4 5 2 0 3 0 6 2 1 5 1 6 5 5 5 6 5 5 1 3 5 3 1 2 5 6 1 3 0 4 0
 1 2 3 0 1 0 2 6 0 2 3 5 1 6 4 0 2 2 5 4 1 1 4 3 3 0 2 2 2 1 6 1 0 0 3 0 1
 6 2 6 0 1 5 1 6 0 6 5 4 1 2 2 6 3]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[2 2 0 0 4 5 3 6 0 3 2 2 0 5 6 1 1 1 2 4 0 4 2 2 5 1 5 1 3 4 2 3 2 6 6 1 3
 2 2 4 5 0 0 2 0 3 3 5 1 2 5 4 3 3 3 0 1 6 2 5 3 1 3 0 1 4 3 3 2 6 1 4 0 3
 6 6 6 6 0 2 3 5 1 5 6 4 2 0 2 6 3 6 1 2 4 2 0 0 0 4 4 0 5 5 4 5 3 4 3 0 4
 1 4 4 6 0 3 4 6 2 6 0 6 6 4 0 6 5 4 5 5 4 3 4 5 1 3 5 0 1 6 6 5 5 3 6 4 0
 2 2 3 0 1 0 3 6 0 2 5 5 1 6 1 0 3 2 5 0 1 0 2 4 0 6 4 2 6 1 6 1 1 3 6 6 3
 2 5 6 0 1 0 1 2 5 6 1 2 6 1 1 1 4]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[6 2 0 0 4 5 5 1 0 2 2 1 6 5 1 4 0 1 2 4 2 6 2 2 0 1 5 1 3 4 0 3 2 3 6 5 4
 2 2 4 5 1 4 2 0 4 3 3 1 1 3 4 3 1 1 6 1 6 2 3 2 4 3 0 6 2 5 4 3 6 1 4 6 2
 6 5 6 6 0 5 3 5 5 5 6 6 6 0 5 6 0 3 1 2 4 4 5 0 0 4 4 0 5 5 4 5 5 4 3 1 4
 1 4 4 6 0 3 4 6 2 0 0 6 6 3 1 6 5 3 5 5 4 6 4 5 1 3 5 0 1 6 0 5 5 3 3 4 6
 3 2 3 0 2 0 3 1 0 2 4 5 1 6 1 0 3 2 0 0 1 0 2 4 6 0 1 2 5 1 6 1 6 3 6 5 3
 2 1 6 0 1 0 1 1 5 1 1 2 6 2 6 1 4]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[2 2 0 0 3 0 5 1 2 3 0 1 6 2 1 0 4 6 4 2 2 6 2 2 0 2 2 1 3 4 2 3 2 6 6 5 4
 2 0 3 5 3 5 2 0 4 3 4 3 1 1 4 2 1 1 3 5 6 4 3 5 4 3 0 6 0 3 6 3 6 1 6 6 0
 6 6 6 6 0 5 3 5 5 0 2 6 6 6 2 2 2 5 1 0 4 4 0 1 0 4 3 0 5 5 4 5 5 4 2 3 4
 1 4 3 0 1 2 4 6 2 1 1 3 4 1 5 1 6 4 5 6 0 3 4 5 0 1 5 0 4 6 6 5 0 2 3 4 6
 3 2 3 0 2 2 1 1 0 0 0 5 1 6 1 0 3 1 0 4 1 6 1 4 3 0 4 3 5 1 3 4 6 3 0 4 3
 2 1 4 1 1 0 1 1 5 1 1 2 5 2 6 1 4]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[6 2 0 0 3 5 5 1 0 2 2 5 6 0 1 4 3 1 0 6 0 5 2 2 0 1 5 1 3 4 2 3 5 3 3 4 4
 2 6 2 5 1 5 2 0 4 3 4 1 4 6 4 2 1 3 0 5 6 0 5 2 4 3 0 6 1 5 6 3 6 1 6 0 0
 5 6 6 6 0 5 3 5 5 6 2 6 6 0 2 0 2 5 1 2 1 4 0 0 0 4 3 6 5 0 4 5 5 4 2 0 4
 1 4 3 6 0 2 4 6 2 1 1 6 5 1 1 1 5 5 5 6 3 6 4 5 1 0 5 0 1 4 6 5 0 2 6 4 6
 3 2 5 0 2 6 1 1 0 6 0 5 0 4 1 0 3 1 6 0 0 0 3 4 3 4 1 3 0 1 3 1 1 0 4 1 3
 2 5 4 0 1 3 1 1 5 1 1 2 1 2 2 1 4]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[6 0 0 0 3 0 5 1 2 2 2 4 6 2 1 4 3 1 2 4 0 2 2 2 0 1 2 1 3 4 2 3 2 3 3 1 4
 2 0 3 5 5 5 2 0 3 3 4 3 1 3 4 2 1 3 3 1 6 6 5 2 4 3 0 6 1 5 2 3 6 1 6 6 2
 5 6 3 6 0 5 3 5 5 6 2 6 6 6 5 0 2 5 1 2 4 4 1 0 4 4 2 0 4 2 4 5 5 4 2 0 4
 1 4 4 0 0 3 4 6 2 2 1 6 5 1 1 1 5 5 5 6 3 6 4 5 1 3 5 1 1 4 6 5 3 5 6 4 6
 3 2 3 0 3 6 5 6 0 6 0 1 0 4 1 0 3 1 6 0 0 0 1 4 6 6 1 2 5 1 3 4 1 3 4 4 3
 2 2 4 0 1 3 1 1 5 6 1 2 6 1 6 0 4]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[5 4 0 0 4 0 5 1 2 0 2 4 6 0 0 4 3 1 2 4 0 2 2 2 0 1 2 1 3 4 3 3 5 3 3 1 4
 2 4 3 5 5 5 3 0 3 3 3 3 1 6 4 5 1 3 3 1 6 4 5 1 4 3 0 6 4 5 6 3 6 6 6 0 0
 0 6 3 6 0 5 3 4 5 6 2 6 6 6 5 0 2 5 1 2 4 4 0 1 4 4 2 0 4 4 5 5 0 4 2 0 4
 1 4 3 4 0 3 4 0 2 1 1 6 5 1 1 1 5 5 5 6 3 6 4 5 1 0 5 1 1 4 6 5 3 2 6 4 6
 3 2 3 0 3 6 5 5 0 0 0 1 0 4 1 0 3 1 5 0 0 0 2 4 6 0 0 2 0 1 6 1 1 0 4 1 0
 2 1 4 0 1 3 1 2 5 6 1 2 1 1 1 0 4]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[2 0 0 0 4 0 4 1 0 0 2 4 0 5 0 4 3 6 2 4 2 2 2 2 0 1 5 1 3 4 3 2 5 3 3 5 4
 2 0 3 5 5 5 3 0 3 3 4 3 1 6 4 5 1 3 3 1 6 6 2 3 4 6 0 6 1 5 6 3 0 6 6 6 0
 5 6 3 6 0 4 3 5 5 6 2 6 6 6 6 0 2 5 1 2 4 2 1 1 4 4 2 0 4 2 4 5 5 4 2 0 4
 1 4 3 4 0 3 4 0 2 1 1 0 6 1 0 3 5 3 5 5 4 6 4 5 1 0 5 1 1 4 6 5 3 2 6 4 6
 2 2 3 0 6 2 0 5 0 0 0 1 0 0 1 0 3 1 5 0 0 0 2 4 6 0 0 2 0 1 6 4 6 3 0 4 3
 2 2 4 0 1 3 1 2 5 6 1 2 6 1 6 1 4]
[32m[2022-09-05 13:45:11,849] [    INFO][0m - eval_loss: 0.6428247094154358, eval_accuracy: 0.3069306930693069, eval_runtime: 11.1941, eval_samples_per_second: 126.316, eval_steps_per_second: 15.812, epoch: 6.2147[0m
[32m[2022-09-05 13:45:11,849] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-1100[0m
[32m[2022-09-05 13:45:11,849] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:45:14,803] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-1100/tokenizer_config.json[0m
[32m[2022-09-05 13:45:14,804] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-1100/special_tokens_map.json[0m
[32m[2022-09-05 13:45:21,328] [    INFO][0m - loss: 0.24962177, learning_rate: 8.745762711864407e-06, global_step: 1110, interval_runtime: 20.6743, interval_samples_per_second: 0.387, interval_steps_per_second: 0.484, epoch: 6.2712[0m
[32m[2022-09-05 13:45:22,816] [    INFO][0m - loss: 0.32536592, learning_rate: 8.734463276836159e-06, global_step: 1120, interval_runtime: 1.4886, interval_samples_per_second: 5.374, interval_steps_per_second: 6.718, epoch: 6.3277[0m
[32m[2022-09-05 13:45:24,307] [    INFO][0m - loss: 0.51849532, learning_rate: 8.72316384180791e-06, global_step: 1130, interval_runtime: 1.4909, interval_samples_per_second: 5.366, interval_steps_per_second: 6.708, epoch: 6.3842[0m
[32m[2022-09-05 13:45:25,801] [    INFO][0m - loss: 0.46272473, learning_rate: 8.711864406779662e-06, global_step: 1140, interval_runtime: 1.4943, interval_samples_per_second: 5.354, interval_steps_per_second: 6.692, epoch: 6.4407[0m
[32m[2022-09-05 13:45:27,289] [    INFO][0m - loss: 0.25439322, learning_rate: 8.700564971751413e-06, global_step: 1150, interval_runtime: 1.4879, interval_samples_per_second: 5.377, interval_steps_per_second: 6.721, epoch: 6.4972[0m
[32m[2022-09-05 13:45:28,778] [    INFO][0m - loss: 0.24468801, learning_rate: 8.689265536723165e-06, global_step: 1160, interval_runtime: 1.4888, interval_samples_per_second: 5.373, interval_steps_per_second: 6.717, epoch: 6.5537[0m
[32m[2022-09-05 13:45:30,269] [    INFO][0m - loss: 0.14660472, learning_rate: 8.677966101694915e-06, global_step: 1170, interval_runtime: 1.491, interval_samples_per_second: 5.366, interval_steps_per_second: 6.707, epoch: 6.6102[0m
[32m[2022-09-05 13:45:31,758] [    INFO][0m - loss: 0.32375002, learning_rate: 8.666666666666668e-06, global_step: 1180, interval_runtime: 1.489, interval_samples_per_second: 5.373, interval_steps_per_second: 6.716, epoch: 6.6667[0m
[32m[2022-09-05 13:45:33,251] [    INFO][0m - loss: 0.26046298, learning_rate: 8.655367231638418e-06, global_step: 1190, interval_runtime: 1.4925, interval_samples_per_second: 5.36, interval_steps_per_second: 6.7, epoch: 6.7232[0m
[32m[2022-09-05 13:45:34,747] [    INFO][0m - loss: 0.67477589, learning_rate: 8.64406779661017e-06, global_step: 1200, interval_runtime: 1.4966, interval_samples_per_second: 5.346, interval_steps_per_second: 6.682, epoch: 6.7797[0m
[32m[2022-09-05 13:45:34,748] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:45:34,748] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:45:34,748] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:45:34,748] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:45:34,748] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:45:45,944] [    INFO][0m - eval_loss: 1.0273475646972656, eval_accuracy: 0.400990099009901, eval_runtime: 11.1952, eval_samples_per_second: 126.304, eval_steps_per_second: 15.81, epoch: 6.7797[0m
[32m[2022-09-05 13:45:45,944] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-1200[0m
[32m[2022-09-05 13:45:45,944] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:45:49,358] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-1200/tokenizer_config.json[0m
[32m[2022-09-05 13:45:49,359] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-1200/special_tokens_map.json[0m
[32m[2022-09-05 13:45:56,728] [    INFO][0m - loss: 0.35335133, learning_rate: 8.632768361581921e-06, global_step: 1210, interval_runtime: 21.9805, interval_samples_per_second: 0.364, interval_steps_per_second: 0.455, epoch: 6.8362[0m
[32m[2022-09-05 13:45:58,216] [    INFO][0m - loss: 0.47060862, learning_rate: 8.621468926553674e-06, global_step: 1220, interval_runtime: 1.4883, interval_samples_per_second: 5.375, interval_steps_per_second: 6.719, epoch: 6.8927[0m
[32m[2022-09-05 13:45:59,821] [    INFO][0m - loss: 0.277072, learning_rate: 8.610169491525424e-06, global_step: 1230, interval_runtime: 1.4905, interval_samples_per_second: 5.367, interval_steps_per_second: 6.709, epoch: 6.9492[0m
[32m[2022-09-05 13:46:01,333] [    INFO][0m - loss: 0.3504483, learning_rate: 8.598870056497177e-06, global_step: 1240, interval_runtime: 1.6261, interval_samples_per_second: 4.92, interval_steps_per_second: 6.15, epoch: 7.0056[0m
[32m[2022-09-05 13:46:02,822] [    INFO][0m - loss: 0.26703739, learning_rate: 8.587570621468927e-06, global_step: 1250, interval_runtime: 1.489, interval_samples_per_second: 5.373, interval_steps_per_second: 6.716, epoch: 7.0621[0m
[32m[2022-09-05 13:46:04,312] [    INFO][0m - loss: 0.18643241, learning_rate: 8.57627118644068e-06, global_step: 1260, interval_runtime: 1.4902, interval_samples_per_second: 5.368, interval_steps_per_second: 6.71, epoch: 7.1186[0m
[32m[2022-09-05 13:46:05,801] [    INFO][0m - loss: 0.31782117, learning_rate: 8.56497175141243e-06, global_step: 1270, interval_runtime: 1.4896, interval_samples_per_second: 5.371, interval_steps_per_second: 6.713, epoch: 7.1751[0m
[32m[2022-09-05 13:46:07,293] [    INFO][0m - loss: 0.37116625, learning_rate: 8.553672316384181e-06, global_step: 1280, interval_runtime: 1.4917, interval_samples_per_second: 5.363, interval_steps_per_second: 6.704, epoch: 7.2316[0m
[32m[2022-09-05 13:46:08,787] [    INFO][0m - loss: 0.35206695, learning_rate: 8.542372881355933e-06, global_step: 1290, interval_runtime: 1.4938, interval_samples_per_second: 5.356, interval_steps_per_second: 6.695, epoch: 7.2881[0m
[32m[2022-09-05 13:46:10,276] [    INFO][0m - loss: 0.51324301, learning_rate: 8.531073446327684e-06, global_step: 1300, interval_runtime: 1.4891, interval_samples_per_second: 5.372, interval_steps_per_second: 6.716, epoch: 7.3446[0m
[32m[2022-09-05 13:46:10,276] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:46:10,277] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:46:10,277] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:46:10,277] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:46:10,277] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:46:21,453] [    INFO][0m - eval_loss: 0.9407783150672913, eval_accuracy: 0.39603960396039606, eval_runtime: 11.1759, eval_samples_per_second: 126.522, eval_steps_per_second: 15.838, epoch: 7.3446[0m
[32m[2022-09-05 13:46:21,453] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-1300[0m
[32m[2022-09-05 13:46:21,454] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:46:24,644] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-1300/tokenizer_config.json[0m
[32m[2022-09-05 13:46:24,644] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-1300/special_tokens_map.json[0m
[32m[2022-09-05 13:46:31,838] [    INFO][0m - loss: 0.40404029, learning_rate: 8.519774011299435e-06, global_step: 1310, interval_runtime: 21.5621, interval_samples_per_second: 0.371, interval_steps_per_second: 0.464, epoch: 7.4011[0m
[32m[2022-09-05 13:46:33,329] [    INFO][0m - loss: 0.26585138, learning_rate: 8.508474576271187e-06, global_step: 1320, interval_runtime: 1.4908, interval_samples_per_second: 5.366, interval_steps_per_second: 6.708, epoch: 7.4576[0m
[32m[2022-09-05 13:46:34,819] [    INFO][0m - loss: 0.5110177, learning_rate: 8.497175141242938e-06, global_step: 1330, interval_runtime: 1.4899, interval_samples_per_second: 5.369, interval_steps_per_second: 6.712, epoch: 7.5141[0m
[32m[2022-09-05 13:46:36,309] [    INFO][0m - loss: 0.23159335, learning_rate: 8.48587570621469e-06, global_step: 1340, interval_runtime: 1.4905, interval_samples_per_second: 5.367, interval_steps_per_second: 6.709, epoch: 7.5706[0m
[32m[2022-09-05 13:46:37,795] [    INFO][0m - loss: 0.52578931, learning_rate: 8.47457627118644e-06, global_step: 1350, interval_runtime: 1.4859, interval_samples_per_second: 5.384, interval_steps_per_second: 6.73, epoch: 7.6271[0m
[32m[2022-09-05 13:46:39,284] [    INFO][0m - loss: 0.16170398, learning_rate: 8.463276836158193e-06, global_step: 1360, interval_runtime: 1.4889, interval_samples_per_second: 5.373, interval_steps_per_second: 6.716, epoch: 7.6836[0m
[32m[2022-09-05 13:46:40,774] [    INFO][0m - loss: 0.39832461, learning_rate: 8.451977401129944e-06, global_step: 1370, interval_runtime: 1.4895, interval_samples_per_second: 5.371, interval_steps_per_second: 6.714, epoch: 7.7401[0m
[32m[2022-09-05 13:46:42,263] [    INFO][0m - loss: 0.60174069, learning_rate: 8.440677966101696e-06, global_step: 1380, interval_runtime: 1.4891, interval_samples_per_second: 5.372, interval_steps_per_second: 6.716, epoch: 7.7966[0m
[32m[2022-09-05 13:46:43,755] [    INFO][0m - loss: 0.3192533, learning_rate: 8.429378531073447e-06, global_step: 1390, interval_runtime: 1.4922, interval_samples_per_second: 5.361, interval_steps_per_second: 6.701, epoch: 7.8531[0m
[32m[2022-09-05 13:46:45,246] [    INFO][0m - loss: 0.21386833, learning_rate: 8.418079096045199e-06, global_step: 1400, interval_runtime: 1.4914, interval_samples_per_second: 5.364, interval_steps_per_second: 6.705, epoch: 7.9096[0m
[32m[2022-09-05 13:46:45,247] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:46:45,247] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:46:45,247] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:46:45,247] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:46:45,247] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:46:56,391] [    INFO][0m - eval_loss: 0.9441964030265808, eval_accuracy: 0.39603960396039606, eval_runtime: 11.1435, eval_samples_per_second: 126.89, eval_steps_per_second: 15.884, epoch: 7.9096[0m
[32m[2022-09-05 13:46:56,392] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-1400[0m
[32m[2022-09-05 13:46:56,392] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:46:59,506] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-1400/tokenizer_config.json[0m
[32m[2022-09-05 13:46:59,506] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-1400/special_tokens_map.json[0m
[32m[2022-09-05 13:47:06,490] [    INFO][0m - loss: 0.18355615, learning_rate: 8.40677966101695e-06, global_step: 1410, interval_runtime: 21.2432, interval_samples_per_second: 0.377, interval_steps_per_second: 0.471, epoch: 7.9661[0m
[32m[2022-09-05 13:47:07,998] [    INFO][0m - loss: 0.6281426, learning_rate: 8.395480225988702e-06, global_step: 1420, interval_runtime: 1.5079, interval_samples_per_second: 5.305, interval_steps_per_second: 6.632, epoch: 8.0226[0m
[32m[2022-09-05 13:47:09,489] [    INFO][0m - loss: 0.20508797, learning_rate: 8.384180790960452e-06, global_step: 1430, interval_runtime: 1.491, interval_samples_per_second: 5.365, interval_steps_per_second: 6.707, epoch: 8.0791[0m
[32m[2022-09-05 13:47:10,979] [    INFO][0m - loss: 0.2886189, learning_rate: 8.372881355932205e-06, global_step: 1440, interval_runtime: 1.4906, interval_samples_per_second: 5.367, interval_steps_per_second: 6.709, epoch: 8.1356[0m
[32m[2022-09-05 13:47:12,473] [    INFO][0m - loss: 0.48888884, learning_rate: 8.361581920903955e-06, global_step: 1450, interval_runtime: 1.494, interval_samples_per_second: 5.355, interval_steps_per_second: 6.693, epoch: 8.1921[0m
[32m[2022-09-05 13:47:13,964] [    INFO][0m - loss: 0.20300927, learning_rate: 8.350282485875708e-06, global_step: 1460, interval_runtime: 1.4902, interval_samples_per_second: 5.368, interval_steps_per_second: 6.71, epoch: 8.2486[0m
[32m[2022-09-05 13:47:15,454] [    INFO][0m - loss: 0.1281839, learning_rate: 8.338983050847458e-06, global_step: 1470, interval_runtime: 1.4909, interval_samples_per_second: 5.366, interval_steps_per_second: 6.707, epoch: 8.3051[0m
[32m[2022-09-05 13:47:16,944] [    INFO][0m - loss: 0.03363077, learning_rate: 8.327683615819209e-06, global_step: 1480, interval_runtime: 1.4894, interval_samples_per_second: 5.371, interval_steps_per_second: 6.714, epoch: 8.3616[0m
[32m[2022-09-05 13:47:18,437] [    INFO][0m - loss: 0.17807531, learning_rate: 8.316384180790961e-06, global_step: 1490, interval_runtime: 1.4927, interval_samples_per_second: 5.359, interval_steps_per_second: 6.699, epoch: 8.4181[0m
[32m[2022-09-05 13:47:19,926] [    INFO][0m - loss: 0.1365206, learning_rate: 8.305084745762712e-06, global_step: 1500, interval_runtime: 1.4893, interval_samples_per_second: 5.372, interval_steps_per_second: 6.715, epoch: 8.4746[0m
[32m[2022-09-05 13:47:19,926] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:47:19,926] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:47:19,927] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:47:19,927] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:47:19,927] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:47:31,292] [    INFO][0m - eval_loss: 2.2351157665252686, eval_accuracy: 0.3811881188118812, eval_runtime: 11.3648, eval_samples_per_second: 124.42, eval_steps_per_second: 15.574, epoch: 8.4746[0m
[32m[2022-09-05 13:47:31,293] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-1500[0m
[32m[2022-09-05 13:47:31,293] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:47:34,612] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-1500/tokenizer_config.json[0m
[32m[2022-09-05 13:47:34,612] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-1500/special_tokens_map.json[0m
[32m[2022-09-05 13:47:41,261] [    INFO][0m - loss: 0.26985352, learning_rate: 8.293785310734463e-06, global_step: 1510, interval_runtime: 21.3352, interval_samples_per_second: 0.375, interval_steps_per_second: 0.469, epoch: 8.5311[0m
[32m[2022-09-05 13:47:42,753] [    INFO][0m - loss: 0.25003974, learning_rate: 8.282485875706215e-06, global_step: 1520, interval_runtime: 1.4915, interval_samples_per_second: 5.364, interval_steps_per_second: 6.705, epoch: 8.5876[0m
[32m[2022-09-05 13:47:44,240] [    INFO][0m - loss: 0.13795424, learning_rate: 8.271186440677966e-06, global_step: 1530, interval_runtime: 1.4872, interval_samples_per_second: 5.379, interval_steps_per_second: 6.724, epoch: 8.6441[0m
[32m[2022-09-05 13:47:45,736] [    INFO][0m - loss: 0.41990395, learning_rate: 8.259887005649718e-06, global_step: 1540, interval_runtime: 1.4955, interval_samples_per_second: 5.349, interval_steps_per_second: 6.687, epoch: 8.7006[0m
[32m[2022-09-05 13:47:47,227] [    INFO][0m - loss: 0.1349122, learning_rate: 8.248587570621469e-06, global_step: 1550, interval_runtime: 1.4914, interval_samples_per_second: 5.364, interval_steps_per_second: 6.705, epoch: 8.7571[0m
[32m[2022-09-05 13:47:48,716] [    INFO][0m - loss: 0.24566588, learning_rate: 8.237288135593221e-06, global_step: 1560, interval_runtime: 1.4894, interval_samples_per_second: 5.371, interval_steps_per_second: 6.714, epoch: 8.8136[0m
[32m[2022-09-05 13:47:50,214] [    INFO][0m - loss: 0.36396685, learning_rate: 8.225988700564972e-06, global_step: 1570, interval_runtime: 1.4976, interval_samples_per_second: 5.342, interval_steps_per_second: 6.677, epoch: 8.8701[0m
[32m[2022-09-05 13:47:51,710] [    INFO][0m - loss: 0.32407298, learning_rate: 8.214689265536724e-06, global_step: 1580, interval_runtime: 1.496, interval_samples_per_second: 5.348, interval_steps_per_second: 6.685, epoch: 8.9266[0m
[32m[2022-09-05 13:47:53,201] [    INFO][0m - loss: 0.42893496, learning_rate: 8.203389830508475e-06, global_step: 1590, interval_runtime: 1.4905, interval_samples_per_second: 5.367, interval_steps_per_second: 6.709, epoch: 8.9831[0m
[32m[2022-09-05 13:47:54,753] [    INFO][0m - loss: 0.13857007, learning_rate: 8.192090395480227e-06, global_step: 1600, interval_runtime: 1.5526, interval_samples_per_second: 5.153, interval_steps_per_second: 6.441, epoch: 9.0395[0m
[32m[2022-09-05 13:47:54,754] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:47:54,754] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:47:54,754] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:47:54,754] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:47:54,754] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:48:05,980] [    INFO][0m - eval_loss: 1.8548226356506348, eval_accuracy: 0.4306930693069307, eval_runtime: 11.2251, eval_samples_per_second: 125.967, eval_steps_per_second: 15.768, epoch: 9.0395[0m
[32m[2022-09-05 13:48:05,980] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-1600[0m
[32m[2022-09-05 13:48:05,981] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:48:08,948] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-1600/tokenizer_config.json[0m
[32m[2022-09-05 13:48:08,949] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-1600/special_tokens_map.json[0m
[32m[2022-09-05 13:48:15,823] [    INFO][0m - loss: 0.13843247, learning_rate: 8.18079096045198e-06, global_step: 1610, interval_runtime: 21.0697, interval_samples_per_second: 0.38, interval_steps_per_second: 0.475, epoch: 9.096[0m
[32m[2022-09-05 13:48:17,316] [    INFO][0m - loss: 0.19756706, learning_rate: 8.16949152542373e-06, global_step: 1620, interval_runtime: 1.4934, interval_samples_per_second: 5.357, interval_steps_per_second: 6.696, epoch: 9.1525[0m
[32m[2022-09-05 13:48:18,812] [    INFO][0m - loss: 0.12042447, learning_rate: 8.158192090395482e-06, global_step: 1630, interval_runtime: 1.4959, interval_samples_per_second: 5.348, interval_steps_per_second: 6.685, epoch: 9.209[0m
[32m[2022-09-05 13:48:20,310] [    INFO][0m - loss: 0.13513722, learning_rate: 8.146892655367233e-06, global_step: 1640, interval_runtime: 1.4976, interval_samples_per_second: 5.342, interval_steps_per_second: 6.677, epoch: 9.2655[0m
[32m[2022-09-05 13:48:21,802] [    INFO][0m - loss: 0.31513178, learning_rate: 8.135593220338983e-06, global_step: 1650, interval_runtime: 1.4923, interval_samples_per_second: 5.361, interval_steps_per_second: 6.701, epoch: 9.322[0m
[32m[2022-09-05 13:48:23,293] [    INFO][0m - loss: 0.18270565, learning_rate: 8.124293785310736e-06, global_step: 1660, interval_runtime: 1.491, interval_samples_per_second: 5.365, interval_steps_per_second: 6.707, epoch: 9.3785[0m
[32m[2022-09-05 13:48:24,784] [    INFO][0m - loss: 0.28201115, learning_rate: 8.112994350282486e-06, global_step: 1670, interval_runtime: 1.4906, interval_samples_per_second: 5.367, interval_steps_per_second: 6.709, epoch: 9.435[0m
[32m[2022-09-05 13:48:26,275] [    INFO][0m - loss: 0.11425054, learning_rate: 8.101694915254237e-06, global_step: 1680, interval_runtime: 1.4916, interval_samples_per_second: 5.364, interval_steps_per_second: 6.704, epoch: 9.4915[0m
[32m[2022-09-05 13:48:27,770] [    INFO][0m - loss: 0.08850673, learning_rate: 8.09039548022599e-06, global_step: 1690, interval_runtime: 1.4947, interval_samples_per_second: 5.352, interval_steps_per_second: 6.69, epoch: 9.548[0m
[32m[2022-09-05 13:48:29,262] [    INFO][0m - loss: 0.3865844, learning_rate: 8.07909604519774e-06, global_step: 1700, interval_runtime: 1.492, interval_samples_per_second: 5.362, interval_steps_per_second: 6.702, epoch: 9.6045[0m
[32m[2022-09-05 13:48:29,262] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:48:29,263] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:48:29,263] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:48:29,263] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:48:29,263] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:48:40,812] [    INFO][0m - eval_loss: 1.728922724723816, eval_accuracy: 0.4207920792079208, eval_runtime: 11.5478, eval_samples_per_second: 122.448, eval_steps_per_second: 15.328, epoch: 9.6045[0m
[32m[2022-09-05 13:48:40,813] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-1700[0m
[32m[2022-09-05 13:48:40,813] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:48:43,767] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-1700/tokenizer_config.json[0m
[32m[2022-09-05 13:48:43,767] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-1700/special_tokens_map.json[0m
[32m[2022-09-05 13:48:50,515] [    INFO][0m - loss: 0.24370937, learning_rate: 8.067796610169492e-06, global_step: 1710, interval_runtime: 21.2532, interval_samples_per_second: 0.376, interval_steps_per_second: 0.471, epoch: 9.661[0m
[32m[2022-09-05 13:48:52,005] [    INFO][0m - loss: 0.34613388, learning_rate: 8.056497175141243e-06, global_step: 1720, interval_runtime: 1.4897, interval_samples_per_second: 5.37, interval_steps_per_second: 6.713, epoch: 9.7175[0m
[32m[2022-09-05 13:48:53,496] [    INFO][0m - loss: 0.12504015, learning_rate: 8.045197740112995e-06, global_step: 1730, interval_runtime: 1.4912, interval_samples_per_second: 5.365, interval_steps_per_second: 6.706, epoch: 9.774[0m
[32m[2022-09-05 13:48:54,986] [    INFO][0m - loss: 0.28236938, learning_rate: 8.033898305084746e-06, global_step: 1740, interval_runtime: 1.4899, interval_samples_per_second: 5.37, interval_steps_per_second: 6.712, epoch: 9.8305[0m
[32m[2022-09-05 13:48:56,477] [    INFO][0m - loss: 0.07377167, learning_rate: 8.022598870056498e-06, global_step: 1750, interval_runtime: 1.4904, interval_samples_per_second: 5.368, interval_steps_per_second: 6.709, epoch: 9.887[0m
[32m[2022-09-05 13:48:57,968] [    INFO][0m - loss: 0.14060838, learning_rate: 8.011299435028249e-06, global_step: 1760, interval_runtime: 1.4921, interval_samples_per_second: 5.361, interval_steps_per_second: 6.702, epoch: 9.9435[0m
[32m[2022-09-05 13:48:59,422] [    INFO][0m - loss: 0.40556488, learning_rate: 8.000000000000001e-06, global_step: 1770, interval_runtime: 1.4535, interval_samples_per_second: 5.504, interval_steps_per_second: 6.88, epoch: 10.0[0m
[32m[2022-09-05 13:49:00,976] [    INFO][0m - loss: 0.11261121, learning_rate: 7.988700564971752e-06, global_step: 1780, interval_runtime: 1.5544, interval_samples_per_second: 5.147, interval_steps_per_second: 6.433, epoch: 10.0565[0m
[32m[2022-09-05 13:49:02,468] [    INFO][0m - loss: 0.07204418, learning_rate: 7.977401129943504e-06, global_step: 1790, interval_runtime: 1.4913, interval_samples_per_second: 5.365, interval_steps_per_second: 6.706, epoch: 10.113[0m
[32m[2022-09-05 13:49:03,960] [    INFO][0m - loss: 0.06002347, learning_rate: 7.966101694915255e-06, global_step: 1800, interval_runtime: 1.4922, interval_samples_per_second: 5.361, interval_steps_per_second: 6.701, epoch: 10.1695[0m
[32m[2022-09-05 13:49:03,960] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:49:03,960] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:49:03,960] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:49:03,961] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:49:03,961] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:49:15,174] [    INFO][0m - eval_loss: 1.8385460376739502, eval_accuracy: 0.4207920792079208, eval_runtime: 11.2132, eval_samples_per_second: 126.102, eval_steps_per_second: 15.785, epoch: 10.1695[0m
[32m[2022-09-05 13:49:15,175] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-1800[0m
[32m[2022-09-05 13:49:15,175] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:49:18,124] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-1800/tokenizer_config.json[0m
[32m[2022-09-05 13:49:18,125] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-1800/special_tokens_map.json[0m
[32m[2022-09-05 13:49:25,083] [    INFO][0m - loss: 0.04723194, learning_rate: 7.954802259887007e-06, global_step: 1810, interval_runtime: 21.1235, interval_samples_per_second: 0.379, interval_steps_per_second: 0.473, epoch: 10.226[0m
[32m[2022-09-05 13:49:26,572] [    INFO][0m - loss: 0.01244647, learning_rate: 7.943502824858758e-06, global_step: 1820, interval_runtime: 1.4882, interval_samples_per_second: 5.376, interval_steps_per_second: 6.72, epoch: 10.2825[0m
[32m[2022-09-05 13:49:28,063] [    INFO][0m - loss: 0.2444262, learning_rate: 7.93220338983051e-06, global_step: 1830, interval_runtime: 1.4912, interval_samples_per_second: 5.365, interval_steps_per_second: 6.706, epoch: 10.339[0m
[32m[2022-09-05 13:49:29,557] [    INFO][0m - loss: 0.18484019, learning_rate: 7.920903954802261e-06, global_step: 1840, interval_runtime: 1.4942, interval_samples_per_second: 5.354, interval_steps_per_second: 6.692, epoch: 10.3955[0m
[32m[2022-09-05 13:49:31,048] [    INFO][0m - loss: 0.24659672, learning_rate: 7.909604519774012e-06, global_step: 1850, interval_runtime: 1.4911, interval_samples_per_second: 5.365, interval_steps_per_second: 6.706, epoch: 10.452[0m
[32m[2022-09-05 13:49:32,542] [    INFO][0m - loss: 0.11287534, learning_rate: 7.898305084745764e-06, global_step: 1860, interval_runtime: 1.4931, interval_samples_per_second: 5.358, interval_steps_per_second: 6.698, epoch: 10.5085[0m
[32m[2022-09-05 13:49:34,031] [    INFO][0m - loss: 0.07955372, learning_rate: 7.887005649717515e-06, global_step: 1870, interval_runtime: 1.4903, interval_samples_per_second: 5.368, interval_steps_per_second: 6.71, epoch: 10.565[0m
[32m[2022-09-05 13:49:35,523] [    INFO][0m - loss: 0.14209633, learning_rate: 7.875706214689265e-06, global_step: 1880, interval_runtime: 1.4914, interval_samples_per_second: 5.364, interval_steps_per_second: 6.705, epoch: 10.6215[0m
[32m[2022-09-05 13:49:37,017] [    INFO][0m - loss: 0.21857226, learning_rate: 7.864406779661017e-06, global_step: 1890, interval_runtime: 1.4941, interval_samples_per_second: 5.354, interval_steps_per_second: 6.693, epoch: 10.678[0m
[32m[2022-09-05 13:49:38,509] [    INFO][0m - loss: 0.09570376, learning_rate: 7.853107344632768e-06, global_step: 1900, interval_runtime: 1.4915, interval_samples_per_second: 5.364, interval_steps_per_second: 6.705, epoch: 10.7345[0m
[32m[2022-09-05 13:49:38,509] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:49:38,509] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:49:38,509] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:49:38,509] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:49:38,509] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:49:49,740] [    INFO][0m - eval_loss: 2.252502202987671, eval_accuracy: 0.3910891089108911, eval_runtime: 11.2302, eval_samples_per_second: 125.911, eval_steps_per_second: 15.761, epoch: 10.7345[0m
[32m[2022-09-05 13:49:49,741] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-1900[0m
[32m[2022-09-05 13:49:49,741] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:49:52,772] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-1900/tokenizer_config.json[0m
[32m[2022-09-05 13:49:52,772] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-1900/special_tokens_map.json[0m
[32m[2022-09-05 13:49:59,866] [    INFO][0m - loss: 0.17331398, learning_rate: 7.84180790960452e-06, global_step: 1910, interval_runtime: 21.3576, interval_samples_per_second: 0.375, interval_steps_per_second: 0.468, epoch: 10.791[0m
[32m[2022-09-05 13:50:01,356] [    INFO][0m - loss: 0.2593317, learning_rate: 7.830508474576271e-06, global_step: 1920, interval_runtime: 1.4895, interval_samples_per_second: 5.371, interval_steps_per_second: 6.713, epoch: 10.8475[0m
[32m[2022-09-05 13:50:02,851] [    INFO][0m - loss: 0.11513364, learning_rate: 7.819209039548023e-06, global_step: 1930, interval_runtime: 1.4948, interval_samples_per_second: 5.352, interval_steps_per_second: 6.69, epoch: 10.904[0m
[32m[2022-09-05 13:50:04,343] [    INFO][0m - loss: 0.18216654, learning_rate: 7.807909604519774e-06, global_step: 1940, interval_runtime: 1.4926, interval_samples_per_second: 5.36, interval_steps_per_second: 6.7, epoch: 10.9605[0m
[32m[2022-09-05 13:50:05,859] [    INFO][0m - loss: 0.00854313, learning_rate: 7.796610169491526e-06, global_step: 1950, interval_runtime: 1.5157, interval_samples_per_second: 5.278, interval_steps_per_second: 6.597, epoch: 11.0169[0m
[32m[2022-09-05 13:50:07,350] [    INFO][0m - loss: 0.19131155, learning_rate: 7.785310734463277e-06, global_step: 1960, interval_runtime: 1.4915, interval_samples_per_second: 5.364, interval_steps_per_second: 6.705, epoch: 11.0734[0m
[32m[2022-09-05 13:50:08,842] [    INFO][0m - loss: 0.0004667, learning_rate: 7.77401129943503e-06, global_step: 1970, interval_runtime: 1.4916, interval_samples_per_second: 5.363, interval_steps_per_second: 6.704, epoch: 11.1299[0m
[32m[2022-09-05 13:50:10,335] [    INFO][0m - loss: 0.03949, learning_rate: 7.76271186440678e-06, global_step: 1980, interval_runtime: 1.4931, interval_samples_per_second: 5.358, interval_steps_per_second: 6.698, epoch: 11.1864[0m
[32m[2022-09-05 13:50:11,828] [    INFO][0m - loss: 0.07785956, learning_rate: 7.751412429378532e-06, global_step: 1990, interval_runtime: 1.4933, interval_samples_per_second: 5.357, interval_steps_per_second: 6.696, epoch: 11.2429[0m
[32m[2022-09-05 13:50:13,330] [    INFO][0m - loss: 0.03597107, learning_rate: 7.740112994350283e-06, global_step: 2000, interval_runtime: 1.5014, interval_samples_per_second: 5.328, interval_steps_per_second: 6.66, epoch: 11.2994[0m
[32m[2022-09-05 13:50:13,331] [    INFO][0m - ***** Running Evaluation *****[0m
[32m[2022-09-05 13:50:13,331] [    INFO][0m -   Num examples = 1414[0m
[32m[2022-09-05 13:50:13,331] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:50:13,331] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:50:13,331] [    INFO][0m -   Total prediction steps = 177[0m
[32m[2022-09-05 13:50:24,569] [    INFO][0m - eval_loss: 3.168492555618286, eval_accuracy: 0.3465346534653465, eval_runtime: 11.238, eval_samples_per_second: 125.823, eval_steps_per_second: 15.75, epoch: 11.2994[0m
[32m[2022-09-05 13:50:24,570] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/checkpoint-2000[0m
[32m[2022-09-05 13:50:24,570] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:50:27,854] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/checkpoint-2000/tokenizer_config.json[0m
[32m[2022-09-05 13:50:27,854] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/checkpoint-2000/special_tokens_map.json[0m
[32m[2022-09-05 13:50:33,629] [    INFO][0m - 
Training completed. 
[0m
[32m[2022-09-05 13:50:33,629] [    INFO][0m - Loading best model from ./checkpoints_chid/checkpoint-1600 (score: 0.4306930693069307).[0m
[32m[2022-09-05 13:50:34,558] [    INFO][0m - train_runtime: 701.0336, train_samples_per_second: 100.851, train_steps_per_second: 12.624, train_loss: 0.37117536417162045, epoch: 11.2994[0m
[32m[2022-09-05 13:50:34,559] [    INFO][0m - Saving model checkpoint to ./checkpoints_chid/[0m
[32m[2022-09-05 13:50:34,560] [    INFO][0m - Trainer.model is not a `PretrainedModel`, only saving its state dict.[0m
[32m[2022-09-05 13:50:37,877] [    INFO][0m - tokenizer config file saved in ./checkpoints_chid/tokenizer_config.json[0m
[32m[2022-09-05 13:50:37,878] [    INFO][0m - Special tokens file saved in ./checkpoints_chid/special_tokens_map.json[0m
[32m[2022-09-05 13:50:37,879] [    INFO][0m - ***** train metrics *****[0m
[32m[2022-09-05 13:50:37,879] [    INFO][0m -   epoch                    =    11.2994[0m
[32m[2022-09-05 13:50:37,879] [    INFO][0m -   train_loss               =     0.3712[0m
[32m[2022-09-05 13:50:37,879] [    INFO][0m -   train_runtime            = 0:11:41.03[0m
[32m[2022-09-05 13:50:37,879] [    INFO][0m -   train_samples_per_second =    100.851[0m
[32m[2022-09-05 13:50:37,879] [    INFO][0m -   train_steps_per_second   =     12.624[0m
[32m[2022-09-05 13:50:37,893] [    INFO][0m - ***** Running Prediction *****[0m
[32m[2022-09-05 13:50:37,893] [    INFO][0m -   Num examples = 14014[0m
[32m[2022-09-05 13:50:37,893] [    INFO][0m -   Pre device batch size = 8[0m
[32m[2022-09-05 13:50:37,893] [    INFO][0m -   Total Batch size = 8[0m
[32m[2022-09-05 13:50:37,894] [    INFO][0m -   Total prediction steps = 1752[0m
[32m[2022-09-05 13:52:32,692] [    INFO][0m - ***** test metrics *****[0m
[32m[2022-09-05 13:52:32,692] [    INFO][0m -   test_accuracy           =     0.3591[0m
[32m[2022-09-05 13:52:32,693] [    INFO][0m -   test_loss               =     1.8174[0m
[32m[2022-09-05 13:52:32,693] [    INFO][0m -   test_runtime            = 0:01:54.79[0m
[32m[2022-09-05 13:52:32,693] [    INFO][0m -   test_samples_per_second =    122.075[0m
[32m[2022-09-05 13:52:32,693] [    INFO][0m -   test_steps_per_second   =     15.262[0m
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[6 4 0 0 4 0 2 1 0 3 2 4 0 0 0 4 2 2 2 4 2 2 2 2 0 1 2 1 3 4 3 2 2 6 3 1 4
 0 4 3 5 3 5 3 3 3 3 0 3 1 6 4 2 1 3 3 0 6 6 2 4 4 6 0 6 4 5 6 3 6 6 6 6 0
 5 6 6 6 4 4 6 6 5 6 2 6 6 6 5 0 2 5 1 4 4 4 6 1 4 4 2 6 4 6 4 5 5 4 2 6 4
 1 4 3 5 4 3 4 0 2 5 0 0 5 1 1 3 5 3 5 5 5 6 4 5 1 3 5 1 1 4 6 5 3 2 6 4 1
 5 2 3 0 0 1 0 5 0 0 0 1 0 0 1 0 3 1 5 0 0 3 2 4 6 0 0 3 0 1 6 4 1 3 0 1 3
 2 1 4 0 1 3 1 1 5 6 1 2 1 1 1 1 6]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[6 4 0 0 4 5 2 1 2 3 2 4 0 0 0 4 2 1 2 4 0 6 2 2 0 1 2 1 3 4 3 2 2 6 3 1 4
 0 4 3 5 3 5 3 3 3 3 0 3 1 6 4 2 1 3 3 0 6 6 2 4 6 6 0 6 6 3 6 3 6 1 6 6 0
 5 6 6 6 4 6 6 6 5 6 2 1 6 6 5 0 2 5 1 2 4 4 6 1 4 4 2 6 4 6 4 5 4 4 2 6 4
 1 4 3 0 4 3 4 0 2 5 0 0 5 1 5 3 5 5 5 5 3 6 4 5 1 2 5 1 1 4 6 5 3 5 6 4 0
 5 2 3 0 0 2 5 5 0 0 0 1 0 4 1 0 3 1 5 4 0 3 2 4 6 4 5 3 0 1 6 4 1 3 0 1 0
 2 1 4 1 1 3 1 1 5 6 1 2 1 1 6 1 4]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[5 0 0 0 4 5 2 1 2 3 2 1 0 0 0 2 2 1 2 4 0 2 2 2 0 1 2 1 3 4 3 2 2 6 3 1 4
 0 4 3 5 5 5 3 3 3 3 0 3 1 6 4 3 1 3 3 0 6 6 2 4 4 6 0 6 1 3 6 3 6 1 6 6 0
 5 6 6 6 0 4 2 5 5 6 2 1 6 6 2 0 2 5 1 2 4 4 6 1 4 4 2 6 4 6 4 5 4 4 2 0 4
 1 4 3 5 4 3 5 0 2 5 0 0 5 1 5 3 5 6 5 5 5 6 4 5 1 3 5 1 1 4 6 5 3 2 4 4 0
 5 2 3 0 0 2 5 5 0 0 1 1 0 4 1 0 0 1 5 4 0 0 0 4 6 0 5 3 0 1 6 4 6 0 0 1 0
 2 1 4 0 1 3 1 1 5 1 1 1 1 1 1 1 2]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[2 4 0 0 4 5 2 6 0 2 2 2 0 0 0 2 3 2 2 4 2 2 4 2 0 1 2 1 3 4 3 2 2 6 3 1 4
 0 4 6 5 3 5 3 3 3 3 0 3 1 6 4 5 1 3 3 0 6 6 2 4 4 6 0 6 4 3 6 3 6 6 6 6 3
 5 6 6 6 0 6 2 5 5 6 2 1 6 6 6 5 4 5 1 2 4 2 1 1 4 4 2 6 4 6 4 5 5 4 2 6 4
 1 4 3 5 4 3 5 0 2 3 0 0 5 3 5 3 5 6 5 5 5 6 4 3 1 5 5 1 2 4 6 1 3 5 6 4 0
 5 2 3 0 1 2 5 5 0 0 0 1 0 4 1 0 3 1 5 4 0 3 2 4 6 0 5 2 0 1 6 4 6 3 0 1 0
 2 1 4 1 1 3 1 1 5 1 1 2 6 1 1 1 4]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[2 4 0 0 4 5 2 1 2 2 2 2 0 0 0 2 2 2 2 4 2 2 2 2 0 1 2 1 3 4 3 3 2 6 3 5 4
 0 4 6 5 3 5 3 3 3 3 0 3 1 6 4 3 1 3 3 0 6 6 2 4 6 6 0 6 1 3 6 3 6 6 6 6 3
 5 6 0 6 1 6 6 5 5 6 2 1 6 6 5 5 4 5 5 2 4 2 6 1 4 4 2 6 4 6 4 5 5 4 3 6 4
 1 4 3 5 4 4 5 0 2 5 0 0 5 1 5 3 2 6 5 5 5 6 4 3 6 3 5 1 2 4 6 1 3 5 6 4 0
 5 2 3 0 0 2 5 5 0 0 0 1 0 4 4 0 0 1 5 4 0 3 2 4 6 0 1 3 0 1 6 4 1 3 0 1 0
 2 1 4 1 1 3 1 1 5 6 1 2 1 1 1 1 4]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[2 0 0 0 4 5 2 1 0 2 2 2 0 0 0 2 2 2 2 4 0 2 2 2 0 1 2 1 3 4 3 6 2 6 3 5 4
 0 4 6 5 3 5 3 3 3 3 0 5 1 3 4 3 1 3 3 0 6 6 2 4 6 6 0 6 1 3 6 3 6 6 6 6 3
 5 6 0 6 0 4 6 5 5 6 2 1 6 6 5 5 2 5 1 2 4 2 6 1 4 4 4 6 4 1 4 5 4 4 3 6 4
 1 4 3 5 4 3 5 0 2 5 0 0 5 1 5 3 2 6 5 5 5 6 4 3 1 3 5 1 2 4 6 5 3 5 4 4 0
 5 2 3 0 0 6 5 5 5 0 0 1 0 4 1 0 0 1 5 4 0 0 0 4 6 4 1 3 0 1 6 4 1 3 0 1 0
 2 1 4 1 1 3 1 1 5 1 1 1 1 1 6 0 2]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[2 0 0 0 4 5 2 1 0 2 2 2 0 0 0 2 2 2 4 4 0 2 0 2 0 1 2 1 3 4 3 3 2 6 3 1 4
 6 4 6 5 3 5 3 3 3 3 0 5 1 3 4 3 1 3 3 0 6 6 2 4 6 6 0 2 5 3 6 3 6 6 4 6 5
 5 6 6 6 0 4 6 5 5 6 2 1 6 6 5 5 4 5 1 2 4 2 6 1 4 4 4 6 4 1 4 5 4 4 3 6 4
 1 4 3 5 4 4 5 0 2 5 0 0 5 1 5 3 2 6 5 5 5 6 4 3 1 3 5 1 2 4 6 5 3 5 4 4 0
 5 2 3 0 0 1 5 5 0 0 0 1 0 4 4 0 0 1 5 4 0 0 0 4 6 0 1 3 0 1 6 4 1 5 0 4 0
 2 1 4 1 1 3 1 1 5 6 1 1 1 1 1 0 2]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[2 4 0 0 4 5 2 1 2 2 2 2 0 0 0 2 2 2 4 4 2 2 4 2 0 1 2 1 3 4 3 3 2 6 3 1 4
 6 4 6 4 3 5 2 3 3 2 0 5 1 3 4 5 3 3 3 0 6 6 2 4 6 6 0 2 5 3 3 1 6 6 4 6 5
 5 6 3 5 0 4 6 5 5 6 2 1 6 6 5 5 4 2 1 2 4 4 6 1 4 4 2 6 4 1 4 5 5 4 2 6 4
 1 4 3 5 4 4 5 0 2 5 1 0 5 1 5 3 2 6 0 5 5 6 5 5 1 3 5 1 2 4 6 5 3 2 4 4 0
 3 2 3 0 0 2 5 5 0 0 0 1 0 4 4 0 0 1 5 4 3 0 0 4 6 0 1 2 0 0 6 4 1 5 0 1 0
 2 1 4 1 1 5 1 1 5 1 0 1 6 1 1 0 4]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[2 0 0 0 4 5 2 6 2 2 2 2 0 0 0 2 2 1 4 6 0 2 4 4 6 1 5 1 6 4 3 3 2 3 3 1 4
 2 4 3 5 3 5 2 3 3 2 3 5 1 5 5 5 1 3 3 0 6 3 3 4 6 6 0 2 5 3 3 1 6 2 4 6 5
 5 6 0 5 0 4 2 5 5 6 6 6 6 6 5 5 4 2 1 2 4 2 6 1 4 4 2 6 4 1 4 5 5 0 2 0 6
 1 4 3 6 6 3 5 0 2 5 5 0 5 1 0 0 5 6 0 5 5 6 5 4 1 3 5 2 2 4 6 5 3 5 6 4 0
 5 2 3 4 0 6 5 5 0 0 0 1 0 0 4 0 0 1 5 0 3 0 2 4 0 0 1 2 0 0 6 4 6 5 0 2 1
 1 1 6 1 0 5 1 1 4 1 0 1 6 2 1 1 4]
[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
[1 4 1 ... 1 1 0]
[1 1 1 ... 1 1 1]
0
= 0 ===================
[('‰∏ç', 7894), ('Âæà', 4118)]
----------
[('Âæà', 7894), ('‰∏ç', 4118)]
----------
[('ËæÉ', 3261), ('Êå∫', 2530), ('ÁöÑ', 1696), ('Â∏∏', 1258), ('ÊúÄ', 1018), ('Â§ß', 845), ('Âà´', 810), ('ÂàÜ', 274), ('‰ª•', 179), ('Â§™', 102), ('Ê≤°', 8), ('Èùû', 5), ('Â•Ω', 4), ('ÂÖ∂', 4), ('‰∏Ä', 3), ('Â∞è', 3), ('Âæó', 3), ('ÊòØ', 3), ('‰πü', 2), ('‰∏å', 1), ('Êù•', 1), ('Êó†', 1), ('ÂΩì', 1)]
----------
[('ÊúÄ', 2513), ('ËæÉ', 2234), ('Â∏∏', 1854), ('Âà´', 1199), ('ÁöÑ', 1123), ('Êå∫', 963), ('ÂàÜ', 803), ('Â§ß', 711), ('Â§™', 257), ('‰ª•', 244), ('Èùû', 22), ('Âæó', 19), ('Ê≤°', 18), ('ÂÖ∂', 9), ('Â•Ω', 8), ('‰∏Ä', 5), ('Áõ∏', 5), ('‰∏∫', 4), ('ÊòØ', 4), ('ÂΩì', 3), ('Â∞è', 3), ('‰πü', 2), ('Ë°å', 2), ('‰∏å', 2), ('‰∫é', 1), ('Êúâ', 1), ('Êó†', 1), ('ÊØî', 1), ('ÁÇπ', 1)]
----------
[('ËæÉ', 2301), ('Â∏∏', 2070), ('Â•Ω', 1918), ('Âà´', 1470), ('ÂàÜ', 1122), ('ÁöÑ', 1075), ('Â§ß', 609), ('Â§™', 360), ('ÊúÄ', 294), ('‰ª•', 241), ('Êå∫', 232), ('Ê≠£', 71), ('Êõ¥', 34), ('Âæó', 33), ('Èùû', 33), ('ÂÖ∂', 32), ('‰πü', 31), ('Ê≤°', 26), ('Áõ∏', 9), ('ÊòØ', 8), ('Â∞è', 7), ('‰∏Ä', 7), ('‰∏∫', 5), ('Êúâ', 4), ('Ëøá', 3), ('ÁÇπ', 2), ('‰∏å', 2), ('Êàê', 2), ('ÂΩì', 2), ('‰πã', 1), ('ÊØî', 1), ('Â§Ñ', 1), ('Êó†', 1), ('Áôæ', 1), (',', 1), ('‰∫Ü', 1), ('„ÄÇ', 1), ('‰∏ä', 1)]
----------
1
= 0 ===================
[('Âæà', 1371), ('‰∏ç', 631)]
----------
[('‰∏ç', 1371), ('Âæà', 631)]
----------
[('Êå∫', 958), ('ÊúÄ', 267), ('ËæÉ', 237), ('Â∏∏', 195), ('ÁöÑ', 183), ('Âà´', 73), ('Â§ß', 52), ('ÂàÜ', 21), ('‰ª•', 8), ('Â§™', 5), ('Êù•', 1), ('Áôæ', 1), ('ÊòØ', 1)]
----------
[('ÊúÄ', 954), ('Êå∫', 248), ('Â∏∏', 225), ('ËæÉ', 221), ('Âà´', 125), ('ÁöÑ', 117), ('ÂàÜ', 44), ('Â§ß', 32), ('Â§™', 14), ('‰ª•', 9), ('ÂÖ∂', 3), ('Âæó', 3), ('Ê≤°', 2), ('‰πü', 2), ('‰∏å', 1), ('ÂΩì', 1), ('ÊòØ', 1)]
----------
[('Â•Ω', 793), ('ËæÉ', 368), ('Â∏∏', 283), ('Âà´', 134), ('ÁöÑ', 131), ('ÂàÜ', 74), ('Êå∫', 63), ('ÊúÄ', 54), ('Â§ß', 32), ('Ê≠£', 16), ('Â§™', 15), ('Êõ¥', 10), ('‰πü', 10), ('‰ª•', 9), ('Ê≤°', 3), ('ÊòØ', 2), ('ÂÖ∂', 2), ('ÈÉΩ', 1), ('‰∫Ü', 1), ('ÂΩì', 1)]
----------
run.sh: line 58: --freeze_plm: command not found
